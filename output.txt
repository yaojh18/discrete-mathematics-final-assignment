InfoVis
2015
A comparative study between RadViz and Star Coordinates
10.1109/TVCG.2015.2467324
http://dx.doi.org/10.1109/TVCG.2015.2467324
619
628

J
RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.
Rubio-Sanchez, M.;Raya, L.;Diaz, F.;Sanchez, A.
;;;
10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2014.2346258;10.1109/TVCG.2008.173
RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection
InfoVis
2015
A Linguistic Approach to Categorical Color Assignment for Data Visualization
10.1109/TVCG.2015.2467471
http://dx.doi.org/10.1109/TVCG.2015.2467471
698
707

J
When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette.
Setlur, V.;Stone, M.C.
;

linguistics, natural language processing, semantics, color names, categorical color, Google n-grams, WordNet, XKCD
InfoVis
2015
A Psychophysical Investigation of Size as a Physical Variable
10.1109/TVCG.2015.2467951
http://dx.doi.org/10.1109/TVCG.2015.2467951
479
488

J
Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, ΓÇ£physical variablesΓÇ¥ remain poorly understood. One of them is physical size. A difficulty for solid elements is that ΓÇ£sizeΓÇ¥ is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants' estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables.
Jansen, Y.;Hornbaek, K.
Univ. of Copenhagen, Copenhagen, Denmark|c|;
10.1109/TVCG.2012.251;10.1109/TVCG.2013.234;10.1109/TVCG.2012.220;10.1109/TVCG.2013.134;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/TVCG.2014.2346320
Data physicalization, physical visualization, psychophysics, experiment, physical variable
InfoVis
2015
A Simple Approach for Boundary Improvement of Euler Diagrams
10.1109/TVCG.2015.2467992
http://dx.doi.org/10.1109/TVCG.2015.2467992
678
687

J
General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations.
Simonetto, P.;Archambault, D.;Scheidegger, C.
;;
10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210
Euler diagrams, Boundary Improvement, Force-Directed Approaches
InfoVis
2015
Acquired Codes of Meaning in Data Visualization and Infographics: Beyond Perceptual Primitives
10.1109/TVCG.2015.2467321
http://dx.doi.org/10.1109/TVCG.2015.2467321
509
518

J
While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88% of the infographics and 71% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.
Byrne, L.;Angus, D.;Wiles, J.
;;
10.1109/TVCG.2013.234;10.1109/TVCG.2010.126;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.221;10.1109/TVCG.2008.171
Visual Design, Taxonomies, Illustrative Visualization, Design Methodologies
InfoVis
2015
AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations
10.1109/TVCG.2015.2467051
http://dx.doi.org/10.1109/TVCG.2015.2467051
688
697

J
Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.
Yalcin, M.A.;Elmqvist, N.;Bederson, B.B.
Univ. of Maryland, College Park, MD, USA|c|;;
10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2011.185;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.144;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.141;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210;10.1109/TVCG.2014.2346249
Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability
InfoVis
2015
AmbiguityVis: Visualization of Ambiguity in Graph Layouts
10.1109/TVCG.2015.2467691
http://dx.doi.org/10.1109/TVCG.2015.2467691
359
368

J
Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.
Yong Wang;Qiaomu Shen;Archambault, D.;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu
;;;;;;
10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.155;10.1109/TVCG.2012.189
Visual Ambiguity, Visualization, Node-link diagram, Graph layout, Graph visualization
InfoVis
2015
Automatic Selection of Partitioning Variables for Small Multiple Displays
10.1109/TVCG.2015.2467323
http://dx.doi.org/10.1109/TVCG.2015.2467323
669
677

J
Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets.
Anand, A.;Talbot, J.
;
10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/TVCG.2011.229;10.1109/TVCG.2006.161;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70594;10.1109/VAST.2006.261423;10.1109/INFVIS.2000.885086;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.161;10.1109/INFVIS.2005.1532142
Small multiple displays, Visualization selection, Multidimensional data
InfoVis
2015
Beyond Memorability: Visualization Recognition and Recall
10.1109/TVCG.2015.2467732
http://dx.doi.org/10.1109/TVCG.2015.2467732
519
528

J
In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable ΓÇ£at-a-glanceΓÇ¥ are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.
Borkin, M.A.;Bylinskii, Z.;Nam Wook Kim;Bainbridge, C.M.;Yeh, C.S.;Borkin, D.;Pfister, H.;Oliva, A.
;;;;;;;
10.1109/TVCG.2012.197;10.1109/TVCG.2013.234;10.1109/TVCG.2011.193;10.1109/TVCG.2012.233;10.1109/TVCG.2011.175;10.1109/TVCG.2013.234;10.1109/TVCG.2012.215;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.245;10.1109/TVCG.2012.221
Information visualization, memorability, recognition, recall, eye-tracking study
InfoVis
2015
Beyond Weber's Law: A Second Look at Ranking Visualizations of Correlation
10.1109/TVCG.2015.2467671
http://dx.doi.org/10.1109/TVCG.2015.2467671
469
478

J
Models of human perception - including perceptual ΓÇ£lawsΓÇ¥ - can be valuable tools for deriving visualization design recommendations. However, it is important to assess the explanatory power of such models when using them to inform design. We present a secondary analysis of data previously used to rank the effectiveness of bivariate visualizations for assessing correlation (measured with Pearson's r) according to the well-known Weber-Fechner Law. Beginning with the model of Harrison et al. [1], we present a sequence of refinements including incorporation of individual differences, log transformation, censored regression, and adoption of Bayesian statistics. Our model incorporates all observations dropped from the original analysis, including data near ceilings caused by the data collection process and entire visualizations dropped due to large numbers of observations worse than chance. This model deviates from Weber's Law, but provides improved predictive accuracy and generalization. Using Bayesian credibility intervals, we derive a partial ranking that groups visualizations with similar performance, and we give precise estimates of the difference in performance between these groups. We find that compared to other visualizations, scatterplots are unique in combining low variance between individuals and high precision on both positively- and negatively correlated data. We conclude with a discussion of the value of data sharing and replication, and share implications for modeling similar experimental data.
Kay, M.;Heer, J.
;
10.1109/TVCG.2014.2346979
Weber's law, perception of correlation, log transformation, censored regression, Bayesian methods
InfoVis
2015
Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research
10.1109/TVCG.2015.2466992
http://dx.doi.org/10.1109/TVCG.2015.2466992
579
588

J
The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.
Johansson, J.;Forsell, C.
Norrkoping Visualization Center C, Linkoping Univ., Linkoping, Sweden|c|;
10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.201;10.1109/VISUAL.1999.809866;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.5;10.1109/TVCG.2011.197;10.1109/VISUAL.1997.663867
Survey, evaluation, guidelines, parallel coordinates
InfoVis
2015
Guidelines for Effective Usage of Text Highlighting Techniques
10.1109/TVCG.2015.2467759
http://dx.doi.org/10.1109/TVCG.2015.2467759
489
498

J
Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.
Strobelt, H.;Oelke, D.;Bum Chul Kwon;Schreck, T.;Pfister, H.
;;;;
10.1109/TVCG.2012.277;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.183;10.1109/TVCG.2009.139;10.1109/VAST.2011.6102453;10.1109/INFVIS.1995.528686
Text highlighting techniques, visual document analytics, text annotation, crowdsourced study
InfoVis
2015
High-Quality Ultra-Compact Grid Layout of Grouped Networks
10.1109/TVCG.2015.2467251
http://dx.doi.org/10.1109/TVCG.2015.2467251
339
348

J
Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks.
Yoghourdjian, V.;Dwyer, T.;Gange, G.;Kieffer, S.;Klein, K.;Marriott, K.
;;;;;
10.1109/TVCG.2008.117;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/INFVIS.2003.1249009;10.1109/TVCG.2015.2467451;10.1109/TVCG.2012.245
Network visualization, graph drawing, power graph, optimization, large-neighborhood search
InfoVis
2015
HOLA: Human-like Orthogonal Network Layout
10.1109/TVCG.2015.2467451
http://dx.doi.org/10.1109/TVCG.2015.2467451
349
358

J
Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new ΓÇ£human-centredΓÇ¥ methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.
Kieffer, S.;Dwyer, T.;Marriott, K.;Wybrow, M.
;;;
10.1109/TVCG.2006.120;10.1109/TVCG.2012.208;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/TVCG.2008.141;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/TVCG.2008.155
Graph layout, orthogonal layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics
InfoVis
2015
How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice&#x0027;s Information Visualization Sensemaking
10.1109/TVCG.2015.2467195
http://dx.doi.org/10.1109/TVCG.2015.2467195
499
508

J
In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.
Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Lam, H.;Youn-ah Kang;Ji Soo Yi
Sch. of Ind. Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;;
10.1109/TVCG.2013.234;10.1109/TVCG.2014.2346984;10.1109/TVCG.2010.164;10.1109/VAST.2011.6102435;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.177;10.1109/TVCG.2014.2346481;10.1109/TVCG.2010.179;10.1109/TVCG.2007.70515
Sensemaking model, information visualization, novice users, grounded theory, qualitative study
InfoVis
2015
Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability
10.1109/TVCG.2015.2467758
http://dx.doi.org/10.1109/TVCG.2015.2467758
529
538

J
Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields.
Ottley, A.;Peck, E.M.;Harrison, L.T.;Afergan, D.;Ziemkiewicz, C.;Taylor, H.A.;Han, P.K.J.;Chang, R.
;;;;;;;
10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5653587;10.1109/TVCG.2011.255;10.1109/TVCG.2013.119;10.1109/TVCG.2012.199;10.1109/TVCG.2010.179;10.1109/VISUAL.2005.1532836
Bayesian Reasoning, Visualization, Spatial Ability, Individual Differences
InfoVis
2015
Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis
10.1109/TVCG.2015.2466971
http://dx.doi.org/10.1109/TVCG.2015.2466971
449
458

J
The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.
Brehmer, M.;Ng, J.;Tate, K.;Munzner, T.
;;;
10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2008.166;10.1109/TVCG.2013.145;10.1109/TVCG.2013.173;10.1109/TVCG.2010.162;10.1109/TVCG.2007.70583;10.1109/TVCG.2011.209;10.1109/TVCG.2014.2346331;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2011.196;10.1109/TVCG.2012.213;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122
Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views
InfoVis
2015
Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators
10.1109/TVCG.2015.2467322
http://dx.doi.org/10.1109/TVCG.2015.2467322
569
578

J
A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.
Albo, Y.;Lanir, J.;Bak, P.;Rafaeli, S.
Univ. of Haifa, Haifa, Israel|c|;;;
10.1109/TVCG.2010.209;10.1109/TVCG.2008.125
Visualization evaluation, radial layout design, composite indicator visualization, experiment
InfoVis
2015
Optimal Sets of Projections of High-Dimensional Data
10.1109/TVCG.2015.2467132
http://dx.doi.org/10.1109/TVCG.2015.2467132
609
618

J
Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.
Lehmann, D.J.;Theisel, H.
Univ. of Magdeburg, Magdeburg, Germany|c|;
10.1109/VAST.2010.5652433;10.1109/VAST.2011.6102437;10.1109/TVCG.2011.229;10.1109/VISUAL.1997.663916;10.1109/TVCG.2011.220;10.1109/TVCG.2013.182;10.1109/TVCG.2010.207;10.1109/VAST.2006.261423;10.1109/INFVIS.2005.1532142
Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data
InfoVis
2015
Orientation-Enhanced Parallel Coordinate Plots
10.1109/TVCG.2015.2467872
http://dx.doi.org/10.1109/TVCG.2015.2467872
589
598

J
Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques.
Raidou, R.G.;Eisemann, M.;Breeuwer, M.;Eisemann, E.;Vilanova, A.
;;;;
10.1109/INFVIS.1998.729559;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1999.809866;10.1109/TVCG.2011.166;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.15;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.179
Parallel Coordinates, Orientation-enhanced Parallel Coordinates, Brushing, Orientation-enhanced Brushing, Data Readability, Data Selection
InfoVis
2015
Poemage: Visualizing the Sonic Topology of a Poem
10.1109/TVCG.2015.2467811
http://dx.doi.org/10.1109/TVCG.2015.2467811
439
448

J
The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.
McCurdy, N.;Lein, J.;Coles, K.;Meyer, M.
;;;
10.1109/TVCG.2011.186;10.1109/TVCG.2009.122;10.1109/VAST.2009.5333443;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2008.172;10.1109/INFVIS.1995.528686
Visualization in the humanities, design studies, text and document data, graph/network data
InfoVis
2015
Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions
10.1109/TVCG.2015.2467717
http://dx.doi.org/10.1109/TVCG.2015.2467717
629
638

J
We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.
Stahnke, J.;Dörk, M.;Müller, B.;Thom, A.
;;;
10.1109/TVCG.2013.157;10.1109/TVCG.2011.255;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/TVCG.2009.153;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346419;10.1109/TVCG.2013.153;10.1109/TVCG.2009.127;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/INFVIS.2004.60;10.1109/INFVIS.1995.528686
Information visualization, interactivity, dimensionality reduction, multidimensional scaling
InfoVis
2015
Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization
10.1109/TVCG.2015.2467091
http://dx.doi.org/10.1109/TVCG.2015.2467091
659
668

J
We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.
Satyanarayan, A.;Russell, R.;Hoffswell, J.;Heer, J.
;;;
10.1109/VISUAL.1995.480821;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2010.144;10.1109/TVCG.2014.2346250;10.1109/TVCG.2013.179;10.1109/TVCG.2010.177;10.1109/VISUAL.1996.567752;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70515
Information visualization, systems, toolkits, declarative specification, optimization, interaction, streaming data
InfoVis
2015
SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams
10.1109/TVCG.2015.2467035
http://dx.doi.org/10.1109/TVCG.2015.2467035
330
338

J
System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.
Cohé, A.;Liutkus, B.;Bailly, G.;Eagan, J.;Lecolinet, E.
;;;;
10.1109/INFVIS.2004.66;10.1109/TVCG.2012.245;10.1109/INFVIS.2003.1249008
Fisheye, vector-scaling, content-aware, network schematics, interactive zoom, navigation, information visualization
InfoVis
2015
Sketching Designs Using the Five Design-Sheet Methodology
10.1109/TVCG.2015.2467271
http://dx.doi.org/10.1109/TVCG.2015.2467271
419
428

J
Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching.
Roberts, J.C.;Headleand, C.;Ritsos, P.D.
;;
10.1109/TVCG.2010.132;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.178;10.1109/VISUAL.1994.346304;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.171
Lo-fidelity prototyping, User-centred design, Sketching for visualization, Ideation
InfoVis
2015
Spatial Reasoning and Data Displays
10.1109/TVCG.2015.2469125
http://dx.doi.org/10.1109/TVCG.2015.2469125
459
468

J
Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types.
VanderPlas, S.;Hofmann, H.
;
10.1109/TVCG.2012.230;10.1109/TVCG.2014.2346320;10.1109/TVCG.2010.161
Data visualization, Perception, Statistical graphics, Statistical computing
InfoVis
2015
Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections
10.1109/TVCG.2015.2467452
http://dx.doi.org/10.1109/TVCG.2015.2467452
429
438

J
In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.
Hinrichs, U.;Forlini, S.;Moynihan, B.
SACHI Group, Univ. of St. Andrews, St. Andrews, UK|c|;;
10.1109/TVCG.2012.272;10.1109/TVCG.2014.2346431;10.1109/TVCG.2008.175;10.1109/TVCG.2008.127;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2008.4677370
Digital Humanities, Interlinked Visualization, Literary Studies, Cultural Collections, Science Fiction
InfoVis
2015
Suggested Interactivity: Seeking Perceived Affordances for Information Visualization
10.1109/TVCG.2015.2467201
http://dx.doi.org/10.1109/TVCG.2015.2467201
639
648

J
In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.
Boy, J.;Eveillard, L.;Detienne, F.;Fekete, J.-D.
;;;
10.1109/TVCG.2014.2346984;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/INFVIS.2005.1532122
Suggested interactivity, perceived affordances, information visualization for the people, online visualization
InfoVis
2015
Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data
10.1109/TVCG.2015.2467851
http://dx.doi.org/10.1109/TVCG.2015.2467851
559
568

J
We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.
Bach, B.;Conglei Shi;Heulot, N.;Madhyastha, T.;Grabowski, T.;Dragicevic, P.
Microsoft Res.-Inria Joint Centre, USA|c|;;;;;
10.1109/TVCG.2011.186;10.1109/TVCG.2007.70535;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346325;10.1109/TVCG.2013.192;10.1109/INFVIS.2002.1173155
Temporal data visualization, information visualization, multidimensional scaling
InfoVis
2015
TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data
10.1109/TVCG.2015.2467751
http://dx.doi.org/10.1109/TVCG.2015.2467751
549
558

J
Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.
Walker, J.;Borgo, R.;Jones, M.W.
;;
10.1109/TVCG.2009.181;10.1109/TVCG.2014.2346428;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.160;10.1109/TVCG.2010.162;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801860;10.1109/TVCG.2011.195
Time-series Exploration, Focus+Context, Lens, Interaction Techniques
InfoVis
2015
TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients
10.1109/TVCG.2015.2467325
http://dx.doi.org/10.1109/TVCG.2015.2467325
409
418

J
We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.
Loorak, M.H.;Perin, C.;Kamal, N.;Hill, M.;Carpendale, S.
Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada|c|;;;;
10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70515
Multi-dimensional data, Temporal event sequences, Electronic health records
InfoVis
2015
Vials: Visualizing Alternative Splicing of Genes
10.1109/TVCG.2015.2467911
http://dx.doi.org/10.1109/TVCG.2015.2467911
399
408

J
Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.
Strobelt, H.;Alsallakh, B.;Botros, J.;Peterson, B.;Borowsky, M.;Pfister, H.;Lex, A.
;;;;;;
10.1109/TVCG.2013.214;10.1109/TVCG.2013.223;10.1109/TVCG.2014.2346248
Biology visualization, protein isoforms, mRNA-seq, directed acyclic graphs, multivariate networks
InfoVis
2015
Visual Encodings of Temporal Uncertainty: A Comparative User Study
10.1109/TVCG.2015.2467752
http://dx.doi.org/10.1109/TVCG.2015.2467752
539
548

J
A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values.
Gschwandtner, T.;Bögl, M.;Federico, P.;Miksch, S.
;;;
10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.279;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.114
Uncertainty, temporal intervals, visualization
InfoVis
2015
Visual Mementos: Reflecting Memories with Personal Data
10.1109/TVCG.2015.2467831
http://dx.doi.org/10.1109/TVCG.2015.2467831
369
378

J
In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.
Thudt, A.;Baur, D.;Huron, S.;Carpendale, S.
;;;
10.1109/TVCG.2010.206;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/INFVIS.2004.8
Visual Memento, Memories, Personal Visualization, Movement Data, World Wide Web
InfoVis
2015
Visualization, Selection, and Analysis of Traffic Flows
10.1109/TVCG.2015.2467112
http://dx.doi.org/10.1109/TVCG.2015.2467112
379
388

J
Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.
Scheepens, R.;Hurter, C.;van de Wetering, H.;van Wijk, J.J.
Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;
10.1109/TVCG.2011.185;10.1109/TVCG.2011.261;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294
Moving Object Visualization, traffic flows, interaction
InfoVis
2015
Visualizing Multiple Variables Across Scale and Geography
10.1109/TVCG.2015.2467199
http://dx.doi.org/10.1109/TVCG.2015.2467199
599
608

J
Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.
Goodwin, S.;Dykes, J.;Slingsby, A.;Turkay, C.
;;;
10.1109/TVCG.2007.70558;10.1109/TVCG.2013.145;10.1109/TVCG.2007.70539;10.1109/TVCG.2014.2346482;10.1109/VAST.2011.6102448;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321;10.1109/TVCG.2009.128;10.1109/TVCG.2011.197;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346265
Scale, Geography, Multivariate, Sensitivity Analysis, Variable Selection, Local Statistics, Geodemographics, Energy
InfoVis
2015
Visually Comparing Weather Features in Forecasts
10.1109/TVCG.2015.2467754
http://dx.doi.org/10.1109/TVCG.2015.2467754
389
398

J
Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.
Quinan, P.S.;Meyer, M.
;
10.1109/VISUAL.1990.146361;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2011.209;10.1109/TVCG.2010.181;10.1109/TVCG.2012.213;10.1109/TVCG.2013.143
Design study, weather, geographic/geospatial visualization, ensemble data
InfoVis
2015
Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations
10.1109/TVCG.2015.2467191
http://dx.doi.org/10.1109/TVCG.2015.2467191
649
658

J
General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.
Wongsuphasawat, K.;Moritz, D.;Anand, A.;Mackinlay, J.;Howe, B.;Heer, J.
;;;;;
10.1109/TVCG.2014.2346297;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346291;10.1109/INFVIS.2000.885086
User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems
SciVis
2015
3D superquadric glyphs for visualizing myocardial motion
10.1109/SciVis.2015.7429504
http://dx.doi.org/10.1109/SciVis.2015.7429504
143
144

M
Various cardiac diseases can be diagnosed by the analysis of myocardial motion. Relevant biomarkers are radial, longitudinal, and rotational velocities of the cardiac muscle computed locally from MR images. We designed a visual encoding that maps these three attributes to glyph shapes according to a barycentric space formed by 3D superquadric glyphs. The glyphs show aggregated myocardial motion information following the AHA model and are displayed in a respective 3D layout.
T. Chitiboi;M. Neugebauer;S. Schnell;M. Markl;L. Linsen
FraunhoferMEVIS, Jacobs University Bremen|c|;;;;

User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems
SciVis
2015
A bottom-up scheme for user-defined feature exploration in vector field ensembles
10.1109/SciVis.2015.7429510
http://dx.doi.org/10.1109/SciVis.2015.7429510
155
156

M
Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.
R. Liu;H. Guo;X. Yuan
Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University|c|;;

User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems
SciVis
2015
A Classification of User Tasks in Visual Analysis of Volume Data
10.1109/SciVis.2015.7429485
http://dx.doi.org/10.1109/SciVis.2015.7429485
1
8

C
Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.
B. Laha;D. A. Bowman;D. H. Laidlaw;J. J. Socha
Stanford University|c|;;;
10.1109/INFVIS.2004.10;10.1109/TVCG.2013.124;10.1109/TVCG.2012.216;10.1109/TVCG.2009.126;10.1109/TVCG.2013.130;10.1109/TVCG.2013.120;10.1109/TVCG.2014.2346321;10.1109/INFVIS.2004.59
Task Taxonomy, Empirical Evaluation, Volume Visualization, Scientific Visualization, Virtual Reality, 3D Interaction
SciVis
2015
A proposed multivariate visualization taxonomy from user data
10.1109/SciVis.2015.7429511
http://dx.doi.org/10.1109/SciVis.2015.7429511
157
158

M
We revisited past user study data on multivariate visualizations, looking at whether image processing measures offer any insight into user performance. While we find statistically significant correlations, some of the greatest insights into user performance came from variables that have strong ties to two key properties of multivariate representations. We discuss our analysis and propose a taxonomy of multivariate visualizations that arises.
M. A. Livingston;J. W. Decker;Z. Ai
;;

Task Taxonomy, Empirical Evaluation, Volume Visualization, Scientific Visualization, Virtual Reality, 3D Interaction
SciVis
2015
A Visual Voting Framework for Weather Forecast Calibration
10.1109/SciVis.2015.7429488
http://dx.doi.org/10.1109/SciVis.2015.7429488
25
32

C
Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.
H. Liao;Y. Wu;L. Chen;T. M. Hamill;Y. Wang;K. Dai;H. Zhang;W. Chen
School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University|c|;;;;;;;
10.1109/TVCG.2013.131;10.1109/TVCG.2013.138;10.1109/TVCG.2013.144;10.1109/TVCG.2009.197;10.1109/TVCG.2008.139;10.1109/TVCG.2014.2346755;10.1109/TVCG.2010.181;10.1109/VISUAL.1994.346298;10.1109/TVCG.2013.143
Weather forecast, analog method, calibration, majority voting, visual analytics
SciVis
2015
Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles
10.1109/TVCG.2015.2467198
http://dx.doi.org/10.1109/TVCG.2015.2467198
708
717

J
Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality.
Hermann, M.;Schunke, A.C.;Schultz, T.;Klein, R.
Inst. fur Inf. II, Univ. Bonn, Bonn, Germany|c|;;;
10.1109/TVCG.2006.140;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2014.2346591;10.1109/TVCG.2014.2346405;10.1109/TVCG.2006.123
Statistical deformation model, stationary velocity fields, image warping, interactive visual analysis
SciVis
2015
Adaptive Multilinear Tensor Product Wavelets
10.1109/TVCG.2015.2467412
http://dx.doi.org/10.1109/TVCG.2015.2467412
985
994

J
Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.
Weiss, K.;Lindstrom, P.
Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;
10.1109/TVCG.2010.145;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183810;10.1109/TVCG.2011.252;10.1109/VISUAL.1996.568127;10.1109/TVCG.2009.186
Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction
SciVis
2015
An evaluation of three methods for visualizing uncertainty in architecture and archaeology
10.1109/SciVis.2015.7429507
http://dx.doi.org/10.1109/SciVis.2015.7429507
149
150

M
This project explores the representation of uncertainty in visualizations for archaeological research and provides insights obtained from user feedback. Our 3D models brought together information from standing architecture and excavated remains, surveyed plans, ground penetrating radar (GPR) data from the Carthusian monastery of Bourgfontaine in northern France. We also included information from comparative Carthusian sites and a bird's eye representation of the site in an early modern painting. Each source was assigned a certainty value which was then mapped to a color or texture for the model. Certainty values between one and zero were assigned by one subject matter expert and should be considered qualitative. Students and faculty from the fields of architectural history and archaeology at two institutions interacted with the models and answered a short survey with four questions about each. We discovered equal preference for color and transparency and a strong dislike for the texture model. Discoveries during model building also led to changes of the excavation plans for summer 2015.
S. Houde;S. Bonde;D. H. Laidlaw
Brown University|c|;;

Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction
SciVis
2015
AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics
10.1109/TVCG.2015.2467434
http://dx.doi.org/10.1109/TVCG.2015.2467434
747
756

J
In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.
Byska, J.;Le Muzic, M.;Gröller, M.E.;Viola, I.;Kozlikova, B.
Masaryk Univ., Brno, Czech Republic|c|;;;;
10.1109/VISUAL.2002.1183754;10.1109/TVCG.2009.136;10.1109/TVCG.2011.259;10.1109/VISUAL.2001.964540
Protein, tunnel, molecular dynamics, aggregation, interaction
SciVis
2015
Anisotropic Ambient Volume Shading
10.1109/TVCG.2015.2467963
http://dx.doi.org/10.1109/TVCG.2015.2467963
1015
1024

J
We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.
Ament, M.;Dachsbacher, C.
Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;
10.1109/TVCG.2014.2346333;10.1109/TVCG.2013.129;10.1109/TVCG.2014.2346411;10.1109/TVCG.2012.232;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2011.161;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183771;10.1109/TVCG.2011.198;10.1109/VISUAL.2004.5;10.1109/TVCG.2012.267;10.1109/VISUAL.1996.567777
Direct volume rendering, volume illumination, anisotropic shading
SciVis
2015
Association Analysis for Visual Exploration of Multivariate Scientific Data Sets
10.1109/TVCG.2015.2467431
http://dx.doi.org/10.1109/TVCG.2015.2467431
955
964

J
The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.
Xiaotong Liu;Han-Wei Shen
;
10.1109/TVCG.2013.133;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70615;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.165;10.1109/VAST.2012.6400488;10.1109/TVCG.2011.178;10.1109/VAST.2007.4389000
Multivariate data, association analysis, visual exploration, multiple views
SciVis
2015
Auto-Calibration of Multi-Projector Displays with a Single Handheld Camera
10.1109/SciVis.2015.7429493
http://dx.doi.org/10.1109/SciVis.2015.7429493
65
72

C
We present a novel approach that utilizes a simple handheld camera to automatically calibrate multi-projector displays. Most existing studies adopt active structured light patterns to verify the relationship between the camera and the projectors. The utilized camera is typically expensive and requires an elaborate installation process depending on the scalability of its applications. Moreover, the observation of the entire area by the camera is almost impossible for a small space surrounded by walls as there is not enough distance for the camera to capture the entire scene. We tackle these issues by requiring only a portion of the walls to be visible to a handheld camera that is widely used these days. This becomes possible by the introduction of our new structured light pattern scheme based on a perfect submap and a geometric calibration that successfully utilizes the geometric information of multi-planar environments. We demonstrate that immersive display in a small space such as an ordinary room can be effectively created using images captured by a handheld camera.
S. Park;H. Seo;S. Cha;J. Noh
KAIST|c|;;;
10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.1999.809883
Multivariate data, association analysis, visual exploration, multiple views
SciVis
2015
Automated visualization workflow for simulation experiments
10.1109/SciVis.2015.7429509
http://dx.doi.org/10.1109/SciVis.2015.7429509
153
154

M
Modeling and simulation is often used to predict future events and plan accordingly. Experiments in this domain often produce thousands of results from individual simulations, based on slightly varying input parameters. Geo-spatial visualizations can be a powerful tool to help health researchers and decision-makers to take measures during catastrophic and epidemic events such as Ebola outbreaks. The work produced a web-based geo-visualization tool to visualize and compare the spread of Ebola in the West African countries Ivory Coast and Senegal based on multiple simulation results. The visualization is not Ebola specific and may visualize any time-varying frequencies for given geo-locations.
J. P. Leidig;S. Dharmapuri
School of Computing and Information Systems, Grand Valley State University|c|;

Multivariate data, association analysis, visual exploration, multiple views
SciVis
2015
CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds
10.1109/TVCG.2015.2467202
http://dx.doi.org/10.1109/TVCG.2015.2467202
886
895

J
We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.
Lingyun Yu;Efstathiou, K.;Isenberg, P.;Isenberg, T.
Hangzhou Dianzi Univ., Hangzhou, China|c|;;;
10.1109/TVCG.2008.153;10.1109/VISUAL.1999.809932;10.1109/TVCG.2013.126;10.1109/TVCG.2012.292;10.1109/INFVIS.1996.559216;10.1109/TVCG.2012.217;10.1109/TVCG.2010.157
Selection, spatial selection, structure-aware selection, context-aware selection, exploratory data visualization and analysis, 3D interaction, user interaction
SciVis
2015
Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics
10.1109/TVCG.2015.2467203
http://dx.doi.org/10.1109/TVCG.2015.2467203
757
766

J
Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices.
Oeltze-Jafra, S.;Cebral, J.R.;Janiga, G.;Preim, B.
Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;
10.1109/TVCG.2009.138;10.1109/TVCG.2012.202;10.1109/TVCG.2014.2346406;10.1109/TVCG.2006.201;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.59;10.1109/TVCG.2006.199;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.2005.1532859
Blood Flow, Aneurysm, Clustering, Vortex Dynamics, Embedded Vortices
SciVis
2015
Correlation analysis in multidimensional multivariate time-varying datasets
10.1109/SciVis.2015.7429502
http://dx.doi.org/10.1109/SciVis.2015.7429502
139
140

M
One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area.
N. Abedzadeh
Mississippi State University|c|

Blood Flow, Aneurysm, Clustering, Vortex Dynamics, Embedded Vortices
SciVis
2015
CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees
10.1109/SciVis.2015.7429492
http://dx.doi.org/10.1109/SciVis.2015.7429492
57
64

C
We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.
I. Wald;A. Knoll;G. P. Johnson;W. Usher;V. Pascucci;M. E. Papka
Intel Corporation|c|;;;;;
10.1109/TVCG.2010.148;10.1109/TVCG.2009.142;10.1109/TVCG.2012.282
Ray tracing, Visualization, Particle Data, k-d Trees
SciVis
2015
Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis
10.1109/TVCG.2015.2467449
http://dx.doi.org/10.1109/TVCG.2015.2467449
867
876

J
Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.
Kindlmann, G.;Chiw, C.;Seltzer, N.;Samuels, L.;Reppy, J.
;;;;
10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2346322;10.1109/TVCG.2012.240;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809896;10.1109/TVCG.2007.70534;10.1109/TVCG.2014.2346318;10.1109/VISUAL.1998.745290;10.1109/TVCG.2008.148;10.1109/TVCG.2008.163
Domain specific language, portable parallel programming, scientific visualization, tensor fields
SciVis
2015
Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis
10.1109/TVCG.2015.2467436
http://dx.doi.org/10.1109/TVCG.2015.2467436
837
846

J
Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.
Dutta, S.;Han-Wei Shen
;
10.1109/TVCG.2007.70599;10.1109/VISUAL.1993.398877;10.1109/VISUAL.2004.107;10.1109/TVCG.2011.246;10.1109/TVCG.2007.70615;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2013.152;10.1109/TVCG.2014.2346423;10.1109/TVCG.2007.70579;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1998.745288;10.1109/TVCG.2008.163;10.1109/TVCG.2008.140
Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis
SciVis
2015
Effective Visualization of Temporal Ensembles
10.1109/TVCG.2015.2468093
http://dx.doi.org/10.1109/TVCG.2015.2468093
787
796

J
An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions.
Lihua Hao;Healey, C.G.;Bass, S.A.
;;
10.1109/TVCG.2014.2346448;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2014.2346751;10.1109/TVCG.2009.155;10.1109/TVCG.2014.2346455;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143
Ensemble visualization
SciVis
2015
Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces
10.1109/TVCG.2015.2467962
http://dx.doi.org/10.1109/TVCG.2015.2467962
926
934

J
Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits.
Butkiewicz, T.;Stevens, A.H.
Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA|c|;

Structured textures, terrain, deformation, dynamic surfaces
SciVis
2015
Explicit Frequency Control for High-Quality Texture-Based Flow Visualization
10.1109/SciVis.2015.7429490
http://dx.doi.org/10.1109/SciVis.2015.7429490
41
48

C
In this work we propose an effective method for frequency-controlled dense flow visualization derived from a generalization of the Line Integral Convolution (LIC) technique. Our approach consists in considering the spectral properties of the dense flow visualization process as an integral operator defined in a local curvilinear coordinate system aligned with the flow. Exploring LIC from this point of view, we suggest a systematic way to design a flow visualization process with particular local spatial frequency properties of the resulting image. Our method is efficient, intuitive, and based on a long-standing model developed as a result of numerous perception studies. The method can be described as an iterative application of line integral convolution, followed by a one-dimensional Gabor filtering orthogonal to the flow. To demonstrate the utility of the technique, we generated novel adaptive multi-frequency flow visualizations, that according to our evaluation, feature a higher level of frequency control and higher quality scores than traditional approaches in texture-based flow visualization.
V. Matvienko;J. Kr&#65533;&#65533;ger
Saarland University|c|;
10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70595;10.1109/TVCG.2006.161;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1996.567784;10.1109/VISUAL.2001.964505;10.1109/TVCG.2009.126;10.1109/VISUAL.1999.809892;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.2005.1532781
flow visualization, texture-based visualization, LIC, Gabor filter, spatial frequency, image contrast
SciVis
2015
Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data
10.1109/TVCG.2015.2466838
http://dx.doi.org/10.1109/TVCG.2015.2466838
827
836

J
We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.
Hanqi Guo;Phillips, C.L.;Peterka, T.;Karpeyev, D.;Glatz, A.
Math. & Comput. Sci. Div., Argonne Nat. Lab., Argonne, IL, USA|c|;;;;
10.1109/VISUAL.1994.346327;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.249;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2004.3;10.1109/TVCG.2012.212;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545
Superconductor, Vortex extraction, Feature tracking, Unstructured grid
SciVis
2015
Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers
10.1109/SciVis.2015.7429491
http://dx.doi.org/10.1109/SciVis.2015.7429491
49
56

C
Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.
V. Zobel;M. Stommel;G. Scheuermann
Leipzig University|c|;;
10.1109/VISUAL.1994.346326;10.1109/TVCG.2009.184;10.1109/VISUAL.1995.485141;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105
tensor visualization, feature-based visualisation, composite materials, structural mechanics
SciVis
2015
Gaze Stripes: Image-Based Visualization of Eye Tracking Data
10.1109/TVCG.2015.2468091
http://dx.doi.org/10.1109/TVCG.2015.2468091
1005
1014

J
We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques.
Kurzhals, K.;Hlawatsch, M.;Heimerl, F.;Burch, M.;Ertl, T.;Weiskopf, D.
;;;;;
10.1109/TVCG.2011.232;10.1109/TVCG.2012.276;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.194;10.1109/TVCG.2008.125
Eye tracking, time-dependent data, spatio-temporal visualization
SciVis
2015
Glyph-Based Comparative Visualization for Diffusion Tensor Fields
10.1109/TVCG.2015.2467435
http://dx.doi.org/10.1109/TVCG.2015.2467435
797
806

J
Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject.
Changgong Zhang;Schultz, T.;Lawonn, K.;Eisemann, E.;Vilanova, A.
;;;;
10.1109/TVCG.2015.2467031;10.1109/TVCG.2006.134;10.1109/TVCG.2010.134;10.1109/VISUAL.1998.745294;10.1109/VAST.2014.7042491;10.1109/TVCG.2010.199
Glyph Design, Comparative Visualization, Diffusion Tensor Field
SciVis
2015
High performance flow field visualization with high-order access dependencies
10.1109/SciVis.2015.7429515
http://dx.doi.org/10.1109/SciVis.2015.7429515
165
166

M
We present a novel model based on high-order access dependencies for high performance pathline computation in flow field. The high-order access dependencies are defined as transition probabilities from one data block to other blocks based on a few historical data accesses. Compared with existing methods which employed first-order access dependencies, our approach takes the advantages of high order access dependencies with higher accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing densely-seeded pathlines. The efficiency of our proposed approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method can achieve higher data locality than the first-order access dependencies based method, thereby reducing the I/O requests and improving the efficiency of pathline computation in various applications.
J. Zhang;H. Guo;X. Yuan
Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University|c|;;

Glyph Design, Comparative Visualization, Diffusion Tensor Field
SciVis
2015
In Situ Eddy Analysis in a High-Resolution Ocean Climate Model
10.1109/TVCG.2015.2467411
http://dx.doi.org/10.1109/TVCG.2015.2467411
857
866

J
An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements.
Woodring, J.;Petersen, M.;Schmeisser, A.;Patchett, J.;Ahrens, J.;Hagen, H.
Los Alamos Nat. Lab., Los Alamos, NM, USA|c|;;;;;
10.1109/TVCG.2008.143;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2010.215;10.1109/TVCG.2011.162
In situ analysis, online analysis, mesoscale eddies, ocean modeling, climate modeling, simulation, feature extraction,feature analysis, high performance computing, supercomputing, software engineering, collaborative development, revision control
SciVis
2015
Interactive Visualization for Singular Fibers of Functions f : R3 -> R2
10.1109/TVCG.2015.2467433
http://dx.doi.org/10.1109/TVCG.2015.2467433
945
954

J
Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R3->R2. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.
Sakurai, D.;Saeki, O.;Carr, H.;Hsiang-Yun Wu;Yamamoto, T.;Duke, D.;Takahashi, S.
Univ. of Tokyo & Japan Atomic Energy Agency, Kashiwa, Japan|c|;;;;;;
10.1109/TVCG.2008.119;10.1109/VISUAL.1997.663875;10.1109/TVCG.2012.287;10.1109/TVCG.2010.213;10.1109/TVCG.2014.2346447;10.1109/TVCG.2010.146;10.1109/VISUAL.2002.1183774;10.1109/TVCG.2008.143;10.1109/TVCG.2009.119;10.1109/TVCG.2007.70601
Singular fibers, fiber topology, mathematical visualization, design study
SciVis
2015
Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials
10.1109/TVCG.2015.2467432
http://dx.doi.org/10.1109/TVCG.2015.2467432
916
925

J
Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.
Gyulassy, A.;Knoll, A.;Chun Lau;Bei Wang
;;;
10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.244;10.1109/TVCG.2014.2346403;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2011.259
materials science, morse-smale, topology, Delaunay, computational geometry
SciVis
2015
Intuitive Exploration of Volumetric Data Using Dynamic Galleries
10.1109/TVCG.2015.2467294
http://dx.doi.org/10.1109/TVCG.2015.2467294
896
905

J
In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.
Jonsson, D.;Falk, M.;Ynnerman, A.
Linkoping Univ., Linkoping, Sweden|c|;;
10.1109/TVCG.2008.162;10.1109/TVCG.2011.261;10.1109/VISUAL.1996.568113;10.1109/TVCG.2012.231;10.1109/TVCG.2010.195;10.1109/TVCG.2011.224;10.1109/TVCG.2006.148;10.1109/TVCG.2011.218
Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces
SciVis
2015
Inviwo ??? An extensible, multi-purpose visualization framework
10.1109/SciVis.2015.7429514
http://dx.doi.org/10.1109/SciVis.2015.7429514
163
164

M
To enable visualization research impacting other scientific domains, the availability of easy-to-use visualization frameworks is essential. Nevertheless, an easy-to-use system also has to be adapted to the capabilities of modern hardware architectures, as only this allows for realizing interactive visualizations. With this trade-off in mind, we have designed and realized the cross-platform Inviwo (Interactive Visualization Workshop) visualization framework, that supports both interactive visualization research as well as efficient visualization application development and deployment. In this poster we give an overview of the architecture behind Inviwo, and show how its design enables us and other researchers to realize their visualization ideas efficiently. Inviwo consists of a modern and lightweight, graphics independent core, which is extended by optional modules that encapsulate visualization algorithms, well-known utility libraries and commonly used parallel-processing APIs (such as OpenGL and OpenCL). The core enables a simplistic structure for creating bridges between the different modules regarding data transfer across architecture and devices with an easy-to-use screen graph and minimalistic programming. Making the base structures in a modern way while providing intuitive methods of extending the functionality and creating modules based on other modules, we hope that Inviwo can help the visualization community to perform research through a rapid-prototyping design and GUI, while at the same time allowing users to take advantage of the results implemented in the system in any way they desire later on. Inviwo is publicly available at www.inviwo.org, and can be used freely by anyone under a permissive free software license (Simplified BSD).
E. Sund&#65533;&#65533;n;P. Steneteg;S. Kottravel;D. J&#65533;&#65533;nsson;R. Englund;M. Falk;T. Ropinski
Linkoping University|c|;;;;;;

Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces
SciVis
2015
Isosurface Visualization of Data with Nonparametric Models for Uncertainty
10.1109/TVCG.2015.2467958
http://dx.doi.org/10.1109/TVCG.2015.2467958
777
786

J
The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields.
Athawale, T.;Sakhaee, E.;Entezari, A.
Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|;;
10.1109/TVCG.2013.208;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2013.152;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/TVCG.2013.143
Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes, nonparametric statistics
SciVis
2015
JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure
10.1109/TVCG.2015.2467331
http://dx.doi.org/10.1109/TVCG.2015.2467331
1025
1034

J
Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.
Labschütz, M.;Bruckner, S.;Gröller, M.E.;Hadwiger, M.;Rautek, P.
;;;;
10.1109/TVCG.2012.240
Data Transformation and Representation, GPUs and Multi-core Architectures, Volume Rendering
SciVis
2015
Mining Graphs for Understanding Time-Varying Volumetric Data
10.1109/TVCG.2015.2468031
http://dx.doi.org/10.1109/TVCG.2015.2468031
965
974

J
A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.
Yi Gu;Chaoli Wang;Peterka, T.;Jacob, R.;Seung Hyun Kim
Dept. Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA|c|;;;;
10.1109/TVCG.2009.122;10.1109/TVCG.2013.151;10.1109/TVCG.2011.246;10.1109/TVCG.2008.116;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/TVCG.2009.165;10.1109/TVCG.2006.159
Time-varying data visualization, graph simplification, community detection, visual recommendation
SciVis
2015
Multi-field Pattern Matching based on Sparse Feature Sampling
10.1109/TVCG.2015.2467292
http://dx.doi.org/10.1109/TVCG.2015.2467292
807
816

J
We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.
Zhongjie Wang;Seidel, H.-P.;Weinkauf, T.
MPI for Inf., Saarbrucken, Germany|c|;;
10.1109/VISUAL.2003.1250372;10.1109/TVCG.2009.141;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70579;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.236
Pattern matching, multi-field visualization
SciVis
2015
Multiresolution visualization of digital earth data via hexagonal box-spline wavelets
10.1109/SciVis.2015.7429508
http://dx.doi.org/10.1109/SciVis.2015.7429508
151
152

M
Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs.
M. I. Jubair;U. Alim;N. Roeber;J. Clyne;A. Mahdavi-Amiri;F. Samavati
University of Calgary|c|;;;;;

Pattern matching, multi-field visualization
SciVis
2015
NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects
10.1109/TVCG.2015.2467441
http://dx.doi.org/10.1109/TVCG.2015.2467441
738
746

J
In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.
Al-Awami, A.K.;Beyer, J.;Haehn, D.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.
;;;;;;
10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2013.174;10.1109/TVCG.2014.2346249;10.1109/TVCG.2007.70584
Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking
SciVis
2015
Occlusion-free Blood Flow Animation with Wall Thickness Visualization
10.1109/TVCG.2015.2467961
http://dx.doi.org/10.1109/TVCG.2015.2467961
728
737

J
We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.
Lawonn, K.;Glaßer, S.;Vilanova, A.;Preim, B.;Isenberg, T.
Univ. of Magdeburg, Magdeburg, Germany|c|;;;;
10.1109/TVCG.2009.138;10.1109/TVCG.2011.243;10.1109/TVCG.2014.2346406;10.1109/TVCG.2010.153;10.1109/TVCG.2011.215;10.1109/VISUAL.2004.48
Medical visualization, aneurysms, blood flow, wall thickness, illustrative visualization
SciVis
2015
OpenSpace: Public dissemination of space mission profiles
10.1109/SciVis.2015.7429503
http://dx.doi.org/10.1109/SciVis.2015.7429503
141
142

M
This work presents a visualization system and its application to space missions. The system allows the public to disseminate the scientific findings of space craft and gain a greater understanding thereof. Instruments' field-of-views and their measurements are embedded in an accurate 3 dimensional rendering of the solar system to provide context to past measurements or the planning of future events. We tested our system with NASA's New Horizons at the Pluto Pallooza event in New York and will expose it to the greater public on the upcoming July 14th Pluto flyby.
A. Bock;M. Marcinkowski;J. Kilby;C. Emmart;A. Ynnerman
Link&#65533;&#65533;ping University|c|;;;;

Medical visualization, aneurysms, blood flow, wall thickness, illustrative visualization
SciVis
2015
PathlinesExplorer ??? Image-based exploration of large-scale pathline fields
10.1109/SciVis.2015.7429512
http://dx.doi.org/10.1109/SciVis.2015.7429512
159
160

M
PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.
O. H. Nagoor;M. Hadwiger;M. Srinivasan
KAUST|c|;;

Medical visualization, aneurysms, blood flow, wall thickness, illustrative visualization
SciVis
2015
Planar Visualization of Treelike Structures
10.1109/TVCG.2015.2467413
http://dx.doi.org/10.1109/TVCG.2015.2467413
906
915

J
We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study.
Marino, J.;Kaufman, A.
;
10.1109/TVCG.2011.235;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.192;10.1109/TVCG.2014.2346406;10.1109/VISUAL.2001.964538;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2011.182;10.1109/TVCG.2006.172
Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces
SciVis
2015
Real-time interactive time correction on the GPU
10.1109/SciVis.2015.7429505
http://dx.doi.org/10.1109/SciVis.2015.7429505
145
146

M
The study of physical phenomena and their dynamic evolution is supported by the analysis and visualization of time-enabled data. In many applications, available data are sparsely distributed in the space-time domain, which leads to incomprehensible visualizations. We present an interactive approach for the dynamic tracking and visualization of measured data particles through advection in a simulated flow. We introduce a fully GPU-based technique for efficient spatio-temporal interpolation, using a kd-tree forest for acceleration. As the user interacts with the system using a time slider, particle positions are reconstructed for the time selected by the user. Our results show that the proposed technique achieves highly accurate parallel tracking for thousands of particles. The rendering performance is mainly affected by the size of the query set.
M. Elshehaly;D. Gra&#65533;&#65533;anin;M. Gad;J. Wang;H. G. Elmongui
Virginia Tech|c|;;;;

Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces
SciVis
2015
Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion
10.1109/TVCG.2015.2467293
http://dx.doi.org/10.1109/TVCG.2015.2467293
718
727

J
Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations.
Skanberg, R.;Vazquez, P.-P.;Guallar, V.;Ropinski, T.
;;;
10.1109/TVCG.2007.70578;10.1109/TVCG.2009.168;10.1109/TVCG.2007.70517;10.1109/TVCG.2012.282;10.1109/TVCG.2009.157;10.1109/TVCG.2014.2346404;10.1109/TVCG.2006.115
Molecular visualization, diffuse interreflections, ambient occlusion
SciVis
2015
Real-time Uncertainty Visualization for B-Mode Ultrasound
10.1109/SciVis.2015.7429489
http://dx.doi.org/10.1109/SciVis.2015.7429489
33
40

C
B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.
C. S. Z. Berge;D. Declara;C. Hennersperger;M. Baust;N. Navab
;;;;
10.1109/VISUAL.2001.964550;10.1109/TVCG.2006.134;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.279;10.1109/TVCG.2009.114
Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time
SciVis
2015
Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow
10.1109/TVCG.2015.2467291
http://dx.doi.org/10.1109/TVCG.2015.2467291
995
1004

J
Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos.
Kappe, C.P.;Schutz, L.;Gunther, S.;Hufnagel, L.;Lemke, S.;Leitte, H.
IWR, Heidelberg Univ., Heidelberg, Germany|c|;;;;;
10.1109/TVCG.2010.169;10.1109/VISUAL.1996.567784;10.1109/TVCG.2009.190;10.1109/VISUAL.2003.1250364;10.1109/VISUAL.1997.663898;10.1109/VISUAL.2003.1250363
Cell migration, vector field, 3D, timedependent,LIC, tracking, validation
SciVis
2015
Rotation Invariant Vortices for Flow Visualization
10.1109/TVCG.2015.2467200
http://dx.doi.org/10.1109/TVCG.2015.2467200
817
826

J
We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.
Gunther, T.;Schulze, M.;Theisel, H.
;;
10.1109/TVCG.2014.2346415;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2014.2346412;10.1109/TVCG.2011.249;10.1109/TVCG.2013.189;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198
Vortex cores, rotation invariance, Galilean invariance, scientific visualization, flow visualization, line fields
SciVis
2015
Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles
10.1109/TVCG.2015.2467204
http://dx.doi.org/10.1109/TVCG.2015.2467204
767
776

J
We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.
Ferstl, F.;Bürger, K.;Westermann, R.
Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;
10.1109/TVCG.2007.70595;10.1109/VISUAL.2000.885715;10.1109/VISUAL.1999.809863;10.1109/TVCG.2013.141;10.1109/TVCG.2007.70518;10.1109/TVCG.2014.2346455;10.1109/VISUAL.2005.1532779;10.1109/TVCG.2010.181;10.1109/VISUAL.1999.809865;10.1109/TVCG.2013.143
Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling
SciVis
2015
TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data
10.1109/TVCG.2015.2467194
http://dx.doi.org/10.1109/TVCG.2015.2467194
935
944

J
Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.
Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Ni, L.M.
;;;;;;;
10.1109/VAST.2010.5652478;10.1109/TVCG.2013.193;10.1109/TVCG.2014.2346276;10.1109/TVCG.2013.226;10.1109/TVCG.2011.166;10.1109/TVCG.2013.173;10.1109/TVCG.2014.2346271;10.1109/VAST.2011.6102455;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346665;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/VAST.2014.7042490;10.1109/TVCG.2014.2346922
Co-occurrence, human mobility, telco data, bicluster, visual analytics
SciVis
2015
Using Maximum Topology Matching to Explore Differences in Species Distribution Models
10.1109/SciVis.2015.7429486
http://dx.doi.org/10.1109/SciVis.2015.7429486
9
16

C
Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.
J. Poco;H. Doraiswamy;M. Talbert;J. Morisette;C. T. Silva
New York University|c|;;;;
10.1109/TVCG.2011.244;10.1109/TVCG.2010.213;10.1109/TVCG.2008.145;10.1109/TVCG.2009.155;10.1109/TVCG.2013.125;10.1109/TVCG.2008.143;10.1109/TVCG.2011.236;10.1109/TVCG.2013.148;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.248;10.1109/TVCG.2007.70601
Function similarity, computational topology, species distribution models, persistence, high dimensional visualization
SciVis
2015
Visual Verification of Space Weather Ensemble Simulations
10.1109/SciVis.2015.7429487
http://dx.doi.org/10.1109/SciVis.2015.7429487
17
24

C
We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.
A. Bock;A. Pembroke;M. L. Mays;L. Rastaetter;T. Ropinski;A. Ynnerman
Linkoping University|c|;;;;;
10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143
Visual Verification, Space Weather, Coronal Mass Ejections, Ensemble
SciVis
2015
Visualization and Analysis of Rotating Stall for Transonic Jet Engine Simulation
10.1109/TVCG.2015.2467952
http://dx.doi.org/10.1109/TVCG.2015.2467952
847
856

J
Identification of early signs of rotating stall is essential for the study of turbine engine stability. With recent advancements of high performance computing, high-resolution unsteady flow fields allow in depth exploration of rotating stall and its possible causes. Performing stall analysis, however, involves significant effort to process large amounts of simulation data, especially when investigating abnormalities across many time steps. In order to assist scientists during the exploration process, we present a visual analytics framework to identify suspected spatiotemporal regions through a comparative visualization so that scientists are able to focus on relevant data in more detail. To achieve this, we propose efficient stall analysis algorithms derived from domain knowledge and convey the analysis results through juxtaposed interactive plots. Using our integrated visualization system, scientists can visually investigate the detected regions for potential stall initiation and further explore these regions to enhance the understanding of this phenomenon. Positive feedback from scientists demonstrate the efficacy of our system in analyzing rotating stall.
Chun-Ming Chen;Dutta, S.;Xiaotong Liu;Heinlein, G.;Han-Wei Shen;Jen-Ping Chen
Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA|c|;;;;;
10.1109/VISUAL.1991.175794;10.1109/TVCG.2007.70599;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.122;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.128;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2014.2346265
Turbine flow visualization, vortex extraction, anomaly detection, juxtaposition, brushing and linking, time series
SciVis
2015
Visualization-by-Sketching: An Artist&#x0027;s Interface for Creating Multivariate Time-Varying Data Visualizations
10.1109/TVCG.2015.2467153
http://dx.doi.org/10.1109/TVCG.2015.2467153
877
885

J
We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data ΓÇ£underΓÇ¥ the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay ΓÇ£in the creative zoneΓÇ¥ as they work.
Schroeder, D.;Keefe, D.F.
;
10.1109/VAST.2008.4677356;10.1109/TVCG.2009.181;10.1109/TVCG.2013.124;10.1109/TVCG.2011.202;10.1109/TVCG.2008.153;10.1109/TVCG.2013.226;10.1109/TVCG.2014.2346271;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2009.145;10.1109/TVCG.2010.162;10.1109/INFVIS.2001.963286;10.1109/TVCG.2011.181;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346441
Visualization design, multivariate, art, sketch, color map, glyph
SciVis
2015
Visualizing 3D flow through cutting planes
10.1109/SciVis.2015.7429513
http://dx.doi.org/10.1109/SciVis.2015.7429513
161
162

M
Studies have found conflicting results regarding the effectiveness of tube-like structures for representing 3D flow data. This paper presents the findings of a small-scale pilot study contrasting static monoscopic depth cues to ascertain their importance in perceiving the orientation of a three-dimensional glyph with respect to a cutting plane. A simple striped texture and shading were found to reduce judgement errors when used with a 3D tube glyph as compared to plain or shaded line glyphs. A discussion of considerations for a full-scale study and possible future work follows.
C. Ware;A. H. Stevens
University of New Hampshire|c|;

Visualization design, multivariate, art, sketch, color map, glyph
SciVis
2015
Visualizing crossing probabilistic tracts
10.1109/SciVis.2015.7429506
http://dx.doi.org/10.1109/SciVis.2015.7429506
147
148

M
Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.
M. Goldau;A. Reichenbach;M. Hlawitschka
Leipzig University|c|;;

Visualization design, multivariate, art, sketch, color map, glyph
SciVis
2015
Visualizing Tensor Normal Distributions at Multiple Levels of Detail
10.1109/TVCG.2015.2467031
http://dx.doi.org/10.1109/TVCG.2015.2467031
975
984

J
Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.
Abbasloo, A.;Wiens, V.;Hermann, M.;Schultz, T.
Univ. of Bonn, Bonn, Germany|c|;;;
10.1109/TVCG.2009.170;10.1109/TVCG.2009.184;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.181;10.1109/TVCG.2006.134;10.1109/TVCG.2010.199;10.1109/TVCG.2008.128;10.1109/TVCG.2007.70602;10.1109/TVCG.2015.2467435
Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization
VAST
2015
3D Regression Heat Map Analysis of Population Study Data
10.1109/TVCG.2015.2468291
http://dx.doi.org/10.1109/TVCG.2015.2468291
81
90

J
Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject's lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease.
Klemm, P.; Lawonn, K.; Glaßer, S.;Niemann, U.;Hegenscheid,K.;Völzke,H.;Preim,B.
Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany
10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/VAST.2009.5333431;10.1109/TVCG.2013.160;10.1109/TVCG.2014.2346591;10.1109/TVCG.2013.161;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321
Interactive Visual Analysis, Regression Analysis, Heat Map, Epidemiology, Breast Cancer, Hepatic Steatosis
VAST
2015
A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights
10.1109/TVCG.2015.2467613
http://dx.doi.org/10.1109/TVCG.2015.2467613
51
60

J
We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors.
Hua Guo;Gomez, S.R.;Ziemkiewicz, C.;Laidlaw, D.H.
;;;
10.1109/INFVIS.2005.1532136;10.1109/TVCG.2014.2346575;10.1109/VAST.2014.7042482;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346452;10.1109/TVCG.2012.221;10.1109/TVCG.2007.70515
Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation
VAST
2015
A software developer's guide to informal evaluation of Visual Analytics environments using VAST Challenge information
10.1109/VAST.2015.7347674
http://dx.doi.org/10.1109/VAST.2015.7347674
193
194
x
M
The VAST Challenge has been a popular venue for academic and industry participants for over ten years. Many participants comment that the majority of their time in preparing VAST Challenge entries is discovering elements in their software environments that need to be redesigned in order to solve the given task. Fortunately, there is no need to wait until the VAST Challenge is announced to test out software systems. The Visual Analytics Benchmark Repository contains all past VAST Challenge tasks, data, solutions and submissions. In this poster we describe how developers can perform informal evaluations of various aspects of their visual analytics environments using VAST Challenge information.
Cook, K.A.;Scholtz, J.;Whiting, M.A.
;;

Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation
VAST
2015
A System for visual exploration of caution spots from vehicle recorder data
10.1109/VAST.2015.7347677
http://dx.doi.org/10.1109/VAST.2015.7347677
199
200
x
M
It is vital for the transportation industry, which performs most of its work by automobiles, to reduce its accident rate. This paper proposes a 3D visual interaction method for exploring caution areas from large-scale vehicle recorder data. Our method provides (i) a flexible filtering interface for driving operations such as braking or handling operations by various combinations of their attribute values such as velocity and acceleration, and (ii) a 3D visual environment for spatio-temporal exploration of caution areas. The proposed method was able to extract caution areas where some accidents have actually occurred or that are on very narrow roads with bad visibility by using real data given by one of the biggest transportation companies in Japan.
Itoh, M.;Yokoyama, D.;Toyoda, M.;Kitsuregawa, M.
;;;

Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation
VAST
2015
An Uncertainty-Aware Approach for Exploratory Microblog Retrieval
10.1109/TVCG.2015.2467554
http://dx.doi.org/10.1109/TVCG.2015.2467554
250
259

J
Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.
Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan
;;;;;
10.1109/TVCG.2013.186;10.1109/TVCG.2012.291;10.1109/VAST.2009.5332611;10.1109/TVCG.2013.223;10.1109/TVCG.2011.233;10.1109/VAST.2014.7042494;10.1109/VISUAL.1996.568116;10.1109/INFVIS.2005.1532150;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.197;10.1109/TVCG.2014.2346919;10.1109/TVCG.2013.232;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346920;10.1109/TVCG.2010.183;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346922
microblog data, mutual reinforcement model, uncertainty modeling, uncertainty visualization, uncertainty propagation
VAST
2015
BiSet: Semantic Edge Bundling with Biclusters for Sensemaking
10.1109/TVCG.2015.2467813
http://dx.doi.org/10.1109/TVCG.2015.2467813
310
319

J
Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, ΓÇ£in-betweenΓÇ¥, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.
Maoyuan Sun;Peng Mi;North, C.;Ramakrishnan, N.
;;;
10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2008.135;10.1109/TVCG.2012.252;10.1109/TVCG.2012.260;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346260;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/VAST.2009.5333878;10.1109/TVCG.2011.250;10.1109/TVCG.2010.138;10.1109/TVCG.2014.2346752;10.1109/TVCG.2010.210;10.1109/TVCG.2011.183;10.1109/TVCG.2014.2346665
Bicluster, coordinated relationship, semantic edge bundling
VAST
2015
Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes
10.1109/TVCG.2015.2467551
http://dx.doi.org/10.1109/TVCG.2015.2467551
31
40

J
While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.
Ragan, E.D.;Endert, A.;Sanyal, J.;Jian Chen
;;;
10.1109/INFVIS.2005.1532136;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.155;10.1109/VISUAL.1993.398857;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5652932;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/TVCG.2013.126;10.1109/VAST.2009.5333020;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.271;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677366;10.1109/TVCG.2013.130;10.1109/TVCG.2010.181;10.1109/TVCG.2010.179;10.1109/VISUAL.1990.146375
Provenance, Analytic provenance, Visual analytics, Framework, Visualization, Conceptual model
VAST
2015
CiteRivers: Visual Analytics of Citation Patterns
10.1109/TVCG.2015.2467621
http://dx.doi.org/10.1109/TVCG.2015.2467621
190
199

J
The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.
Heimerl, F.;Qi Han;Koch, S.
;;
10.1109/INFVIS.2004.77;10.1109/TVCG.2015.2467757;10.1109/TVCG.2008.166;10.1109/TVCG.2013.212;10.1109/VAST.2009.5333443;10.1109/TVCG.2011.239;10.1109/TVCG.2012.252;10.1109/TVCG.2013.162;10.1109/TVCG.2012.277;10.1109/INFVIS.2004.45;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.162;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1995.528686;10.1109/TVCG.2014.2346920;10.1109/TVCG.2009.202
scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering
VAST
2015
Collaborative visual analysis with RCloud
10.1109/VAST.2015.7347627
http://dx.doi.org/10.1109/VAST.2015.7347627
25
32

C
Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.
North, S.;Scheidegger, C.;Urbanek, S.;Woodhull, G.
Infovisible, USA|c|;;;
10.1109/TVCG.2011.185;10.1109/VAST.2007.4389011;10.1109/TVCG.2012.219;10.1109/TVCG.2009.195;10.1109/TVCG.2007.70577
visual analytics process, provenance, collaboration, visualization, computer-supported cooperative work
VAST
2015
Comparative visual analysis of vector field ensembles
10.1109/VAST.2015.7347634
http://dx.doi.org/10.1109/VAST.2015.7347634
81
88

C
We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison.
Jarema, M.;Demir, I.;Kehrer, J.;Westermann, R.
Tech. Univ. Munchen, Mu&#x0308;nchen, Germany|c|;;;
10.1109/TVCG.2014.2346626;10.1109/TVCG.2010.190;10.1109/VAST.2009.5332611;10.1109/TVCG.2006.160;10.1109/TVCG.2013.141;10.1109/TVCG.2013.177;10.1109/TVCG.2010.199;10.1109/TVCG.2014.2346321
Uncertainty Visualization, Vector Field Data, Coordinated and Multiple Views, Glyph-based Techniques
VAST
2015
DemographicVis: Analyzing demographic information based on user generated content
10.1109/VAST.2015.7347631
http://dx.doi.org/10.1109/VAST.2015.7347631
57
64

C
The wide-spread of social media provides unprecedented sources of written language that can be used to model and infer online demographics. In this paper, we introduce a novel visual text analytics system, DemographicVis, to aid interactive analysis of such demographic information based on user-generated content. Our approach connects categorical data (demographic information) with textual data, allowing users to understand the characteristics of different demographic groups in a transparent and exploratory manner. The modeling and visualization are based on ground truth demographic information collected via a survey conducted on Reddit.com. Detailed user information is taken into our modeling process that connects the demographic groups with features that best describe the distinguishing characteristics of each group. Features including topical and linguistic are generated from the user-generated contents. Such features are then analyzed and ranked based on their ability to predict the users' demographic information. To enable interactive demographic analysis, we introduce a web-based visual interface that presents the relationship of the demographic groups, their topic interests, as well as the predictive power of various features. We present multiple case studies to showcase the utility of our visual analytics approach in exploring and understanding the interests of different demographic groups. We also report results from a comparative evaluation, showing that the DemographicVis is quantitatively superior or competitive and subjectively preferred when compared to a commercial text analysis tool.
Wenwen Dou;Cho, I.;ElTayeby, O.;Jaegul Choo;Xiaoyu Wang;Ribarsky, W.
UNC, Charlotte, NC, USA|c|;;;;;
10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102461;10.1109/TVCG.2014.2346920
Visual Text Analysis, User Interface, Social Media, Demographic Analysis
VAST
2015
EgoNetCloud: Event-based egocentric dynamic network visualization
10.1109/VAST.2015.7347632
http://dx.doi.org/10.1109/VAST.2015.7347632
65
72

C
Event-based egocentric dynamic networks are an important class of networks widely seen in many domains. In this paper, we present a visual analytics approach for these networks by combining data-driven network simplifications with a novel visualization design - EgoNetCloud. In particular, an integrated data processing pipeline is proposed to prune, compress and filter the networks into smaller but salient abstractions. To accommodate the simplified network into the visual design, we introduce a constrained graph layout algorithm on the dynamic network. Through a real-life case study as well as conversations with the domain expert, we demonstrate the effectiveness of the EgoNetCloud design and system in completing analysis tasks on event-based dynamic networks. The user study comparing EgoNetCloud with a working system on academic search confirms the effectiveness and convenience of our visual analytics based approach.
Qingsong Liu;Yifan Hu;Lei Shi;Xinzhu Mu;Yutao Zhang;Jie Tang
SKLCS, Inst. of Software, Beijing, China|c|;;;;;
10.1109/TVCG.2010.159;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213
Visual Text Analysis, User Interface, Social Media, Demographic Analysis
VAST
2015
egoSlider: Visual Analysis of Egocentric Network Evolution
10.1109/TVCG.2015.2468151
http://dx.doi.org/10.1109/TVCG.2015.2468151
260
269

J
Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.
Yanhong Wu;Pitipornvivat, N.;Jian Zhao;Sixiao Yang;Guowei Huang;Huamin Qu
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;
10.1109/TVCG.2011.169;10.1109/TVCG.2011.226;10.1109/TVCG.2006.147;10.1109/TVCG.2013.149
Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics
VAST
2015
Evolution inspector: Interactive visual analysis for evolutionary molecular design
10.1109/VAST.2015.7347687
http://dx.doi.org/10.1109/VAST.2015.7347687
219
220
x
M
De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.
Solteszova, V.;Foscato, M.;Eliasson, S.H.;Jensen, V.R.
Christian Michelsen Res., Bergen, Norway|c|;;;

Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics
VAST
2015
Exploring Evolving Media Discourse Through Event Cueing
10.1109/TVCG.2015.2467991
http://dx.doi.org/10.1109/TVCG.2015.2467991
220
229

J
Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.
Yafeng Lu;Steptoe, M.;Burke, S.;Hong Wang;Jiun-Yi Tsai;Davulcu, H.;Montgomery, D.;Corman, S.R.;Maciejewski, R.
;;;;;;;;
10.1109/TVCG.2013.222;10.1109/VAST.2011.6102488;10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/VAST.2008.4677364;10.1109/TVCG.2014.2346682;10.1109/VAST.2014.7042484;10.1109/TVCG.2011.179;10.1109/VAST.2014.7042494;10.1109/VAST.2012.6400491;10.1109/VAST.2009.5333919;10.1109/INFVIS.1999.801851;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346913
Media Analysis, Time Series Analysis, Event Detection
VAST
2015
FeatureInsight: Visual support for error-driven feature ideation in text classification
10.1109/VAST.2015.7347637
http://dx.doi.org/10.1109/VAST.2015.7347637
105
112

C
Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research.
Brooks, M.;Amershi, S.;Bongshin Lee;Drucker, S.M.;Kapoor, A.;Simard, P.
Univ. of Washington, Seattle, WA, USA|c|;;;;;
10.1109/VAST.2010.5652443
Media Analysis, Time Series Analysis, Event Detection
VAST
2015
Four considerations for supporting visual analysis in display ecologies
10.1109/VAST.2015.7347628
http://dx.doi.org/10.1109/VAST.2015.7347628
33
40

C
The current proliferation of large displays and mobile devices presents a number of exciting opportunities for visual analytics and information visualization. The display ecology enables multiple displays to function in concert within a broader technological environment to accomplish visual analysis tasks. Based on a comprehensive survey of multi-display systems from a variety of fields, we propose four key considerations for visual analysis in display ecologies: 1) Display Composition, 2) Information Coordination/Transfer, 3) Information Connection, and 4) Display Membership. Different aspects of display ecologies stemming from these design considerations will enable users to transform and empower multiple displays as a display ecology for visual analysis.
Haeyong Chung;North, C.;Joshi, S.;Jian Chen
Univ. of Alabama Huntsville, Huntsville, AL, USA|c|;;;
10.1109/VAST.2008.4677358
Media Analysis, Time Series Analysis, Event Detection
VAST
2015
FPSSeer: Visual analysis of game frame rate data
10.1109/VAST.2015.7347633
http://dx.doi.org/10.1109/VAST.2015.7347633
73
80

C
The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers.
Quan Li;Peng Xu;Huamin Qu
NetEase Games, NetEase, Inc., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;
10.1109/TVCG.2008.166;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346445;10.1109/INFVIS.2001.963273
frame rate data, game performance evaluation, visual analytics
VAST
2015
HTMVS: Visualizing hierarchical topics and their evolution
10.1109/VAST.2015.7347675
http://dx.doi.org/10.1109/VAST.2015.7347675
195
196
x
M
Topic model has been an active research area for many years, it can be used for discovering latent semantics and finding hidden knowledge in unstructured data corpus. In this paper, we investigated the problems in visualizing hierarchical topic and their evolution. The contribution of this paper is threefold, first we explore the static visualization of hierarchical topics using the `nested circle' layout, and then in order to present the topic evolution over time, we extended a hierarchical topic model and employ topic transformation visualizations to track the arising, splitting and disappearing of certain topics under the dynamic topical hierarchy. Finally, a Hierarchical Topic Model Visualization System (HTMVS) is designed to take advantage of both static and dynamic hierarchical topic visualization.
Haoling Dong;Siliang Tang;Si Li;Fei Wu;Yueting Zhuang
Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China|c|;;;;

frame rate data, game performance evaluation, visual analytics
VAST
2015
Integrating predictive analytics into a spatiotemporal epidemic simulation
10.1109/VAST.2015.7347626
http://dx.doi.org/10.1109/VAST.2015.7347626
17
24

C
The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.
Bryan, C.;Xue Wu;Mniszewski, S.;Kwan-Liu Ma
VIDi @ U.C. Davis, Davis, CA, USA|c|;;;
10.1109/VAST.2011.6102457;10.1109/INFVIS.1998.729563;10.1109/TVCG.2014.2346926;10.1109/TVCG.2013.125;10.1109/TVCG.2010.181;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2012.190
Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems
VAST
2015
Interactive semi-automatic categorization for spinel group minerals
10.1109/VAST.2015.7347676
http://dx.doi.org/10.1109/VAST.2015.7347676
197
198
x
M
Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.
Lujan Ganuza, M.;Gargiulo, F.;Ferracutti, G.;Castro, S.;Bjerg, E.;Groller, E.;Matkovic, K.
VyGLab, UNS, Bahia Blanca, Argentina|c|;;;;;;

Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems
VAST
2015
Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data
10.1109/TVCG.2015.2467619
http://dx.doi.org/10.1109/TVCG.2015.2467619
270
279

J
Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.
Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Zhang;Jiawan Zhang
;;;;;;;
10.1109/VAST.2009.5332584;10.1109/VAST.2008.4677356;10.1109/TVCG.2009.182;10.1109/TVCG.2011.185;10.1109/TVCG.2012.291;10.1109/TVCG.2009.143;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346746;10.1109/TVCG.2014.2346922
Spatial temporal visual analytics, Geo-tagged social media, Sparsely sampling, Uncertainty, Movement
VAST
2015
Interactive Visual Profiling of Musicians
10.1109/TVCG.2015.2467620
http://dx.doi.org/10.1109/TVCG.2015.2467620
200
209

J
Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.
Jänicke, S.;Focht, J.;Scheuermann, G.
Image & Signal Process. Group, Leipzig Univ., Leipzig, Germany|c|;;
10.1109/VAST.2011.6102454;10.1109/TVCG.2010.159;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/VAST.2009.5333443;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.175;10.1109/TVCG.2012.252;10.1109/VAST.2012.6400485;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2009.111;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333023;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333248;10.1109/VAST.2008.4677370;10.1109/VAST.2010.5652520
visual analytics, profiling system, musicians database visualization, digital humanities, musicology
VAST
2015
Interactive visual steering of hierarchical simulation ensembles
10.1109/VAST.2015.7347635
http://dx.doi.org/10.1109/VAST.2015.7347635
89
96

C
Multi-level simulation models, i.e., models where different components are simulated using sub-models of varying levels of complexity, belong to the current state-of-the-art in simulation. The existing analysis practice for multi-level simulation results is to manually compare results from different levels of complexity, amounting to a very tedious and error-prone, trial-and-error exploration process. In this paper, we introduce hierarchical visual steering, a new approach to the exploration and design of complex systems. Hierarchical visual steering makes it possible to explore and analyze hierarchical simulation ensembles at different levels of complexity. At each level, we deal with a dynamic simulation ensemble - the ensemble grows during the exploration process. There is at least one such ensemble per simulation level, resulting in a collection of dynamic ensembles, analyzed simultaneously. The key challenge is to map the multi-dimensional parameter space of one ensemble to the multi-dimensional parameter space of another ensemble (from another level). In order to support the interactive visual analysis of such complex data we propose a novel approach to interactive and semi-automatic parameter space segmentation and comparison. The approach combines a novel interaction technique and automatic, computational methods - clustering, concave hull computation, and concave polygon overlapping - to support the analysts in the cross-ensemble parameter space mapping. In addition to the novel parameter space segmentation we also deploy coordinated multiple views with standard plots. We describe the abstract analysis tasks, identified during a case study, i.e., the design of a variable valve actuation system of a car engine. The study is conducted in cooperation with experts from the automotive industry. Very positive feedback indicates the usefulness and efficiency of the newly proposed approach.
Splechtna, R.;Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.
VRVis Res. Center in Vienna, Vienna, Austria|c|;;;;
10.1109/TVCG.2008.145;10.1109/TVCG.2014.2346744;10.1109/TVCG.2014.2346321;10.1109/VAST.2009.5333081;10.1109/TVCG.2010.223
Interactive Visual Analysis, Simulation-Ensemble Steering, Multi-resolution simulation
VAST
2015
InterAxis: Steering Scatterplot Axes via Observation-Level Interaction
10.1109/TVCG.2015.2467615
http://dx.doi.org/10.1109/TVCG.2015.2467615
131
140

J
Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.
Hannah Kim;Jaegul Choo;Haesun Park;Endert, A.
;;;
10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.212;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.201;10.1109/TVCG.2008.153;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346250;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.178;10.1109/TVCG.2013.167
Scatterplots, user interaction, model steering
VAST
2015
iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data
10.1109/VAST.2015.7347630
http://dx.doi.org/10.1109/VAST.2015.7347630
49
56

C
Using transport smart card transaction data to understand the homework dynamics of a city for urban planning is emerging as an alternative to traditional surveys which may be conducted every few years are no longer effective and efficient for the rapidly transforming modern cities. As commuters travel patterns are highly diverse, existing rule-based methods are not fully adequate. In this paper, we present iVizTRANS - a tool which combines an interactive visual analytics (VA) component to aid urban planners to analyse complex travel patterns and decipher activity locations for single public transport commuters. It is coupled with a machine learning component that iteratively learns from the planners classifications to train a classifier. The classifier is then applied to the city-wide smart card data to derive the dynamics for all public transport commuters. Our evaluation shows it outperforms the rule-based methods in previous work.
Yu Liang;Wei Wu;Xiaohui Li;Guangxia Li;Wee Siong Ng;See-Kiong Ng;Zhongwen Huang;Arunan, A.;Hui Min Watt
Inst. for Infocomm Res., Singapore, Singapore|c|;;;;;;;;
10.1109/INFVIS.2004.27;10.1109/INFVIS.2002.1173155
Smart card data, origin-destination (OD), spatiotemporal visualization, clustering, machine learning
VAST
2015
LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design
10.1109/TVCG.2015.2468011
http://dx.doi.org/10.1109/TVCG.2015.2468011
290
299

J
State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.
Sorger, J.;Ortner, T.;Luksch, C.;Schwärzler, M.;Gröller, E.;Piringer, H.
;;;;;
10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.185;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/INFVIS.2003.1249032;10.1109/TVCG.2013.173;10.1109/TVCG.2009.110;10.1109/TVCG.2014.2346321
Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery
VAST
2015
Mixed-initiative visual analytics using task-driven recommendations
10.1109/VAST.2015.7347625
http://dx.doi.org/10.1109/VAST.2015.7347625
9
16

C
Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach.
Cook, K.;Cramer, N.;Israel, D.;Wolverton, M.;Bruce, J.;Burtner, R.;Endert, A.
Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;;;
10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/TVCG.2014.2346573;10.1109/VAST.2014.7042492;10.1109/TVCG.2008.174;10.1109/TVCG.2013.225
mixed-initiative visual analytics, task modeling, recommender systems, sensemaking
VAST
2015
MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering
10.1109/TVCG.2015.2468111
http://dx.doi.org/10.1109/TVCG.2015.2468111
11
20

J
Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.
von Landesberger, T.;Brodkorb, F.;Roskosch, P.;Andrienko, N.;Andrienko, G.;Kerren, A.
Tech. Univ. of Darmstadt, Darmstadt, Germany|c|;;;;;
10.1109/TVCG.2011.202;10.1109/TVCG.2011.226;10.1109/TVCG.2011.233;10.1109/INFVIS.2004.18;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346441;10.1109/INFVIS.1999.801851;10.1109/VAST.2012.6400553;10.1109/VAST.2009.5333893;10.1109/INFVIS.2005.1532150
Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering
VAST
2015
MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data
10.1109/TVCG.2015.2468292
http://dx.doi.org/10.1109/TVCG.2015.2468292
21
30

J
Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.
Sujin Jang;Elmqvist, N.;Ramani, K.
Purdue Univ. in West LafayetteWest Lafayette, West Lafayette, IN, USA|c|;;
10.1109/TVCG.2013.178;10.1109/TVCG.2009.181;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.258;10.1109/TVCG.2013.196;10.1109/TVCG.2013.200;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2013.181;10.1109/TVCG.2010.149;10.1109/VISUAL.2002.1183778;10.1109/TVCG.2008.172;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346920
Human motion visualization, interactive clustering, motion tracking data, expert reviews, user study
VAST
2015
PhenoBlocks: Phenotype Comparison Visualizations
10.1109/TVCG.2015.2467733
http://dx.doi.org/10.1109/TVCG.2015.2467733
101
110

J
The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.
Glueck, M.;Hamilton, P.;Chevalier, F.;Breslav, S.;Khan, A.;Wigdor, D.;Brudno, M.
;;;;;;
10.1109/VAST.2011.6102439;10.1109/TVCG.2013.214;10.1109/TVCG.2013.231;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2009.167;10.1109/TVCG.2009.116;10.1109/INFVIS.2000.885091;10.1109/TVCG.2007.70529;10.1109/INFVIS.2003.1249030;10.1109/TVCG.2012.226
Clinical diagnosis, differential hierarchy comparison, ontology, genomics, phenomics, phenotype
VAST
2015
Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration
10.1109/TVCG.2015.2468078
http://dx.doi.org/10.1109/TVCG.2015.2468078
1
10

J
We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.
van den Elzen, S.;Holten, D.;Blaas, J.;van Wijk, J.J.
;;;
10.1109/TVCG.2011.226;10.1109/INFVIS.2004.18;10.1109/TVCG.2013.198;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2008.125;10.1109/TVCG.2011.178;10.1109/INFVIS.1999.801851
Dynamic Networks, Exploration, Dimensionality Reduction
VAST
2015
SensePath: Understanding the Sensemaking Process Through Analytic Provenance
10.1109/TVCG.2015.2467611
http://dx.doi.org/10.1109/TVCG.2015.2467611
41
50

J
Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.
Nguyen, P.H.;Kai Xu;Wheat, A.;Wong, B.L.W.;Attfield, S.;Fields, B.
;;;;;
10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346575;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333020;10.1109/TVCG.2013.132
Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization
VAST
2015
Sequencing of categorical time series
10.1109/VAST.2015.7347684
http://dx.doi.org/10.1109/VAST.2015.7347684
213
214
x
M
Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.
Richter, C.;Luboschik, M.;Rohlig, M.;Schumann, H.
Univ. of Rostock, Rostock, Germany|c|;;;

Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization
VAST
2015
StreamVisND: Visualizing relationships in streaming multivariate data
10.1109/VAST.2015.7347673
http://dx.doi.org/10.1109/VAST.2015.7347673
191
192
x
M

Shenghui Cheng;Yue Wang;Dan Zhang;Zhifang Jiang;Mueller, K.
;;;;

Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization
VAST
2015
Supporting activity recognition by visual analytics
10.1109/VAST.2015.7347629
http://dx.doi.org/10.1109/VAST.2015.7347629
41
48

C
Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.
Rohlig, M.;Luboschik, M.;Kruger, F.;Kirste, T.;Schumann, H.;Bogl, M.;Alsallakh, B.;Miksch, S.
Univ. of Rostock, Rostock, Germany|c|;;;;;;;
10.1109/TVCG.2014.2346454;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2009.187;10.1109/VAST.2009.5332595
Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization
VAST
2015
Supporting Iterative Cohort Construction with Visual Temporal Queries
10.1109/TVCG.2015.2467622
http://dx.doi.org/10.1109/TVCG.2015.2467622
91
100

J
Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.
Krause, J.;Perer, A.;Stavropoulos, H.
;;
10.1109/TVCG.2011.185;10.1109/VAST.2007.4389013;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/VAST.2010.5652890;10.1109/TVCG.2014.2346482;10.1109/TVCG.2013.200;10.1109/TVCG.2013.206;10.1109/TVCG.2009.117;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.225;10.1109/TVCG.2013.167
Visual temporal queries, cohort definition, electronic medical records, information visualization
VAST
2015
TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems
10.1109/TVCG.2015.2467196
http://dx.doi.org/10.1109/TVCG.2015.2467196
280
289

J
Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.
Nan Cao;Conglei Shi;Lin, S.;Jie Lu;Yu-Ru Lin;Ching-Yung Lin
;;;;;
10.1109/TVCG.2012.291;10.1109/TVCG.2006.170;10.1109/VISUAL.2002.1183816;10.1109/TVCG.2014.2346922
Anomaly Detection, Social Media, Visual Analysis
VAST
2015
Task-Driven Comparison of Topic Models
10.1109/TVCG.2015.2467618
http://dx.doi.org/10.1109/TVCG.2015.2467618
320
329

J
Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.
Alexander, E.;Gleicher, M.
Univ. of Wisconsin-Madison, Madison, WI, USA|c|;
10.1109/TVCG.2011.232;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/TVCG.2012.260;10.1109/INFVIS.2000.885098;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.221
Text visualization, topic modeling
VAST
2015
Tell me what do you see: Detecting perceptually-separable visual patterns via clustering of image-space features in visualizations
10.1109/VAST.2015.7347683
http://dx.doi.org/10.1109/VAST.2015.7347683
211
212
x
M
Visualization helps users infer structures and relationships in the data by encoding information as visual features that can be processed by the human visual-perceptual system. However, users would typically need to expend significant effort to scan and analyze a large number of views before they can begin to recognize relationships in a visualization. We propose a technique to partially automate the process of analyzing visualizations. By deriving and analyzing image-space features from visualizations, we can detect perceptually-separable patterns in the information space. We summarize these patterns with a tree-based meta-visualization and present it to the user to aid exploration. We illustrate this technique with an example scenario involving the analysis of census data.
Reda, K.;Gonzalez, A.;Leigh, J.;Papka, M.E.
Argonne Nat. Lab., Argonne, IL, USA|c|;;;

Text visualization, topic modeling
VAST
2015
Temporal MDS Plots for Analysis of Multivariate Data
10.1109/TVCG.2015.2467553
http://dx.doi.org/10.1109/TVCG.2015.2467553
141
150

J
Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.
Jäckle, D.;Fischer, F.;Schreck, T.;Keim, D.A.
Univ. of Konstanz, Konstanz, Germany|c|;;;
10.1109/VAST.2009.5332593;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70592;10.1109/VAST.2009.5332628
Multivariate Data, Time Series, Data Reduction, Multidimensional Scaling
VAST
2015
The Data Context Map: Fusing Data and Attributes into a Unified Display
10.1109/TVCG.2015.2467552
http://dx.doi.org/10.1109/TVCG.2015.2467552
121
130

J
Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.
Shenghui Cheng;Mueller, K.
;
10.1109/TVCG.2013.146;10.1109/VAST.2009.5332629;10.1109/VISUAL.1997.663916;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.220;10.1109/INFVIS.1997.636793;10.1109/TVCG.2010.207
High Dimensional Data, Low-Dimensional Embedding, Visual Analytics, Decision Make, Tradeoffs
VAST
2015
The Role of Uncertainty, Awareness, and Trust in Visual Analytics
10.1109/TVCG.2015.2467591
http://dx.doi.org/10.1109/TVCG.2015.2467591
240
249

J
Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.
Sacha, D.;Senaratne, H.;Bum Chul Kwon;Ellis, G.;Keim, D.A.
;;;;
10.1109/TVCG.2014.2346575;10.1109/VISUAL.2000.885679;10.1109/VAST.2008.4677385;10.1109/VAST.2009.5332611;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102473;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102435;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346481;10.1109/VAST.2006.261416
Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors
VAST
2015
The Visual Causality Analyst: An Interactive Interface for Causal Reasoning
10.1109/TVCG.2015.2467931
http://dx.doi.org/10.1109/TVCG.2015.2467931
230
239

J
Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.
Jun Wang;Mueller, K.
Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;
10.1109/INFVIS.2003.1249025;10.1109/TVCG.2007.70528;10.1109/TVCG.2012.225;10.1109/VAST.2007.4388999
Visual knowledge discovery, Causality, Hypothesis testing, Visual evidence, High-dimensional data
VAST
2015
TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text
10.1109/TVCG.2015.2467531
http://dx.doi.org/10.1109/TVCG.2015.2467531
300
309

J
We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.
Fulda, J.;Brehmer, M.;Munzner, T.
;;
10.1109/VAST.2014.7042493;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346431;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/TVCG.2013.214;10.1109/TVCG.2012.224;10.1109/TVCG.2014.2346291;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.212;10.1109/VAST.2012.6400530;10.1109/TVCG.2007.70577
System, timelines, authoring environment, time-oriented data, journalism
VAST
2015
TimeStitch: Interactive multi-focus cohort discovery and comparison
10.1109/VAST.2015.7347682
http://dx.doi.org/10.1109/VAST.2015.7347682
209
210
x
M
Whereas event-based timelines for healthcare enable users to visualize the chronology of events surrounding events of interest, they are often not designed to aid the discovery, construction, or comparison of associated cohorts. We present TimeStitch, a system that helps health researchers discover and understand events that may cause abstinent smokers to lapse. TimeStitch extracts common sequences of events performed by abstinent smokers from large amounts of mobile health sensor data, and offers a suite of interactive and visualization techniques to enable cohort discovery, construction, and comparison, using extracted sequences as interactive elements. We are extending TimeStitch to support more complex health conditions with high mortality risk, such as reducing hospital readmission in congestive heart failure.
Polack, P.J.;Shang-Tse Chen;Minsuk Kahng;Sharmin, M.;Duen Horng Chau
;;;;

System, timelines, authoring environment, time-oriented data, journalism
VAST
2015
Topicks: Visualizing complex topic models for user comprehension
10.1109/VAST.2015.7347681
http://dx.doi.org/10.1109/VAST.2015.7347681
207
208
x
M
The interactive visualization of topic models is a promising approach to summarizing large sets of textual data. Topicks is the working title for a means to visualize topic modelling outputs. Incorporating a radial layout, users can view the relationships between topics, terms and the corpus as a whole. Interacting with topic and term nodes, as well as a related bar chart, provides the user with various ways to manipulate the visualization and explore the data. We describe the visualization and potential user interactions before discussing future work.
Peter, J.;Szigeti, S.;Jofre, A.;Diamond, S.
OCAD Univ., Canada|c|;;;

System, timelines, authoring environment, time-oriented data, journalism
VAST
2015
TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data
10.1109/TVCG.2015.2467771
http://dx.doi.org/10.1109/TVCG.2015.2467771
160
169

J
We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.
Xiaoke Huang;Ye Zhao;Jing Yang;Chong Zhang;Chao Ma;Xinyue Ye
;;;;;
10.1109/VAST.2009.5332593;10.1109/TVCG.2013.226;10.1109/TVCG.2009.145;10.1109/VAST.2011.6102455;10.1109/TVCG.2006.122;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346746
Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment
VAST
2015
Trending pool: Visual analytics for trending event compositions for time-series categorical log data
10.1109/VAST.2015.7347688
http://dx.doi.org/10.1109/VAST.2015.7347688
221
222
x
M
Although many visualization tools provide us plenty of ways to view the data, users can not easily find the trending events and their explanation from the data. In this work, we address the issue by leveraging the real music streaming log data as an example to better understand a million-scale dataset. Trending event explanation turns out to be challenging when it comes to categorical log data. Therefore, we propose to use a learning-based method with an interface design to uncover the trending event compositions for time-series categorical log data, which can be extend to other datasets, e.g., the hashtags in social media. First, we perform ΓÇ£trending poolΓÇ¥ operation to save the memory and time cost. Second, we apply sparse coding to learn important trending candidate combination sets instead of traditional brute-force way or manual investigation for generating combinations. Besides the contributions above, we also observe some interesting user behaviors by exploring detected trending candidate combinations visually through our interface.
Yi-Chih Tsai;Liang-Chi Hsieh;Wen-Feng Cheng;Yin-Hsi Kuo;Hsu, W.;Wen-Chin Chen
Nat. Taiwan Univ., Taipei, Taiwan|c|;;;;;

Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment
VAST
2015
uRank: Visual analytics approach for search result exploration
10.1109/VAST.2015.7347686
http://dx.doi.org/10.1109/VAST.2015.7347686
217
218
x
M
uRank is a Web-based tool combining lightweight text analytics and visual methods for topic-wise exploration of document sets. It includes a view summarizing the content of the document set in meaningful terms, a dynamic document ranking view and a detailed view for further inspection of individual documents. Its major strength lies in how it supports users in reorganizing documents on-the-fly as their information interests change. We present a preliminary evaluation showing that uRank helps to reduce cognitive load compared to a traditional list-based representation.
di Sciascio, C.;Sabol, V.;Veas, E.
Know-Center GmbH, Graz, Austria|c|;;

Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment
VAST
2015
Urbane: A 3D framework to support data driven decision making in urban development
10.1109/VAST.2015.7347636
http://dx.doi.org/10.1109/VAST.2015.7347636
97
104

C
Architects working with developers and city planners typically rely on experience, precedent and data analyzed in isolation when making decisions that impact the character of a city. These decisions are critical in enabling vibrant, sustainable environments but must also negotiate a range of complex political and social forces. This requires those shaping the built environment to balance maximizing the value of a new development with its impact on the character of a neighborhood. As a result architects are focused on two issues throughout the decision making process: a) what defines the character of a neighborhood? and b) how will a new development change its neighborhood? In the first, character can be influenced by a variety of factors and understanding the interplay between diverse data sets is crucial; including safety, transportation access, school quality and access to entertainment. In the second, the impact of a new development is measured, for example, by how it impacts the view from the buildings that surround it. In this paper, we work in collaboration with architects to design Urbane, a 3-dimensional multi-resolution framework that enables a data-driven approach for decision making in the design of new urban development. This is accomplished by integrating multiple data layers and impact analysis techniques facilitating architects to explore and assess the effect of these attributes on the character and value of a neighborhood. Several of these data layers, as well as impact analysis, involve working in 3-dimensions and operating in real time. Efficient computation and visualization is accomplished through the use of techniques from computer graphics. We demonstrate the effectiveness of Urbane through a case study of development in Manhattan depicting how a data-driven understanding of the value and impact of speculative buildings can benefit the design-development process between architects, planners and developers.
Ferreira, N.;Lage, M.;Doraiswamy, H.;Huy Vo;Wilson, L.;Werner, H.;Park, M.;Silva, C.
New York Univ., New York, NY, USA|c|;;;;;;;
10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346446;10.1109/TVCG.2007.70574;10.1109/TVCG.2013.226;10.1109/TVCG.2007.70523;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346893;10.1109/TVCG.2014.2346898
Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment
VAST
2015
Using visualization and analysis with efficient dimension Reduction to determine underlying factors in hospital inpatient procedure costs
10.1109/VAST.2015.7347680
http://dx.doi.org/10.1109/VAST.2015.7347680
205
206
x
M
The Centers for Medicare and Medicaid Services (CMS) has made public a data set showing what hospitals charged and what Medicare paid for the one hundred most common inpatient stays. Here we present the application of Reduced Basis Decomposition (RBD), an efficient novel dimension reduction algorithm for data processing, to the CMS data. This was paired with a comparative visual exploration of the results when put into context with characteristics of the hospitals and marketplaces in which they operate. We used Weave Analyst, a new web-based analysis and visualization environment, to visualize the relationship between the hospital groups, their charge levels, and distinguishing indicator variables. Particular insights to the relatively small number of underlying factors that exert greatest influence on hospital pricing surfaced thanks to the combined synergetic integration of the modeling, reduction, and visualization techniques.
Perkins, M.;Yanlai Chen
Univ. of Massachusetts Lowell, Lowell, MA, USA|c|;

Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment
VAST
2015
VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications
10.1109/TVCG.2015.2467871
http://dx.doi.org/10.1109/TVCG.2015.2467871
61
70

J
Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.
Blascheck, T.;John, M.;Kurzhals, K.;Koch, S.;Ertl, T.
Inst. for Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;
10.1109/TVCG.2012.276;10.1109/TVCG.2013.124;10.1109/VAST.2008.4677361;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346677;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.273;10.1109/VISUAL.2005.1532837
visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data
VAST
2015
VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History
10.1109/TVCG.2015.2467971
http://dx.doi.org/10.1109/TVCG.2015.2467971
210
219

J
Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.
Cho, I.;Wewnen Dou;Wang, D.X.;Sauda, E.;Ribarsky, W.
;;;;
10.1109/VAST.2014.7042493;10.1109/VAST.2007.4389012;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.178;10.1109/VAST.2010.5652885;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2000.885091
Visual Analytics, Text Analytics, Wikipedia
VAST
2015
VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments
10.1109/TVCG.2015.2467954
http://dx.doi.org/10.1109/TVCG.2015.2467954
111
120

J
Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.
Papadopoulos, C.;Gutenko, I.;Kaufman, A.E.
Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA|c|;;
10.1109/TVCG.2012.276;10.1109/TVCG.2012.251;10.1109/TVCG.2014.2346591;10.1109/TVCG.2010.157;10.1109/TVCG.2014.2346311;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12
Visual Analytics, Evaluation, User Studies, Ontology, Experiments, Interaction, Virtual Reality, Visualization
VAST
2015
VisOHC: Designing Visual Analytics for Online Health Communities
10.1109/TVCG.2015.2467555
http://dx.doi.org/10.1109/TVCG.2015.2467555
71
80

J
Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.
Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi
;;;;;
10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102441;10.1109/TVCG.2014.2346292;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2010.175;10.1109/VAST.2014.7042494;10.1109/TVCG.2014.2346331;10.1109/VAST.2009.5333919;10.1109/TVCG.2012.213;10.1109/TVCG.2009.171;10.1109/TVCG.2009.187;10.1109/TVCG.2013.221;10.1109/VAST.2012.6400554;10.1109/VAST.2014.7042496;10.1109/TVCG.2008.171
Online health communities, visual analytics, conversation analysis, thread visualization, healthcare, design study
VAST
2015
Visual Analysis and Dissemination of Scientific Literature Collections with SurVis
10.1109/TVCG.2015.2467757
http://dx.doi.org/10.1109/TVCG.2015.2467757
180
189

J
Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.
Beck, F.;Koch, S.;Weiskopf, D.
VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;
10.1109/TVCG.2011.169;10.1109/TVCG.2012.252;10.1109/TVCG.2015.2467621;10.1109/VAST.2009.5333564;10.1109/TVCG.2010.194;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.167
Visual analytics of documents, bibliographic data, dissemination, literature browser
VAST
2015
Visual analysis of route choice behaviour based on GPS trajectories
10.1109/VAST.2015.7347679
http://dx.doi.org/10.1109/VAST.2015.7347679
203
204
x
M
There are often multiple routes between regions. Many factors potentially affect driver's route choice, such as expected time cost, length etc. In this work, we present a visual analysis system to explore driver's route choice behaviour based on taxi GPS trajectory data. With interactive trajectory filtering, the system constructs feasible routes between regions of interest. Using a rank-based visualization, the attributes of multiple routes are explored and compared. Based on a statistical model, the system supports to verify trajectory-related factors' impact on route choice behaviour. The effectiveness of the system is demonstrated by applying to real trajectory dataset.
Min Lu;Chufan Lai;Ye Tangzhi;Jie Liang;Xiaoru Yuan
Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;

Visual analytics of documents, bibliographic data, dissemination, literature browser
VAST
2015
Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes
10.1109/TVCG.2015.2467612
http://dx.doi.org/10.1109/TVCG.2015.2467612
151
159

J
Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example.
Löwe, T.;Förster, E.-C.;Albuquerque, G.;Kreiss, J.-P.;Magnor, M.
Comput. Graphics Lab., Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;
10.1109/TVCG.2013.222
Visual analytics, time series analysis, order selection
VAST
2015
Visual Analytics for fraud detection and monitoring
10.1109/VAST.2015.7347678
http://dx.doi.org/10.1109/VAST.2015.7347678
201
202
x
M
One of the primary concerns of financial institutions is to guarantee security and legitimacy in their services. Being able to detect and avoid fraudulent schemes also enhances the credibility of these institutions. Currently, fraud detection approaches still lack Visual Analytics techniques. We propose a Visual Analytics process that tackles the main challenges in the area of fraud detection.
Leite, R.A.;Gschwandtner, T.;Miksch, S.;Gstrein, E.;Kuntner, J.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;

Visual analytics, time series analysis, order selection
VAST
2015
Visual data quality analysis for taxi GPS data
10.1109/VAST.2015.7347689
http://dx.doi.org/10.1109/VAST.2015.7347689
223
224
x
M
We present a novel visual analysis method to systematically discover data quality problems in raw taxi GPS data. It combines semi-supervised active learning and interactive visual exploration. It helps analysts interactively discover unknown data quality problems, and automatically extract known problems. We report analysis results on Beijing taxi GPS data.
Zuchao Wang;Xiaoru Yuan;Ye Tangzhi;Youfeng hao;Siming Chen;Jie Liangk;Qiusheng Li;Haiyang Wang;Yadong Wu
Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;;;;;

Visual analytics, time series analysis, order selection
VAST
2015
Visual Pruner: Visually guided cohort selection for observational studies
10.1109/VAST.2015.7347685
http://dx.doi.org/10.1109/VAST.2015.7347685
215
216
x
M
Observational studies are a widely used and challenging class of studies. A key challenge is selecting a study cohort from the available data, or ΓÇ£pruningΓÇ¥ the data, in a way that produces both sufficient balance in pre-treatment covariates and an easily described cohort from which results can be generalized. Even with advanced pruning methods, it is often difficult for researchers to see how the cohort is being selected; consequently, these methods are underutilized in research. Visual Pruner is a free, easy-to-use web application that can improve both the credibility and generalizability of observational studies by letting analysts use updatable visual displays of estimated propensity scores and key baseline covariates to refine inclusion criteria. By helping researchers see how covariate distributions in their data relate to the estimated probabilities of treatment assignment, the app lets researchers make pruning decisions based on pre-treatment covariate patterns that are otherwise hard to discover. The app yields a set of inclusion criteria that can be used in conjunction with further statistical analysis in any statistical software.
Samuels, L.R.;Greevy, R.A.
Sch. of Med., Dept. of Biostat., Vanderbilt Univ., Nashville, TN, USA|c|;

Visual analytics, time series analysis, order selection
VAST
2015
Visual scalability of spatial ensemble uncertainty
10.1109/VAST.2015.7347671
http://dx.doi.org/10.1109/VAST.2015.7347671
187
188
x
M
Weather Research and Forecasting (WRF) models simulate weather conditions by generating 2D numerical weather prediction ensemble members either through perturbing initial conditions or by changing different parameterization schemes, e.g., cumulus and microphysics schemes. These simulations are often used by weather analysts to analyze the nature of uncertainty attributed by these simulations to forecast weather conditions with good accuracy. The number of simulations used for forecasting is growing with the advent of increase in computing power. Hence, there is a need for providing better visual insights of uncertainty with growing number of ensemble members. We propose a geo visual analytical framework that uses visual analytics approach to resolve visual scalability of these ensemble members. Our approach naturally fits with the workflow of an analyst analyzing ensemble spatial uncertainty. Meteorologists evaluated our framework qualitatively and found it to be effective in acquiring insights of spatial uncertainty associated with multiple ensemble runs that are simulated using multiple parameterization schemes.
Anreddy, S.;Song Zhang;Mercer, A.;Dyer, J.;Swan, J.E.
Mississippi State Univ., Starkville, MS, USA|c|;;;;

Anreddy, S.;Song Zhang;Mercer, A.;Dyer, J.;Swan, J.E. n
VAST
2015
Visually and statistically guided imputation of missing values in univariate seasonal time series
10.1109/VAST.2015.7347672
http://dx.doi.org/10.1109/VAST.2015.7347672
189
190
x
M
Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.
Bogl, M.;Filzmoser, P.;Gschwandtner, T.;Miksch, S.;Aigner, W.;Rind, A.;Lammarsch, T.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;

Anreddy, S.;Song Zhang;Mercer, A.;Dyer, J.;Swan, J.E. n
VAST
2015
Visually Exploring Transportation Schedules
10.1109/TVCG.2015.2467592
http://dx.doi.org/10.1109/TVCG.2015.2467592
170
179

J
Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.
Palomo, C.;Zhan Guo;Silva, C.T.;Freire, J.
;;;
10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346449;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.176;10.1109/TVCG.2013.226;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.137;10.1109/TVCG.2009.131;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2011.179;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249005
Transportation, schedules, kernel density estimation, visual exploration
VAST
2015
Wavelet-based visualization of time-varying data on graphs
10.1109/VAST.2015.7347624
http://dx.doi.org/10.1109/VAST.2015.7347624
1
8

C
Visualizing time-varying data defined on the nodes of a graph is a challenging problem that has been faced with different approaches. Although techniques based on aggregation, topology, and topic modeling have proven their usefulness, the visual analysis of smooth and/or abrupt data variations as well as the evolution of such variations over time are aspects not properly tackled by existing methods. In this work we propose a novel visualization methodology that relies on graph wavelet theory and stacked graph metaphor to enable the visual analysis of time-varying data defined on the nodes of a graph. The proposed method is able to identify regions where data presents abrupt and mild spacial and/or temporal variation while still been able to show how such changes evolve over time, making the identification of events an easier task. The usefulness of our approach is shown through a set of results using synthetic as well as a real data set involving taxi trips in downtown Manhattan. The methodology was able to reveal interesting phenomena and events such as the identification of specific locations with abrupt variation in the number of taxi pickups.
Valdivia, P.;Dias, F.;Petronetto, F.;Silva, C.T.;Nonato, L.G.
;;;;
10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346449;10.1109/TVCG.2013.226;10.1109/INFVIS.2000.885098;10.1109/TVCG.2013.228
Time-varying data, graph wavelets, stacked graph visualization
InfoVis
2014
A Principled Way of Assessing Visualization Literacy
10.1109/TVCG.2014.2346984
http://dx.doi.org/10.1109/TVCG.2014.2346984
1963
1972

J
We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.
Boy, J.;Rensink, R.A.;Bertini, E.;Fekete, J.-D.
EnsadLab, Telecom ParisTech, Paris, France|c|;;;
10.1109/TVCG.2011.160
Literacy, Visualization literacy, Rasch Model, Item Response Theory
InfoVis
2014
Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity
10.1109/TVCG.2014.2352953
http://dx.doi.org/10.1109/TVCG.2014.2352953
2201
2210

J
Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.
Stusak, S.;Tabard, A.;Sauka, F.;Khot, R.A.;Butz, A.
Univ. of Munich, Munich, Germany|c|;;;;
10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031;10.1109/TVCG.2013.134
Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change
InfoVis
2014
An Algebraic Process for Visualization Design
10.1109/TVCG.2014.2346325
http://dx.doi.org/10.1109/TVCG.2014.2346325
2181
2190

J
We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.
Kindlmann, G.;Scheidegger, C.
Univ. of Chicago, Chicago, IL, USA|c|;
10.1109/TVCG.2013.173;10.1109/INFVIS.1999.801860;10.1109/TVCG.2010.132;10.1109/TVCG.2010.199;10.1109/VISUAL.1996.568118;10.1109/TVCG.2013.124;10.1109/TVCG.2009.125;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594;10.1109/TVCG.2013.119;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2004.59;10.1109/VISUAL.1996.567784;10.1109/TVCG.2013.126;10.1109/TVCG.2008.121;10.1109/TVCG.2012.230;10.1109/TVCG.2010.161
Visualization Design, Symmetries, Visualization Theory
InfoVis
2014
Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data
10.1109/TVCG.2014.2346265
http://dx.doi.org/10.1109/TVCG.2014.2346265
2033
2042

J
The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.
Turkay, C.;Slingsby, A.;Hauser, H.;Wood, J.;Dykes, J.
Dept. of Comput. Sci., City Univ. London, London, UK|c|;;;;
10.1109/TVCG.2013.173;10.1109/TVCG.2011.178;10.1109/TVCG.2013.226;10.1109/TVCG.2011.197;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.149;10.1109/INFVIS.2004.12;10.1109/TVCG.2012.256;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677350;10.1109/TVCG.2008.125;10.1109/TVCG.2013.122
Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis
InfoVis
2014
Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots
10.1109/TVCG.2014.2346258
http://dx.doi.org/10.1109/TVCG.2014.2346258
2013
2022

J
Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.
Rubio-Sanchez, M.;Sanchez, A.
URJC, Fuenlabrada, Spain|c|;
10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663916
Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection
InfoVis
2014
Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time
10.1109/TVCG.2014.2346456
http://dx.doi.org/10.1109/TVCG.2014.2346456
2349
2358

J
With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.
Isaacs, K.E.;Bremer, P.-T.;Jusufi, I.;Gamblin, T.;Bhatele, A.;Schulz, M.;Hamann, B.
Univ. of California, Davis, Davis, CA, USA|c|;;;;;;
10.1109/TVCG.2012.286;10.1109/TVCG.2009.196;10.1109/TVCG.2011.199;10.1109/TVCG.2013.200
Information visualization, software visualization, timelines, traces, performance analysis
InfoVis
2014
Comparative Eye Tracking Study on Node-Link Visualizations of Trajectories
10.1109/TVCG.2014.2346420
http://dx.doi.org/10.1109/TVCG.2014.2346420
2221
2230

J
We present the results of an eye tracking study that compares different visualization methods for long, dense, complex, and piecewise linear spatial trajectories. Typical sources of such data are from temporally discrete measurements of the positions of moving objects, for example, recorded GPS tracks of animals in movement ecology. In the repeated-measures within-subjects user study, four variants of node-link visualization techniques are compared, with the following representations of directed links: standard arrow, tapered, equidistant arrows, and equidistant comets. In addition, we investigate the effect of rendering order for the halo visualization of those links as well as the usefulness of node splatting. All combinations of link visualization techniques are tested for different trajectory density levels. We used three types of tasks: tracing of paths, identification of longest links, and estimation of the density of trajectory clusters. Results are presented in the form of the statistical evaluation of task completion time, task solution accuracy, and two eye tracking metrics. These objective results are complemented by a summary of subjective feedback from the participants. The main result of our study is that tapered links perform very well. However, we discuss that equidistant comets and equidistant arrows are a good option to perceive direction information independent of zoom-level of the display.
Netzel, R.;Burch, M.;Weiskopf, D.
;;
10.1109/INFVIS.2004.1;10.1109/TVCG.2011.193;10.1109/TVCG.2011.226
User study, eye tracking, evaluation, trajectory visualization, node-link visualization, direction encoding, node splatting, halo rendering
InfoVis
2014
Constructing Visual Representations: Investigating the Use of Tangible Tokens
10.1109/TVCG.2014.2346292
http://dx.doi.org/10.1109/TVCG.2014.2346292
2102
2111

J
The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.
Huron, S.;Jansen, Y.;Carpendale, S.
IRI, Inria, Orsay, France|c|;;
10.1109/TVCG.2009.176;10.1109/TVCG.2011.185;10.1109/TVCG.2013.227;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2011.251;10.1109/VISUAL.1997.663890;10.1109/TVCG.2012.275;10.1109/TVCG.2013.134;10.1109/TVCG.2010.164;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.199
Constructive visualization, Physical visualization, Dynamic visualization, Empirical study, Token, Visualization authoring, Information visualization, Visual mapping, Novices, Visualization construction, Visual analytics
InfoVis
2014
Design Activity Framework for Visualization Design
10.1109/TVCG.2014.2346331
http://dx.doi.org/10.1109/TVCG.2014.2346331
2191
2200

J
An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.
McKenna, S.;Mazur, D.;Agutter, J.;Meyer, M.
Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;
10.1109/TVCG.2012.213;10.1109/TVCG.2011.209;10.1109/TVCG.2009.111;10.1109/TVCG.2013.126;10.1109/TVCG.2013.145
Design, frameworks, process, cybersecurity, nested model, decisions, models, evaluation, visualization
InfoVis
2014
DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation
10.1109/TVCG.2014.2346250
http://dx.doi.org/10.1109/TVCG.2014.2346250
2003
2012

J
We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.
Kondo, B.;Collins, C.
Inst. of Technol., Univ. of Ontario, Toronto, ON, Canada|c|;
10.1109/TVCG.2013.147;10.1109/TVCG.2012.204;10.1109/TVCG.2012.260;10.1109/TVCG.2008.175;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.265;10.1109/TVCG.2013.149;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2008.125;10.1109/TVCG.2011.195
Time navigation, direct manipulation, information visualization
InfoVis
2014
Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets
10.1109/TVCG.2014.2346260
http://dx.doi.org/10.1109/TVCG.2014.2346260
2023
2032

J
Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.
Gratzl, S.;Gehlenborg, N.;Lex, A.;Pfister, H.;Streit, M.
Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;
10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2012.207;10.1109/TVCG.2011.250;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.173;10.1109/TVCG.2011.183;10.1109/TVCG.2013.160;10.1109/TVCG.2011.201;10.1109/TVCG.2006.166;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2004.15;10.1109/TVCG.2007.70521
Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data
InfoVis
2014
Effects of Presentation Mode and Pace Control on Performance in Image Classification
10.1109/TVCG.2014.2346437
http://dx.doi.org/10.1109/TVCG.2014.2346437
2301
2309

J
A common task in visualization is to quickly find interesting items in large sets. When appropriate metadata is missing, automatic queries are impossible and users have to inspect all elements visually. We compared two fundamentally different, but obvious display modes for this task and investigated the difference with respect to effectiveness, efficiency, and satisfaction. The static mode is based on the page metaphor and presents successive pages with a static grid of items. The moving mode is based on the conveyor belt metaphor and lets a grid of items slide though the screen in a continuous flow. In our evaluation, we applied both modes to the common task of browsing images. We performed two experiments where 18 participants had to search for certain target images in a large image collection. The number of shown images per second (pace) was predefined in the first experiment, and under user control in the second one. We conclude that at a fixed pace, the mode has no significant impact on the recall. The perceived pace is generally slower for moving mode, which causes users to systematically choose for a faster real pace than in static mode at the cost of recall, keeping the average number of target images found per second equal for both modes.
van der Corput, P.;van Wijk, J.J.
;

RSVP, image classification, image browsing, multimedia visualization
InfoVis
2014
Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error
10.1109/TVCG.2014.2346298
http://dx.doi.org/10.1109/TVCG.2014.2346298
2142
2151

J
When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.
Correll, M.;Gleicher, M.
Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA|c|;
10.1109/TVCG.2012.220;10.1109/TVCG.2012.199;10.1109/TVCG.2012.262;10.1109/TVCG.2011.175;10.1109/TVCG.2012.279
Visual statistics, information visualization, crowd-sourcing, empirical evaluation
InfoVis
2014
Exploring the Placement and Design of Word-Scale Visualizations
10.1109/TVCG.2014.2346435
http://dx.doi.org/10.1109/TVCG.2014.2346435
2291
2300

J
We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.
Goffin, P.;Willett, W.;Fekete, J.-D.;Isenberg, P.
;;;
10.1109/TVCG.2013.192;10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70589;10.1109/TVCG.2011.183;10.1109/TVCG.2013.120;10.1109/TVCG.2010.194;10.1109/INFVIS.2005.1532144
Information visualization, text visualization, sparklines, glyphs, design space, word-scale visualizations
InfoVis
2014
Four Experiments on the Perception of Bar Charts
10.1109/TVCG.2014.2346320
http://dx.doi.org/10.1109/TVCG.2014.2346320
2152
2160

J
Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland & McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland & McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.
Talbot, J.;Setlur, V.;Anand, A.
Tableau Res., USA|c|;;
10.1109/TVCG.2012.237
Graphical perception, bar charts
InfoVis
2014
GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration
10.1109/TVCG.2014.2346444
http://dx.doi.org/10.1109/TVCG.2014.2346444
2320
2328

J
The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.
Stolper, C.D.;Kahng, M.;Zhiyuan Lin;Foerster, F.;Goel, A.;Stasko, J.;Duen Horng Chau
Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;;;
10.1109/TVCG.2008.137;10.1109/VAST.2011.6102441;10.1109/TVCG.2010.144;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/VAST.2011.6102440;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/TVCG.2010.205;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.233;10.1109/TVCG.2011.185;10.1109/TVCG.2006.166;10.1109/TVCG.2009.108;10.1109/TVCG.2013.192
Graph-level operations, graph visualization, visualization technique specification, graph analysis, information visualization
InfoVis
2014
How Hierarchical Topics Evolve in Large Text Corpora
10.1109/TVCG.2014.2346433
http://dx.doi.org/10.1109/TVCG.2014.2346433
2281
2290

J
Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.
Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei
Microsoft Res., Redmond, WA, USA|c|;;;
10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200
Hierarchical topic visualization, evolutionary tree clustering, data transformation
InfoVis
2014
iVisDesigner: Expressive Interactive Design of Information Visualizations
10.1109/TVCG.2014.2346291
http://dx.doi.org/10.1109/TVCG.2014.2346291
2092
2101

J
We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.
Donghao Ren;Hollerer, T.;Xiaoru Yuan
Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA|c|;;
10.1109/INFVIS.2004.12;10.1109/TVCG.2010.144;10.1109/TVCG.2009.179;10.1109/TVCG.2009.174;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.126;10.1109/TVCG.2013.191;10.1109/INFVIS.1997.636792;10.1109/TVCG.2011.201;10.1109/TVCG.2011.261;10.1109/TVCG.2012.275;10.1109/INFVIS.1997.636761
Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization
InfoVis
2014
Learning Perceptual Kernels for Visualization Design
10.1109/TVCG.2014.2346978
http://dx.doi.org/10.1109/TVCG.2014.2346978
1933
1942

J
Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.
Demiralp, C.D.;Bernstein, M.S.;Heer, J.
Stanford Univ., Stanford, CA, USA|c|;;
10.1109/TVCG.2010.186;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70583;10.1109/TVCG.2008.125;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70539
Visualization, design, encoding, perception, model, crowdsourcing, automated visualization, visual embedding
InfoVis
2014
LiveGantt: Interactively Visualizing a Large Manufacturing Schedule
10.1109/TVCG.2014.2346454
http://dx.doi.org/10.1109/TVCG.2014.2346454
2329
2338

J
In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.
Jaemin Jo;Jaeseok Huh;Jonghun Park;Bohyoung Kim;Jinwook Seo
Seoul Nat. Univ., Seoul, South Korea|c|;;;;
10.1109/TVCG.2013.200;10.1109/TVCG.2012.213;10.1109/TVCG.2009.117;10.1109/TVCG.2012.225
Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation
InfoVis
2014
MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data
10.1109/TVCG.2014.2346311
http://dx.doi.org/10.1109/TVCG.2014.2346311
2359
2368

J
In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.
Palmas, G.;Bachynskyi, M.;Oulasvirta, A.;Seidel, H.-P.;Weinkauf, T.
Max Planck Inst. for Inf., Saarbrucken, Germany|c|;;;;
10.1109/TVCG.2009.152;10.1109/TVCG.2012.213;10.1109/TVCG.2012.204;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2004.12
Information visualization, Design study, Human-Computer Interaction
InfoVis
2014
Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization
10.1109/TVCG.2014.2346323
http://dx.doi.org/10.1109/TVCG.2014.2346323
2171
2180

J
We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.
Wood, J.;Beecham, R.;Dykes, J.
giCentre, City Univ. London, London, UK|c|;;
10.1109/TVCG.2012.272;10.1109/TVCG.2012.262;10.1109/TVCG.2012.213;10.1109/TVCG.2011.175;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/TVCG.2013.132;10.1109/INFVIS.2004.59;10.1109/TVCG.2011.209;10.1109/TVCG.2013.145;10.1109/TVCG.2008.127
Movement visualization, visual analytics, bikeshare, impact, visualization models, design study
InfoVis
2014
Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations
10.1109/TVCG.2014.2346441
http://dx.doi.org/10.1109/TVCG.2014.2346441
2310
2319

J
Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.
van den Elzen, S.;van Wijk, J.J.
Dept. of Mathematic & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;
10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.122;10.1109/TVCG.2009.145;10.1109/TVCG.2013.223;10.1109/VAST.2007.4389013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.153;10.1109/TVCG.2009.108;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147
Multivariate Networks, Selections of Interest, Interaction, Direct Manipulation
InfoVis
2014
NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity
10.1109/TVCG.2014.2346312
http://dx.doi.org/10.1109/TVCG.2014.2346312
2369
2378

J
We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.
Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.
King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;
10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154
Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context
InfoVis
2014
Nmap: A Novel Neighborhood Preservation Space-filling Algorithm
10.1109/TVCG.2014.2346276
http://dx.doi.org/10.1109/TVCG.2014.2346276
2063
2071

J
Space-filling techniques seek to use as much as possible the visual space to represent a dataset, splitting it into regions that represent the data elements. Amongst those techniques, Treemaps have received wide attention due to its simplicity, reduced visual complexity, and compact use of the available space. Several different Treemap algorithms have been proposed, however the core idea is the same, to divide the visual space into rectangles with areas proportional to some data attribute or weight. Although pleasant layouts can be effectively produced by the existing techniques, most of them do not take into account relationships that might exist between different data elements when partitioning the visual space. This violates the distance-similarity metaphor, that is, close rectangles do not necessarily represent similar data elements. In this paper, we propose a novel approach, called Neighborhood Treemap (Nmap), that seeks to solve this limitation by employing a slice and scale strategy where the visual space is successively bisected on the horizontal or vertical directions and the bisections are scaled until one rectangle is defined per data element. Compared to the current techniques with the same similarity preservation goal, our approach presents the best results while being two to three orders of magnitude faster. The usefulness of Nmap is shown by two applications involving the organization of document collections and the construction of cartograms illustrating its effectiveness on different scenarios.
Duarte, F.S.L.G.;Sikansi, F.;Fatore, F.M.;Fadel, S.G.;Paulovich, F.V.
Inst. of Math. & Comput. Sci., Sao Carlos, Brazil|c|;;;;
10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/TVCG.2007.70522;10.1109/TVCG.2009.128;10.1109/TVCG.2007.70529;10.1109/VISUAL.1991.175815;10.1109/TVCG.2008.165
Space-filling techniques, treemaps, distance-similarity preservation
InfoVis
2014
Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation
10.1109/TVCG.2014.2346422
http://dx.doi.org/10.1109/TVCG.2014.2346422
2231
2240

J
Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.
Saket, B.;Simonetto, P.;Kobourov, S.;Borner, K.
Univ. of Arizona, Tucson, AZ, USA|c|;;;
10.1109/INFVIS.2003.1249011;10.1109/TVCG.2011.186;10.1109/TVCG.2008.155;10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70596;10.1109/TVCG.2009.122;10.1109/TVCG.2013.187;10.1109/TVCG.2013.124
graphs, networks, maps, scatter plots
InfoVis
2014
OnSet: A Visualization Technique for Large-scale Binary Set Data
10.1109/TVCG.2014.2346249
http://dx.doi.org/10.1109/TVCG.2014.2346249
1993
2002

J
Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.
Sadana, R.;Major, T.;Dove, A.;Stasko, J.
Georgia Tech, Atlanta, GA, USA|c|;;;
10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/TVCG.2013.184
Set visualization, information visualization, direct manipulation, Euler diagrams, interaction, logical operations
InfoVis
2014
Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection
10.1109/TVCG.2014.2346428
http://dx.doi.org/10.1109/TVCG.2014.2346428
2261
2270

J
In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types.
Borgo, R.;Dearden, J.;Jones, M.W.
;;
10.1109/TVCG.2013.187;10.1109/TVCG.2012.229;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.160;10.1109/TVCG.2010.130;10.1109/TVCG.2013.234
Orders of magnitude, bar charts, logarithmic scale
InfoVis
2014
Origin-Destination Flow Data Smoothing and Mapping
10.1109/TVCG.2014.2346271
http://dx.doi.org/10.1109/TVCG.2014.2346271
2043
2052

J
This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.
Diansheng Guo;Xi Zhu
Dept. of Geogr., Univ. of South Carolina, Columbia, WA, USA|c|;
10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2011.202;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/VISUAL.2005.1532819
flow mapping, kernel smoothing, generalization, multi-resolution mapping, graph drawing, spatial data mining
InfoVis
2014
Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists
10.1109/TVCG.2014.2346431
http://dx.doi.org/10.1109/TVCG.2014.2346431
2271
2280

J
For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system ÔÇ£in the wildÔÇØ, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of ÔÇ£exploringÔÇØ a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.
Brehmer, M.;Ingram, S.;Stray, J.;Munzner, T.
Univ. of British Columbia, Vancouver, BC, Canada|c|;;;
10.1109/TVCG.2009.127;10.1109/INFVIS.2004.19;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2012.260;10.1109/TVCG.2009.140;10.1109/TVCG.2013.162;10.1109/TVCG.2013.153;10.1109/TVCG.2009.148;10.1109/TVCG.2013.124;10.1109/TVCG.2011.239;10.1109/VAST.2010.5652940;10.1109/TVCG.2011.209
Design study, investigative journalism, task and requirements analysis, text and document data, text analysis
InfoVis
2014
PanoramicData: Data Analysis through Pen & Touch
10.1109/TVCG.2014.2346293
http://dx.doi.org/10.1109/TVCG.2014.2346293
2112
2121

J
Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.
Zgraggen, E.;Zeleznik, R.;Drucker, S.M.
;;
10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.162;10.1109/TVCG.2010.164;10.1109/TVCG.2011.251;10.1109/TVCG.2013.191;10.1109/TVCG.2012.275;10.1109/VAST.2007.4389013;10.1109/TVCG.2013.150;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.137;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70594;10.1109/TVCG.2012.204
Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views
InfoVis
2014
Ranking Visualizations of Correlation Using Weber's Law
10.1109/TVCG.2014.2346979
http://dx.doi.org/10.1109/TVCG.2014.2346979
1943
1952

J
Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.
Harrison, L.;Fumeng Yang;Franconeri, S.;Chang, R.
Tufts Univ., Medford, MA, USA|c|;;;
10.1109/TVCG.2013.187;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594
Perception, Visualization, Evaluation
InfoVis
2014
Reinforcing Visual Grouping Cues to Communicate Complex Informational Structure
10.1109/TVCG.2014.2346998
http://dx.doi.org/10.1109/TVCG.2014.2346998
1973
1982

J
In his book Multimedia Learning [7], Richard Mayer asserts that viewers learn best from imagery that provides them with cues to help them organize new information into the correct knowledge structures. Designers have long been exploiting the Gestalt laws of visual grouping to deliver viewers those cues using visual hierarchy, often communicating structures much more complex than the simple organizations studied in psychological research. Unfortunately, designers are largely practical in their work, and have not paused to build a complex theory of structural communication. If we are to build a tool to help novices create effective and well structured visuals, we need a better understanding of how to create them. Our work takes a first step toward addressing this lack, studying how five of the many grouping cues (proximity, color similarity, common region, connectivity, and alignment) can be effectively combined to communicate structured text and imagery from real world examples. To measure the effectiveness of this structural communication, we applied a digital version of card sorting, a method widely used in anthropology and cognitive science to extract cognitive structures. We then used tree edit distance to measure the difference between perceived and communicated structures. Our most significant findings are: 1) with careful design, complex structure can be communicated clearly; 2) communicating complex structure is best done with multiple reinforcing grouping cues; 3) common region (use of containers such as boxes) is particularly effective at communicating structure; and 4) alignment is a weak structural communicator.
Bae, J.;Watson, B.
North Carolina State Univ., Raleigh, NC, USA|c|;
10.1109/TVCG.2010.174;10.1109/INFVIS.2003.1249005
Visual grouping, visual hierarchy, gestalt principles, perception, visual communication
InfoVis
2014
Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations
10.1109/TVCG.2014.2346279
http://dx.doi.org/10.1109/TVCG.2014.2346279
2082
2091

J
We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to ÔÇ£simplify without destroyingÔÇØ by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER
Perin, C.;Dragicevic, P.;Fekete, J.-D.
INRIA, Sophia-Antipolis, France|c|;;
10.1109/TVCG.2006.160;10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2346426
Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets
InfoVis
2014
Stenomaps: Shorthand for shapes
10.1109/TVCG.2014.2346274
http://dx.doi.org/10.1109/TVCG.2014.2346274
2053
2062

J
We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C1-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon's base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the 'cartographic design space'. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data.
van Goethem, A.;Reimer, A.;Speckmann, B.;Wood, J.
Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;
10.1109/INFVIS.2005.1532145
Schematisation, Maps, Algorithm, Design
InfoVis
2014
TenniVis: Visualization for Tennis Match Analysis
10.1109/TVCG.2014.2346445
http://dx.doi.org/10.1109/TVCG.2014.2346445
2339
2348

J
Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.
Polk, T.;Jing Yang;Yueqi Hu;Ye Zhao
Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;
10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/VISUAL.2001.964496;10.1109/INFVIS.1996.559229;10.1109/INFVIS.2002.1173148
Visual knowledge discovery, sports analytics, tennis visualization
InfoVis
2014
The Effects of Interactive Latency on Exploratory Visual Analysis
10.1109/TVCG.2014.2346452
http://dx.doi.org/10.1109/TVCG.2014.2346452
2122
2131

J
To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.
Zhicheng Liu;Heer, J.
;
10.1109/TVCG.2010.177
Interaction, latency, exploratory analysis, interactive visualization, scalability, user performance, verbal analysis
InfoVis
2014
The Influence of Contour on Similarity Perception of Star Glyphs
10.1109/TVCG.2014.2346426
http://dx.doi.org/10.1109/TVCG.2014.2346426
2251
2260

J
We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyp- s.
Fuchs, J.;Isenberg, P.;Bezerianos, A.;Fischer, F.;Bertini, E.
Univ. of Konstanz, Konstanz, Germany|c|;;;;
10.1109/TVCG.2012.220;10.1109/TVCG.2008.136;10.1109/TVCG.2011.242;10.1109/INFVIS.2004.15
Glyphs, star glyphs, contours, perception, quantitative evaluation, similarity detection, visual comparison
InfoVis
2014
The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking
10.1109/TVCG.2014.2346424
http://dx.doi.org/10.1109/TVCG.2014.2346424
2241
2250

J
Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.
Chevalier, F.;Dragicevic, P.;Franconeri, S.
Inria, Sophia-Antipolis, France|c|;;
10.1109/TVCG.2012.199;10.1109/INFVIS.1999.801854;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539
Animated transitions, staggered animation, visual tracking
InfoVis
2014
The Persuasive Power of Data Visualization
10.1109/TVCG.2014.2346419
http://dx.doi.org/10.1109/TVCG.2014.2346419
2211
2220

J
Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.
Pandey, A.V.;Manivannan, A.;Nov, O.;Satterthwaite, M.;Bertini, E.
New York Univ., New York, NY, USA|c|;;;;
10.1109/TVCG.2012.199;10.1109/TVCG.2012.221;10.1109/TVCG.2012.197;10.1109/TVCG.2011.192;10.1109/TVCG.2013.234
Persuasive visualization, elaboration likelihood model, evaluation
InfoVis
2014
The relation between visualization size, grouping, and user performance
10.1109/TVCG.2014.2346983
http://dx.doi.org/10.1109/TVCG.2014.2346983
1953
1962

J
In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (ÔÇ£pop-outÔÇØ), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.
Gramazio, C.C.;Schloss, K.B.;Laidlaw, D.H.
Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;
10.1109/TVCG.2012.233;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/VAST.2007.4389009;10.1109/TVCG.2013.187;10.1109/TVCG.2011.175;10.1109/TVCG.2013.183;10.1109/TVCG.2006.184;10.1109/TVCG.2010.186;10.1109/VISUAL.1996.568118;10.1109/TVCG.2012.220;10.1109/TVCG.2013.170;10.1109/TVCG.2013.234
information visualization, graphical perception, size, layout
InfoVis
2014
Tree Colors: Color Schemes for Tree-Structured Data
10.1109/TVCG.2014.2346277
http://dx.doi.org/10.1109/TVCG.2014.2346277
2072
2081

J
We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.
Tennekes, M.;de Jonge, E.
;
10.1109/TVCG.2011.193;10.1109/INFVIS.2000.885091;10.1109/INFVIS.2002.1173151
Color schemes, statistical graphics, hierarchical data
InfoVis
2014
UpSet: Visualization of Intersecting Sets
10.1109/TVCG.2014.2346248
http://dx.doi.org/10.1109/TVCG.2014.2346248
1983
1992

J
Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.
Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.
Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;
10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183
Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data
InfoVis
2014
Visual Parameter Space Analysis: A Conceptual Framework
10.1109/TVCG.2014.2346321
http://dx.doi.org/10.1109/TVCG.2014.2346321
2161
2170

J
Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.
Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.
Univ. of Vienna, Vienna, Austria|c|;;;;
10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253
Parameter space analysis, input-output model, simulation, task characterization, literature analysis
InfoVis
2014
Visualizing Statistical Mix Effects and Simpson's Paradox
10.1109/TVCG.2014.2346297
http://dx.doi.org/10.1109/TVCG.2014.2346297
2132
2141

J
We discuss how ÔÇ£mix effectsÔÇØ can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as ÔÇ£omitted variable biasÔÇØ or, in extreme cases, as ÔÇ£Simpson's paradoxÔÇØ) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the ÔÇ£comet chart,ÔÇØ that is meant to ameliorate some of these issues.
Armstrong, Z.;Wattenberg, M.
;
10.1109/TVCG.2012.213;10.1109/TVCG.2007.70577
Mix effects, Omitted variable bias, Simpson's paradox, Statistics
SciVis
2014
A Robust Parity Test for Extracting Parallel Vectors in 3D
10.1109/TVCG.2014.2346412
http://dx.doi.org/10.1109/TVCG.2014.2346412
2526
2534

J
Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.
Tao Ju;Minxin Cheng;Xu Wang;Ye Duan
Washington Univ. in St. Louis, St. Louis, MO, USA|c|;;;
10.1109/VISUAL.2002.1183786;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1999.809896
Parallel vectors, feature curve extraction, ridges and valleys, parity test
SciVis
2014
ADR - Anatomy-Driven Reformation
10.1109/TVCG.2014.2346405
http://dx.doi.org/10.1109/TVCG.2014.2346405
2496
2505

J
Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.
Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.
Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;
10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351
Medical Visualization, Volume Reformation, Viewing Algorithms
SciVis
2014
Advection-Based Sparse Data Management for Visualizing Unsteady Flow
10.1109/TVCG.2014.2346418
http://dx.doi.org/10.1109/TVCG.2014.2346418
2555
2564

J
When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.
Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan
;;;;;;;
10.1109/TVCG.2009.154;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2013.144;10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551
Flow visualization, Data management, High performance visualization, Key-value store
SciVis
2014
Attractive Flicker: Guiding Attention in Dynamic Narrative Visualizations
10.1109/TVCG.2014.2346352
http://dx.doi.org/10.1109/TVCG.2014.2346352
2456
2465

J
Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first ÔÇ£orientation stageÔÇØ is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (ÔÇ£engagement stageÔÇØ) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.
Waldner, M.;Le Muzic, M.;Bernhard, M.;Purgathofer, W.;Viola, I.
;;;;
10.1109/TVCG.2009.185;10.1109/VISUAL.1995.480802;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2010.179;10.1109/TVCG.2011.183;10.1109/TVCG.2006.174
Visual attention, flicker, narrative visualization
SciVis
2014
Boundary Aware Reconstruction of Scalar Fields
10.1109/TVCG.2014.2346351
http://dx.doi.org/10.1109/TVCG.2014.2346351
2447
2455

J
In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.
Lindholm, S.;Jonsson, D.;Hansen, C.;Ynnerman, A.
Dept. of Sci. & Technol., Linkoping Univ., Linko&#x0308;ping, Sweden|c|;;;
10.1109/TVCG.2007.70518;10.1109/TVCG.2008.186;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2003.1250387
Reconstruction, signal processing, kernel regression, volume rendering
SciVis
2014
Characterizing Molecular Interactions in Chemical Systems
10.1109/TVCG.2014.2346403
http://dx.doi.org/10.1109/TVCG.2014.2346403
2476
2485

J
Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.
Gunther, D.;Boto, R.A.;Contreras-Garcia, J.;Piquemal, J.-P.;Tierny, J.
Inst. Mines-Telecom, Telecom ParisTech, Paris, France|c|;;;;
10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2008.110;10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2007.70578;10.1109/TVCG.2013.158
Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree
SciVis
2014
City Forensics: Using Visual Elements to Predict Non-Visual City Attributes
10.1109/TVCG.2014.2346446
http://dx.doi.org/10.1109/TVCG.2014.2346446
2624
2633

J
We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.
Arietta, S.M.;Efros, A.A.;Ramamoorthi, R.;Agrawala, M.
EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA|c|;;;

Data mining, big data, computational geography, visual processing
SciVis
2014
Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms
10.1109/TVCG.2014.2346406
http://dx.doi.org/10.1109/TVCG.2014.2346406
2506
2515

J
For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.
Glaber, S.;Lawonn, K.;Hoffmann, T.;Skalej, M.;Preim, B.
Dept. for Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;
10.1109/TVCG.2012.202;10.1109/TVCG.2007.70550;10.1109/VISUAL.1995.480795;10.1109/TVCG.2011.189
Aneurysm, IVUS, Wall Thickness, Wall Shear Stress, Brushing and Linking, Focus + Context
SciVis
2014
Conforming Morse-Smale Complexes
10.1109/TVCG.2014.2346434
http://dx.doi.org/10.1109/TVCG.2014.2346434
2595
2603

J
Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.
Gyulassy, A.;Gunther, D.;Levine, J.A.;Tierny, J.;Pascucci, V.
SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;
10.1109/TVCG.2011.249;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2012.228;10.1109/TVCG.2012.209;10.1109/VISUAL.2005.1532839
Computational Topology, Morse-Smale Complex, Data Analysis
SciVis
2014
Curve Boxplot: Generalization of Boxplot for Ensembles of Curves
10.1109/TVCG.2014.2346455
http://dx.doi.org/10.1109/TVCG.2014.2346455
2654
2663

J
In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.
Mirzargar, M.;Whitaker, R.T.;Kirby, R.M.
Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;
10.1109/TVCG.2013.143;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1996.568105;10.1109/TVCG.2013.141;10.1109/TVCG.2010.212;10.1109/TVCG.2013.126;10.1109/TVCG.2010.181
Uncertainty visualization, boxplots, ensemble visualization, order statistics, data depth, nonparametric statistic, functional data, parametric curves
SciVis
2014
Decomposition and Simplification of Multivariate Data using Pareto Sets
10.1109/TVCG.2014.2346447
http://dx.doi.org/10.1109/TVCG.2014.2346447
2684
2693

J
Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.
Huettenberger, L.;Heine, C.;Garth, C.
Tech. Univ. Kaiserslautern, Kaiserslautern, Denmark|c|;;
10.1109/TVCG.2012.228;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2009.120;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.2000.885716;10.1109/TVCG.2008.110
Multivariate Topology, Pareto Set, Simplification, Decomposition
SciVis
2014
Design and Evaluation of Interactive Proofreading Tools for Connectomics
10.1109/TVCG.2014.2346371
http://dx.doi.org/10.1109/TVCG.2014.2346371
2466
2475

J
Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.
Haehn, D.;Knowles-Barley, S.;Roberts, M.;Beyer, J.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.
Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;
10.1109/TVCG.2013.142;10.1109/TVCG.2012.240
Proofreading, Segmentation, Connectomics, Quantitative Evaluation
SciVis
2014
Escape Maps
10.1109/TVCG.2014.2346442
http://dx.doi.org/10.1109/TVCG.2014.2346442
2604
2613

J
We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.
Machado, G.;Sadlo, F.;Muller, T.;Ertl, T.
Univ. of Stuttgart, Stuttgart, Germany|c|;;;
10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2003.1250376
Streamline behavior, vector field topology, isocline surfaces, coronal hole extraction
SciVis
2014
Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields
10.1109/TVCG.2014.2346432
http://dx.doi.org/10.1109/TVCG.2014.2346432
2585
2594

J
Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.
Gunther, D.;Jacobson, A.;Reininghaus, J.;Seidel, H.-P.;Sorkine-Hornung, O.;Weinkauf, T.
Inst. Mines-Telecom, Paris, France|c|;;;;;
10.1109/TVCG.2012.228;10.1109/VISUAL.2001.964507
Numerical optimization, topology, scalar fields
SciVis
2014
Fixed-Rate Compressed Floating-Point Arrays
10.1109/TVCG.2014.2346458
http://dx.doi.org/10.1109/TVCG.2014.2346458
2674
2683

J
Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4d values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.
Lindstrom, P.
Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|
10.1109/TVCG.2006.143;10.1109/VISUAL.2001.964531;10.1109/TVCG.2006.186;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2012.209;10.1109/TVCG.2007.70516;10.1109/TVCG.2012.194;10.1109/VISUAL.1996.568138
Data compression, floating-point arrays, orthogonal block transform, embedded coding
SciVis
2014
FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis
10.1109/TVCG.2014.2346416
http://dx.doi.org/10.1109/TVCG.2014.2346416
2545
2554

J
In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.
Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li
Minist. of Educ., Peking Univ., Beijing, China|c|;;;;;
10.1109/TVCG.2008.131;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2006.165;10.1109/TVCG.2008.116;10.1109/TVCG.2006.164;10.1109/TVCG.2010.190;10.1109/TVCG.2011.246;10.1109/TVCG.2008.167;10.1109/TVCG.2009.112;10.1109/TVCG.2010.170;10.1109/TVCG.2013.133
Flow visualization, Topic model, Latent Dirichlet allocation (LDA)
SciVis
2014
Interactive Progressive Visualization with Space-Time Error Control
10.1109/TVCG.2014.2346319
http://dx.doi.org/10.1109/TVCG.2014.2346319
2397
2406

J
We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study.
Frey, S.;Sadlo, F.;Kwan-Liu Ma;Ertl, T.
Univ. of Stuttgart, Stuttgart, Germany|c|;;;
10.1109/VISUAL.1994.346321;10.1109/TVCG.2013.126;10.1109/VISUAL.2000.885702;10.1109/TVCG.2009.114
Progressive visualization, error-based frame control, interactive volume raycasting
SciVis
2014
Ligand Excluded Surface: A New Type of Molecular Surface
10.1109/TVCG.2014.2346404
http://dx.doi.org/10.1109/TVCG.2014.2346404
2486
2495

J
The most popular molecular surface in molecular visualization is the solvent excluded surface (SES). It provides information about the accessibility of a biomolecule for a solvent molecule that is geometrically approximated by a sphere. During a period of almost four decades, the SES has served for many purposes - including visualization, analysis of molecular interactions and the study of cavities in molecular structures. However, if one is interested in the surface that is accessible to a molecule whose shape differs significantly from a sphere, a different concept is necessary. To address this problem, we generalize the definition of the SES by replacing the probe sphere with the full geometry of the ligand defined by the arrangement of its van der Waals spheres. We call the new surface ligand excluded surface (LES) and present an efficient, grid-based algorithm for its computation. Furthermore, we show that this algorithm can also be used to compute molecular cavities that could host the ligand molecule. We provide a detailed description of its implementation on CPU and GPU. Furthermore, we present a performance and convergence analysis and compare the LES for several molecules, using as ligands either water or small organic molecules.
Lindow, N.;Baum, D.;Hege, H.-C.
Zuse Inst. Berlin, Berlin, Germany|c|;;
10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2013.158
Molecular visualization, solvent excluded surface, ligand excluded surface, cavity analysis
SciVis
2014
Low-Pass Filtered Volumetric Shadows
10.1109/TVCG.2014.2346333
http://dx.doi.org/10.1109/TVCG.2014.2346333
2437
2446

J
We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.
Ament, M.;Sadlo, F.;Dachsbacher, C.;Weiskopf, D.
Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;;;
10.1109/TVCG.2013.172;10.1109/TVCG.2013.129;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764
Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table
SciVis
2014
Multi-Charts for Comparative 3D Ensemble Visualization
10.1109/TVCG.2014.2346448
http://dx.doi.org/10.1109/TVCG.2014.2346448
2694
2703

J
A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.
Demir, I.;Dick, C.;Westermann, R.
Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Garching, Germany|c|;;
10.1109/TVCG.2013.143;10.1109/VISUAL.2000.885739;10.1109/TVCG.2006.159;10.1109/TVCG.2008.139;10.1109/TVCG.2007.70518;10.1109/TVCG.2010.181;10.1109/TVCG.2009.198;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809921
Ensemble visualization, brushing and linking, statistical analysis
SciVis
2014
Multiscale Symmetry Detection in Scalar Fields by Clustering Contours
10.1109/TVCG.2014.2346332
http://dx.doi.org/10.1109/TVCG.2014.2346332
2427
2436

J
The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.
Thomas, D.M.;Natarajan, V.
Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;
10.1109/TVCG.2013.142;10.1109/VISUAL.1999.809869;10.1109/TVCG.2006.149;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.258;10.1109/TVCG.2013.148
Scalar field visualization, symmetry detection, contour tree, data exploration
SciVis
2014
Predicate-Based Focus-and-Context Visualization for 3D Ultrasound
10.1109/TVCG.2014.2346317
http://dx.doi.org/10.1109/TVCG.2014.2346317
2379
2387

J
Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes.
Schulte zu Berge, C.;Baust, M.;Kapoor, A.;Navab, N.
Dept. of Comput.-Aided Med. Procedures, Tech. Univ. Munchen, Mu&#x0308;nchen, Germany|c|;;;
10.1109/TVCG.2006.148;10.1109/TVCG.2006.124;10.1109/TVCG.2013.189;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2001.964539
Direct Volume Rendering, Ultrasound, Classification, Predicate Function, User Interface
SciVis
2014
Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering
10.1109/TVCG.2014.2346324
http://dx.doi.org/10.1109/TVCG.2014.2346324
2417
2426

J
This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs.
Sicat, R.;Kruger, J.;Moller, T.;Hadwiger, M.
King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;
10.1109/TVCG.2006.143;10.1109/TVCG.2012.240;10.1109/VISUAL.1999.809908
Multi-resolution representations, sparse approximation, pursuit algorithms, large-scale volume rendering
SciVis
2014
Stent Maps - Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations
10.1109/TVCG.2014.2346459
http://dx.doi.org/10.1109/TVCG.2014.2346459
2704
2713

J
Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data- is an appropriate input for statistical group evaluation and machine learning methods.
Born, S.;Sundermann, S.H.;Russ, C.;Hopf, R.;Ruiz, C.E.;Falk, V.;Gessat, M.
Univ. of Zurich, Zurich, Switzerland|c|;;;;;;
10.1109/TVCG.2009.169;10.1109/TVCG.2007.70550;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.235;10.1109/TVCG.2013.139;10.1109/VISUAL.2003.1250353
Comparative visualization, medical visualization, vessel flattening, transcatheter aortic valve implantation (TAVI)
SciVis
2014
Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets
10.1109/TVCG.2014.2346423
http://dx.doi.org/10.1109/TVCG.2014.2346423
2565
2574

J
Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.
Sauer, F.;Hongfeng Yu;Kwan-Liu Ma
Univ. of California, Davis, Davis, CA, USA|c|;;
10.1109/VISUAL.1997.663930;10.1109/VISUAL.1996.567807;10.1109/TVCG.2007.70599;10.1109/VISUAL.2003.1250374;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1998.745288
Feature extraction and tracking, particle data, volume data, particle trajectories, flow visualization
SciVis
2014
Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections
10.1109/TVCG.2014.2346451
http://dx.doi.org/10.1109/TVCG.2014.2346451
2644
2653

J
In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.
Schroeder, D.;Korsakov, F.;Knipe, C.M.-P.;Thorson, L.;Ellingson, A.M.;Nuckley, D.;Carlis, J.V.;Keefe, D.F.
Univ. of Minnesota, Minneapolis, MN, USA|c|;;;;;;;
10.1109/TVCG.2013.178;10.1109/TVCG.2009.152;10.1109/VAST.2011.6102454;10.1109/TVCG.2010.223;10.1109/VISUAL.2001.964496;10.1109/TVCG.2007.70518;10.1109/VAST.2009.5332593;10.1109/VISUAL.2005.1532857
Design studies, focus + context techniques, integrating spatial and non-spatial data visualization, visual design, biomedical and medical visualization
SciVis
2014
Using Topological Analysis to Support Event-Guided Exploration in Urban Data
10.1109/TVCG.2014.2346449
http://dx.doi.org/10.1109/TVCG.2014.2346449
2634
2643

J
The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.
Doraiswamy, H.;Ferreira, N.;Damoulas, T.;Freire, J.;Silva, C.T.
New York Univ., New York, NY, USA|c|;;;;
10.1109/TVCG.2013.130;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677356;10.1109/VISUAL.2004.96;10.1109/TVCG.2013.179;10.1109/TVCG.2006.186;10.1109/VAST.2008.4677354;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102454;10.1109/TVCG.2013.131
Computational topology, event detection, spatio-temporal index, urban data, visual exploration
SciVis
2014
ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization
10.1109/TVCG.2014.2346318
http://dx.doi.org/10.1109/TVCG.2014.2346318
2388
2396

J
Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.
Rautek, P.;Bruckner, S.;Groller, E.;Hadwiger, M.
KAUST, Thuwal, Saudi Arabia|c|;;;
10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.174;10.1109/TVCG.2014.2346322;10.1109/VISUAL.2004.95;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1992.235202;10.1109/TVCG.2008.184
Domain-specific languages, Volume visualization, Volume visualization framework
SciVis
2014
Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields
10.1109/TVCG.2014.2346411
http://dx.doi.org/10.1109/TVCG.2014.2346411
2516
2525

J
Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.
Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.
Univ. of Maryland, College Park, MD, USA|c|;;;
10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148
Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields
SciVis
2014
Visualization of Regular Maps: The Chase Continues
10.1109/TVCG.2014.2352952
http://dx.doi.org/10.1109/TVCG.2014.2352952
2614
2623

J
A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface.
van Wijk, J.J.
Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|

regular maps, tiling, tessellation, surface topology, mathematical visualization
SciVis
2014
Visualizing 2-dimensional Manifolds with Curve Handles in 4D
10.1109/TVCG.2014.2346425
http://dx.doi.org/10.1109/TVCG.2014.2346425
2575
2584

J
In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.
Hui Zhang;Jianguang Weng;Guangchen Ruan
Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;
10.1109/TVCG.2012.242;10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2010.151;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2007.70593
math visualization, 4D, deformation, Reidemeister theorem
SciVis
2014
Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems
10.1109/TVCG.2014.2346322
http://dx.doi.org/10.1109/TVCG.2014.2346322
2407
2416

J
As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.
Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;Hildebrand, D.G.C.;Pfister, H.;Won-Ki Jeong
;;;;;
10.1109/VISUAL.2004.95
Domain-specific language, volume rendering, GPU computing, distributed heterogeneous systems
SciVis
2014
Volume-Preserving Mapping and Registration for Collective Data Visualization
10.1109/TVCG.2014.2346457
http://dx.doi.org/10.1109/TVCG.2014.2346457
2664
2673

J
In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization.
Jiaxi Hu;Zou, G.J.;Jing Hua
Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;
10.1109/TVCG.2008.134;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183795;10.1109/TVCG.2011.171
Volume-preserving mapping, data regularization, data transformation
SciVis
2014
Vortex Cores of Inertial Particles
10.1109/TVCG.2014.2346415
http://dx.doi.org/10.1109/TVCG.2014.2346415
2535
2544

J
The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.
Gunther, T.;Theisel, H.
;
10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296
Inertial particles, flow visualization, vortex cores
VAST
2014
#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media
10.1109/TVCG.2014.2346922
http://dx.doi.org/10.1109/TVCG.2014.2346922
1773
1782

J
We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.
Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Collins, C.
Univ. of Toronto, Toronto, ON, Canada|c|;;;;;
10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162
Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization
VAST
2014
A Five-Level Design Framework for Bicluster Visualizations
10.1109/TVCG.2014.2346665
http://dx.doi.org/10.1109/TVCG.2014.2346665
1713
1722

J
Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.
Maoyuan Sun;North, C.;Ramakrishnan, N.
Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;
10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582
Biclusters, interactive visual analytics, coordinated relationships, design framework
VAST
2014
A System for Visual Analysis of Radio Signal Data
10.1109/VAST.2014.7042479
http://dx.doi.org/10.1109/VAST.2014.7042479
33
42

C
Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform.
Crnovrsanin, T.;Muelder, C.;Kwan-Liu Ma
VIDi @ U. C. Davis|c|;;
10.1109/TVCG.2012.286;10.1109/VAST.2009.5332596;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1998.745302;10.1109/VAST.2009.5332593
Intelligence Analysis, Coordinated and Multiple Views, Time-varying data, Geographic/Geospatial Visualization
VAST
2014
A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads
10.1109/VAST.2014.7042486
http://dx.doi.org/10.1109/VAST.2014.7042486
103
112

C
Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (> 30GB) show that our system performs well for on-demand transport assessment and reasoning.
Fei Wang;Wei Chen;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao
State Key Lab of CAD&CG, Zhejiang University|c|;;;;;;;;
10.1109/VAST.2011.6102458;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.179;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.133
Road-based Query, Taxi Trajectory, Hash Index, Visual Analysis
VAST
2014
An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics
10.1109/VAST.2014.7042482
http://dx.doi.org/10.1109/VAST.2014.7042482
63
72

C
We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.
Gomez, S.R.;Hua Guo;Ziemkiewicz, C.;Laidlaw, D.H.
Brown University|c|;;;
10.1109/TVCG.2012.233;10.1109/TVCG.2007.70617;10.1109/TVCG.2013.124;10.1109/TVCG.2010.154;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.128;10.1109/TVCG.2011.185;10.1109/TVCG.2010.163;10.1109/TVCG.2013.120
Evaluation methodology, insight-based evaluation, visual analytics, network visualization, information visualization
VAST
2014
An Integrated Visual Analysis System for Fusing MR Spectroscopy and Multi-Modal Radiology Imaging
10.1109/VAST.2014.7042481
http://dx.doi.org/10.1109/VAST.2014.7042481
53
62

C
For cancers such as glioblastoma multiforme, there is an increasing interest in defining biological target volumes
 (BTV)
 high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques
 like positron emission tomography
 the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless
VAST
2014
Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration
10.1109/VAST.2014.7042484
http://dx.doi.org/10.1109/VAST.2014.7042484
83
92

C
This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.
Sungahn Ko;Afzal, S.;Walton, S.;Yang Yang;Junghoon Chae;Malik, A.;Yun Jang;Min Chen;Ebert, D.
Purdue University|c|;;;;;;;;
10.1109/VAST.2012.6400554;10.1109/TVCG.2010.150;10.1109/TVCG.2007.70582;10.1109/TVCG.2011.190;10.1109/VAST.2011.6102440;10.1109/TVCG.2009.143;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389013

VAST
2014
Baseball4D: A Tool for Baseball Game Reconstruction & Visualization
10.1109/VAST.2014.7042478
http://dx.doi.org/10.1109/VAST.2014.7042478
23
32

C
While many sports use statistics and video to analyze and improve game play, baseball has led the charge throughout its history. With the advent of new technologies that allow all players and the ball to be tracked across the entire field, it is now possible to bring this understanding to another level. From discrete positions across time, we present techniques to reconstruct entire baseball games and visually explore each play. This provides opportunities to not only derive new metrics for the game, but also allow us to investigate existing measures with targeted visualizations. In addition, our techniques allow users to filter on demand so specific situations can be analyzed both in general and according to those situations. We show that gameplay can be accurately reconstructed from the raw position data and discuss how visualization and statistical methods can combine to better inform baseball analyses.
Dietrich, C.;Koop, D.;Huy T. Vo;Silva, C.T.
;;;
10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/TVCG.2012.225;10.1109/VISUAL.2001.964496
sports visualization, sports analytics, baseball, game reconstruction, baseball metrics, event data
VAST
2014
BoundarySeer: Visual Analysis of 2D Boundary Changes
10.1109/VAST.2014.7042490
http://dx.doi.org/10.1109/VAST.2014.7042490
143
152

C
Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.
Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Groller, E.;Lionel Ni
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;
10.1109/TVCG.2013.230;10.1109/INFVIS.2004.27;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.239;10.1109/TVCG.2008.166;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2013.213;10.1109/TVCG.2012.265;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70561
Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization
VAST
2014
ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery
10.1109/TVCG.2014.2346752
http://dx.doi.org/10.1109/TVCG.2014.2346752
1883
1892

J
Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.
Partl, C.;Lex, A.;Streit, M.;Strobelt, H.;Wassermann, A.-M.;Pfister, H.;Schmalstieg, D.
Graz Univ. of Technol., Graz, Austria|c|;;;;;;
10.1109/TVCG.2013.167;10.1109/TVCG.2012.213;10.1109/TVCG.2012.252;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/TVCG.2013.223
Multi-relational data, visual data analysis, drug discovery
VAST
2014
Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees
10.1109/TVCG.2014.2346626
http://dx.doi.org/10.1109/TVCG.2014.2346626
1693
1702

J
Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.
Beham, M.;Herzner, W.;Groller, M.E.;Kehrer, J.
Austrian Inst. of Technol., Vienna Univ. of Technol., Vienna, Austria|c|;;;
10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581
Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis
VAST
2014
DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data
10.1109/TVCG.2014.2346682
http://dx.doi.org/10.1109/TVCG.2014.2346682
1783
1792

J
Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.
Gotz, D.;Stavropoulos, H.
Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA|c|;
10.1109/TVCG.2013.206;10.1109/TVCG.2012.225;10.1109/TVCG.2011.179;10.1109/INFVIS.2000.885097;10.1109/VAST.2009.5332595;10.1109/VAST.2010.5652890;10.1109/TVCG.2009.117;10.1109/VAST.2006.261421;10.1109/TVCG.2013.200
Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics
VAST
2014
DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios
10.1109/TVCG.2014.2346747
http://dx.doi.org/10.1109/TVCG.2014.2346747
1823
1832

J
We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.
Madhavan, K.;Elmqvist, N.;Vorvoreanu, M.;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Johri, A.
Purdue Univ., West Lafayette, IN, USA|c|;;;;;;;
10.1109/TVCG.2007.70541;10.1109/TVCG.2011.174;10.1109/TVCG.2010.177;10.1109/TVCG.2012.255;10.1109/TVCG.2009.123;10.1109/TVCG.2013.223;10.1109/INFVIS.2001.963283;10.1109/TVCG.2012.213;10.1109/VAST.2008.4677361
visual analytics, portfolio mining, web-based visualization, casual visualization, design study
VAST
2014
EvoRiver: Visual Analysis of Topic Coopetition on Social Media
10.1109/TVCG.2014.2346919
http://dx.doi.org/10.1109/TVCG.2014.2346919
1753
1762

J
Cooperation and competition (jointly called ÔÇ£coopetitionÔÇØ) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., ÔÇ£topic leadersÔÇØ) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).
Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang
;;;;;
10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162
Topic coopetition, information diffusion, information propagation, time-based visualization
VAST
2014
Feature-Driven Visual Analytics of Soccer Data
10.1109/VAST.2014.7042477
http://dx.doi.org/10.1109/VAST.2014.7042477
13
22

C
Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach.
Janetzko, H.;Sacha, D.;Stein, M.;Schreck, T.;Deussen, O.;Keim, D.
University of Konstanz|c|;;;;;
10.1109/TVCG.2012.263;10.1109/VAST.2008.4677350;10.1109/TVCG.2007.70621;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/TVCG.2013.207;10.1109/TVCG.2013.186
Visual Analytics, Sport Analytics, Soccer Analysis
VAST
2014
Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier
10.1109/VAST.2014.7042480
http://dx.doi.org/10.1109/VAST.2014.7042480
43
52

C
The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.
Behrisch, M.;Korkmaz, F.;Lin Shao;Schreck, T.
Universit&#x00E4;t Konstanz, Germany|c|;;;
10.1109/INFVIS.2005.1532142;10.1109/TVCG.2012.277;10.1109/TVCG.2010.184;10.1109/VAST.2012.6400486;10.1109/VAST.2007.4389001;10.1109/TVCG.2013.160;10.1109/VAST.2012.6400488
View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model
VAST
2014
Finding Waldo: Learning about Users from their Interactions
10.1109/TVCG.2014.2346575
http://dx.doi.org/10.1109/TVCG.2014.2346575
1663
1672

J
Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.
Brown, E.T.;Ottley, A.;Zhao, H.;Quan Lin;Souvenir, R.;Endert, A.;Chang, R.
Tufts Univ., Medford, MA, USA|c|;;;;;;
10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352
User Interactions, Analytic Provenance, Visualization, Applied Machine Learning
VAST
2014
Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking
10.1109/TVCG.2014.2346743
http://dx.doi.org/10.1109/TVCG.2014.2346743
1793
1802

J
Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity ÔÇ£discoverage,ÔÇØ discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.
Isaacs, E.;Damico, K.;Ahern, S.;Bart, E.;Singhal, M.
;;;;
10.1109/VAST.2009.5333443;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4389006;10.1109/INFVIS.2001.963287;10.1109/TVCG.2007.70589;10.1109/VAST.2006.261426;10.1109/TVCG.2007.70577
discovery search visualization, visual cues, discoverage, coverage tracking, document triage, interactive histograms
VAST
2014
Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks
10.1109/TVCG.2014.2346753
http://dx.doi.org/10.1109/TVCG.2014.2346753
1903
1912

J
Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).
Bowen Yu;Doraiswamy, H.;Xi Chen;Miraldi, E.;Arrieta-Ortiz, M.L.;Hafemeister, C.;Madar, A.;Bonneau, R.;Silva, C.T.
Sch. of Eng., NYU Polytech., New York, NY, USA|c|;;;;;;;;
10.1109/TVCG.2008.117;10.1109/TVCG.2009.146;10.1109/TVCG.2011.185;10.1109/TVCG.2009.167
Web-based visualization, gene regulatory network
VAST
2014
HydroQual: Visual Analysis of River Water Quality
10.1109/VAST.2014.7042488
http://dx.doi.org/10.1109/VAST.2014.7042488
123
132

C
Economic development based on industrialization, intensive agriculture expansion and population growth places greater pressure on water resources through increased water abstraction and water quality degradation [40]. River pollution is now a visible issue, with emblematic ecological disasters following industrial accidents such as the pollution of the Rhine river in 1986 [31]. River water quality is a pivotal public health and environmental issue that has prompted governments to plan initiatives for preserving or restoring aquatic ecosystems and water resources [56]. Water managers require operational tools to help interpret the complex range of information available on river water quality functioning. Tools based on statistical approaches often fail to resolve some tasks due to the sparse nature of the data. Here we describe HydroQual, a tool to facilitate visual analysis of river water quality. This tool combines spatiotemporal data mining and visualization techniques to perform tasks defined by water experts. We illustrate the approach with a case study that illustrates how the tool helps experts analyze water quality. We also perform a qualitative evaluation with these experts.
Accorsi, P.;Fabregue, M.;Sallaberry, A.;Cernesson, F.;Lalande, N.;Braud, A.;Bringay, S.;Le Ber, F.;Poncelet, P.;Teisseire, M.
LIRMM, Univ. Montpellier 2, Montpellier, France|c|;;;;;;;;;
10.1109/VISUAL.1996.568146;10.1109/INFVIS.2000.885097
Visual Analytics, Spatiotemporal Data Mining and Visualization, Water Quality
VAST
2014
INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data
10.1109/TVCG.2014.2346482
http://dx.doi.org/10.1109/TVCG.2014.2346482
1614
1623

J
Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.
Krause, J.;Perer, A.;Bertini, E.
;;
10.1109/INFVIS.2004.71;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2011.229;10.1109/VAST.2011.6102448;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102453;10.1109/TVCG.2013.125;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652443
Predictive modeling, feature selection, classification, visual analytics, high-dimensional data
VAST
2014
Integrating Predictive Analytics and Social Media
10.1109/VAST.2014.7042495
http://dx.doi.org/10.1109/VAST.2014.7042495
193
202

C
A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.
Yafeng Lu; Kruger, R.;Thom, D.;Feng Wang;Koch, S.;Ertl, T.;Maciejewski, R.
Arizona State Univ., Tempe, AZ, USA|c|;;;;;;
10.1109/VAST.2012.6400557;10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/TVCG.2013.125;10.1109/INFVIS.2004.10;10.1109/VAST.2011.6102448;10.1109/VAST.2010.5652443;10.1109/INFVIS.2004.3
Social Media, Predictive Analytics, Feature Selection
VAST
2014
Interactive Visual Analysis of Image-Centric Cohort Study Data
10.1109/TVCG.2014.2346591
http://dx.doi.org/10.1109/TVCG.2014.2346591
1673
1682

J
Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.
Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.
Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany|c|;;;;;
10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569
Interactive Visual Analysis, Epidemiology, Spine
VAST
2014
Knowledge Generation Model for Visual Analytics
10.1109/TVCG.2014.2346481
http://dx.doi.org/10.1109/TVCG.2014.2346481
1604
1613

J
Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.
Sacha, D.;Stoffel, A.;Stoffel, F.;Bum Chul Kwon;Ellis, G.;Keim, D.A.
Data Anal. & Visualization Group, Univ. of Konstanz, Konstanz, Germany|c|;;;;;
10.1109/VISUAL.2005.1532781;10.1109/TVCG.2013.124;10.1109/VAST.2009.5333023;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677365;10.1109/VAST.2010.5652879;10.1109/TVCG.2012.273;10.1109/VAST.2008.4677358;10.1109/TVCG.2008.121;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102435;10.1109/TVCG.2013.120
Visual Analytics, Knowledge Generation, Reasoning, Visualization Taxonomies and Models, Interaction
VAST
2014
LoyalTracker: Visualizing Loyalty Dynamics in Search Engines
10.1109/TVCG.2014.2346912
http://dx.doi.org/10.1109/TVCG.2014.2346912
1733
1742

J
The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.
Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;
10.1109/VAST.2010.5652931;10.1109/TVCG.2009.171;10.1109/VAST.2007.4389008;10.1109/TVCG.2012.253;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2012.225;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400494;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.166
Time-series visualization, stacked graphs, log data visualization, text visualization
VAST
2014
Multi-Model Semantic Interaction for Text Analytics
10.1109/VAST.2014.7042492
http://dx.doi.org/10.1109/VAST.2014.7042492
163
172

C
Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.
Bradel, L.;North, C.;House, l.;Leman, S.
;;;
10.1109/VAST.2011.6102449;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400559;10.1109/VAST.2012.6400486;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389006
Visual analytics, Semantic Interaction, Sensemaking, Text Analytics
VAST
2014
Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations
10.1109/TVCG.2014.2346578
http://dx.doi.org/10.1109/TVCG.2014.2346578
1643
1652

J
An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.
Muhlbacher, T.;Piringer, H.;Gratzl, S.;Sedlmair, M.;Streit, M.
VRVis Res. Center, Vienna, Austria|c|;;;;
10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229
Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision
VAST
2014
OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media
10.1109/TVCG.2014.2346920
http://dx.doi.org/10.1109/TVCG.2014.2346920
1763
1772

J
It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.
Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu
Microsoft Res., Redmond, WA, USA|c|;;;;
10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919
Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail
VAST
2014
PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media
10.1109/VAST.2014.7042496
http://dx.doi.org/10.1109/VAST.2014.7042496
203
212

C
Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person's demographics and opinions, but also reveal one's emotional style. Emotional style captures a person's patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one's emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person's emotional style derived from this person's social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person's expressed emotions at different time points and summarize those emotions to reveal the person's emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one's emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results.
Jian Zhao;Liang Gou;Fei Wang;Zhou, M.X.
;;;
10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2010.129;10.1109/TVCG.2011.185;10.1109/TVCG.2010.183
Personal emotion analytics, affective and mood modeling, social media text, Twitter, information visualization
VAST
2014
Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement
10.1109/TVCG.2014.2346926
http://dx.doi.org/10.1109/TVCG.2014.2346926
1863
1872

J
In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.
Malik, A.;Maciejewski, R.;Towers, S.;McCullough, S.;Ebert, D.S.
Purdue Univ., West Lafayette, IN, USA|c|;;;;
10.1109/TVCG.2013.125;10.1109/TVCG.2013.206;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.200
Visual Analytics, Natural Scales, Seasonal Trend decomposition based on Loess (STL), Law Enforcement
VAST
2014
Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics
10.1109/TVCG.2014.2346574
http://dx.doi.org/10.1109/TVCG.2014.2346574
1653
1662

J
As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.
Stolper, C.D.;Perer, A.;Gotz, D.
Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;
10.1109/VAST.2006.261421;10.1109/TVCG.2013.227;10.1109/TVCG.2009.187;10.1109/TVCG.2011.179;10.1109/INFVIS.2005.1532133;10.1109/TVCG.2012.225;10.1109/TVCG.2013.179;10.1109/INFVIS.2000.885097;10.1109/TVCG.2013.200
Progressive visual analytics, information visualization, interactive machine learning, electronic medical records
VAST
2014
Run Watchers: Automatic Simulation-Based Decision Support in Flood Management
10.1109/TVCG.2014.2346930
http://dx.doi.org/10.1109/TVCG.2014.2346930
1873
1882

J
In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.
Konev, A.;Waser, J.;Sadransky, B.;Cornel, D.;Perdigao, R.A.P.;Horvath, Z.;Groller, M.E.
VRVis Vienna, Vienna, Austria|c|;;;;;;
10.1109/INFVIS.2002.1173149;10.1109/VISUAL.2000.885727;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/TVCG.2010.223;10.1109/TVCG.2008.145
Disaster management, simulation control, decision making, visual evidence, storytelling
VAST
2014
Serendip: Topic Model-Driven Visual Exploration of Text Corpora
10.1109/VAST.2014.7042493
http://dx.doi.org/10.1109/VAST.2014.7042493
173
182

C
Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.
Alexander, E.;Kohlmann, J.;Valenza, R.;Witmore, M.;Gleicher, M.
Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;;;
10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1998.729568;10.1109/TVCG.2011.239;10.1109/TVCG.2011.220;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.157;10.1109/TVCG.2013.162;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389004
Text visualization, topic modeling
VAST
2014
Supporting Communication and Coordination in Collaborative Sensemaking
10.1109/TVCG.2014.2346573
http://dx.doi.org/10.1109/TVCG.2014.2346573
1633
1642

J
When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.
Mahyar, N.;Tory, M.
Univ. of Victoria, Victoria, BC, Canada|c|;
10.1109/VAST.2009.5333245;10.1109/VAST.2006.261439;10.1109/VAST.2008.4677358;10.1109/TVCG.2013.197;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878;10.1109/VAST.2006.261430;10.1109/VAST.2007.4389011;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102447
Sensemaking, Collaboration, Externalization, Linked common work, Collaborative thinking space
VAST
2014
The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals
10.1109/TVCG.2014.2346754
http://dx.doi.org/10.1109/TVCG.2014.2346754
1913
1922

J
Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the cur- ent workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.
Lujan Ganuza, M.;Ferracutti, G.;Gargiulo, M.F.;Castro, S.M.;Bjerg, E.;Groller, E.;Matkovic, K.
VyGLab Res. Lab., Univ. Nac. del Sur, Bahia Blanca, Argentina|c|;;;;;;
10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.155;10.1109/VISUAL.1995.485139
Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies
VAST
2014
TopicPanorama: A Full Picture of Relevant Topics
10.1109/VAST.2014.7042494
http://dx.doi.org/10.1109/VAST.2014.7042494
183
192

C
We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.
Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo
;;;;
10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919
Topic graph, graph matching, graph visualization, user interactions, level-of-detail
VAST
2014
Towards Interactive, Intelligent, and Integrated Multimedia Analytics
10.1109/VAST.2014.7042476
http://dx.doi.org/10.1109/VAST.2014.7042476
3
12

C
The size and importance of visual multimedia collections grew rapidly over the last years, creating a need for sophisticated multimedia analytics systems enabling large-scale, interactive, and insightful analysis. These systems need to integrate the human's natural expertise in analyzing multimedia with the machine's ability to process large-scale data. The paper starts off with a comprehensive overview of representation, learning, and interaction techniques from both the human's and the machine's point of view. To this end, hundreds of references from the related disciplines (visual analytics, information visualization, computer vision, multimedia information retrieval) have been surveyed. Based on the survey, a novel general multimedia analytics model is synthesized. In the model, the need for semantic navigation of the collection is emphasized and multimedia analytics tasks are placed on the exploration-search axis. The axis is composed of both exploration and search in a certain proportion which changes as the analyst progresses towards insight. Categorization is proposed as a suitable umbrella task realizing the exploration-search axis in the model. Finally, the pragmatic gap, defined as the difference between the tight machine categorization model and the flexible human categorization model is identified as a crucial multimedia analytics topic.
Zahlka, J.;Worring, M.
University of Amsterdam|c|;
10.1109/VAST.2006.261425;10.1109/VAST.2007.4389003;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.136;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70541;10.1109/TVCG.2013.168
Multimedia (image/video/music) visualization, machine learning
VAST
2014
Transforming Scagnostics to Reveal Hidden Features
10.1109/TVCG.2014.2346572
http://dx.doi.org/10.1109/TVCG.2014.2346572
1624
1632

J
Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.
Tuan Nhon Dang;Wilkinson, L.
Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;
10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.187;10.1109/TVCG.2011.167;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006
Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics
VAST
2014
Using Visualizations to Monitor Changes and Harvest Insights from a Global-Scale Logging Infrastructure at Twitter
10.1109/VAST.2014.7042487
http://dx.doi.org/10.1109/VAST.2014.7042487
113
122

C
Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter.
Wongsuphasawat, K.;Lin, J.
Twitter, Inc.|c|;
10.1109/INFVIS.2000.885091;10.1109/TVCG.2009.117;10.1109/INFVIS.1997.636718;10.1109/VAST.2007.4389008;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70529;10.1109/VAST.2012.6400494;10.1109/TVCG.2013.231;10.1109/INFVIS.2004.64;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421;10.1109/TVCG.2011.185
Information Visualization, Visual Analytics, Log Analysis, Log Visualization, Session Analysis, Funnel Analysis
VAST
2014
VAET: A Visual Analytics Approach for E-Transactions Time-Series
10.1109/TVCG.2014.2346913
http://dx.doi.org/10.1109/TVCG.2014.2346913
1743
1752

J
Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.
Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Barlowe, S.;Jing Yang
State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;;;;
10.1109/TVCG.2009.123;10.1109/VAST.2007.4389009;10.1109/TVCG.2012.212;10.1109/INFVIS.1995.528685;10.1109/VAST.2012.6400494;10.1109/TVCG.2010.162;10.1109/TVCG.2009.180
Time-Series, Visual Analytics, E-transaction
VAST
2014
VarifocalReader -- In-Depth Visual Analysis of Large Text Documents
10.1109/TVCG.2014.2346677
http://dx.doi.org/10.1109/TVCG.2014.2346677
1723
1732

J
Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.
Koch, S.;John, M.;Worner, M.;Muller, A.;Ertl, T.
Inst. of Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;
10.1109/VAST.2010.5652926;10.1109/TVCG.2008.172;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.188;10.1109/TVCG.2007.70577;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/TVCG.2009.165;10.1109/TVCG.2013.162;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333248;10.1109/TVCG.2012.260;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333919;10.1109/VAST.2007.4389004
visual analytics, document analysis, literary analysis, natural language processing, text mining, machine learning, distant reading
VAST
2014
VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure
10.1109/TVCG.2014.2346911
http://dx.doi.org/10.1109/TVCG.2014.2346911
1853
1862

J
We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.
Sungahn Ko;Jieqiong Zhao;Jing Xia;Afzal, S.;Xiaoyu Wang;Abram, G.;Elmqvist, N.;Kne, L.;Van Riper, D.;Gaither, K.;Kennedy, S.;Tolone, W.;Ribarsky, W.;Ebert, D.S.
Purdue Univ. in West Lafayette, West Lafayette, IN, USA|c|;;;;;;;;;;;;;
10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.225;10.1109/TVCG.2012.260;10.1109/TVCG.2007.70541;10.1109/TVCG.2010.223;10.1109/TVCG.2013.146;10.1109/TVCG.2010.171;10.1109/VAST.2011.6102460;10.1109/VAST.2011.6102457
Computational steering, visual analytics, critical infrastructure, homeland security

2014
Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes
10.1109/VAST.2014.7042489
http://dx.doi.org/10.1109/VAST.2014.7042489
133
142

C
We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.
Jie Li;Kang Zhang;Zhao-Peng Meng
Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China|c|;;
10.1109/VAST.2012.6400491;10.1109/TVCG.2010.194;10.1109/INFVIS.2000.885098;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.199;10.1109/TVCG.2010.183;10.1109/VAST.2012.6400553;10.1109/TVCG.2010.180;10.1109/TVCG.2009.197
climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics
VAST
2014
Visual Abstraction and Exploration of Multi-class Scatterplots
10.1109/TVCG.2014.2346594
http://dx.doi.org/10.1109/TVCG.2014.2346594
1683
1692

J
Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.
Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma
State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;
10.1109/TVCG.2013.150;10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745301;10.1109/TVCG.2008.120;10.1109/TVCG.2010.197;10.1109/TVCG.2006.187;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.180;10.1109/INFVIS.2004.52;10.1109/VAST.2010.5652460;10.1109/TVCG.2009.112;10.1109/TVCG.2009.122;10.1109/TVCG.2011.181;10.1109/TVCG.2012.238;10.1109/TVCG.2010.176;10.1109/TVCG.2013.212;10.1109/TVCG.2011.261;10.1109/TVCG.2008.153;10.1109/TVCG.2013.183
Scatterplot, overdraw reduction, sampling, visual abstraction
VAST
2014
Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs
10.1109/VAST.2014.7042485
http://dx.doi.org/10.1109/VAST.2014.7042485
93
102

C
Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.
Lenz, O.;Keul, F.;Bremm, S.;Hamacher, K.;von Landesberger, T.
GRIS, TU Darmstadt|c|;;;;
10.1109/TVCG.2013.225;10.1109/VAST.2011.6102439;10.1109/VAST.2009.5333893;10.1109/TVCG.2009.167;10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70529
Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization
VAST
2014
Visual Analysis of Public Utility Service Problems in a Metropolis
10.1109/TVCG.2014.2346898
http://dx.doi.org/10.1109/TVCG.2014.2346898
1843
1852

J
Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.
Jiawan Zhang;Yanli, E.;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan
Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China|c|;;;;;;;
10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400556;10.1109/TVCG.2013.228;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677356;10.1109/TVCG.2012.291;10.1109/TVCG.2013.132;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/VAST.2011.6102460;10.1109/TVCG.2009.122
utility services, evidence-based decision making, visual analytics, aggregate
VAST
2014
Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles
10.1109/TVCG.2014.2346751
http://dx.doi.org/10.1109/TVCG.2014.2346751
1893
1902

J
Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.
Kothur, P.;Sips, M.;Dobslaw, H.;Dransch, D.
GFZ German Res. Centre for Geosci., Potsdam, Germany|c|;;;
10.1109/TVCG.2012.190;10.1109/TVCG.2012.284;10.1109/TVCG.2008.139
Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics
VAST
2014
Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles
10.1109/TVCG.2014.2346744
http://dx.doi.org/10.1109/TVCG.2014.2346744
1803
1812

J
In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a nai╠êve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the ÔÇ£bestÔÇØ points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.
Matkovic, K.;Gracanin, D.;Splechtna, R.;Jelovic, M.;Stehno, B.;Hauser, H.;Purgathofer, W.
VRVis Res. Center, Vienna, Austria|c|;;;;;;
10.1109/TVCG.2010.223;10.1109/TVCG.2012.280;10.1109/TVCG.2008.145;10.1109/TVCG.2009.110;10.1109/TVCG.2010.171
Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization
VAST
2014
Visual Exploration of Sparse Traffic Trajectory Data
10.1109/TVCG.2014.2346746
http://dx.doi.org/10.1109/TVCG.2014.2346746
1813
1822

J
In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.
Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu
Peking Univ., Beijing, China|c|;;;;;;
10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265
Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion
VAST
2014
Visual Methods for Analyzing Probabilistic Classification Data
10.1109/TVCG.2014.2346660
http://dx.doi.org/10.1109/TVCG.2014.2346660
1703
1712

J
Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.
Alsallakh, B.;Hanbury, A.;Hauser, H.;Miksch, S.;Rauber, A.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;
10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5332628;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.184;10.1109/TVCG.2012.254;10.1109/VAST.2011.6102448;10.1109/VAST.2011.6102453;10.1109/VAST.2012.6400492;10.1109/VAST.2010.5652443
Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection
VAST
2014
Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling
10.1109/TVCG.2014.2346755
http://dx.doi.org/10.1109/TVCG.2014.2346755
1923
1932

J
Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.
Poco, J.;Dasgupta, A.;Yaxing Wei;Hargrove, W.;Schwalm, C.R.;Huntzinger, D.N.;Cook, R.;Bertini, E.;Silva, C.T.
New York Univ., New York, NY, USA|c|;;;;;;;;
10.1109/TVCG.2008.139;10.1109/TVCG.2012.256;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.157;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.188;10.1109/TVCG.2013.224;10.1109/VAST.2008.4677350;10.1109/TVCG.2013.120
Similarity, clustering, matrix, optimization, climate model
VAST
2014
Visualizing Mobility of Public Transportation System
10.1109/TVCG.2014.2346893
http://dx.doi.org/10.1109/TVCG.2014.2346893
1833
1842

J
Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.
Wei Zeng;Chi-Wing Fu;Arisona, S.M.;Erath, A.;Huamin Qu
Nanyang Technol. Univ., Singapore, Singapore|c|;;;;
10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.202;10.1109/TVCG.2011.205;10.1109/TVCG.2009.143;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/INFVIS.2005.1532150
Mobility, public transportation, visual analytics
VAST
2014
Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation
10.1109/VAST.2014.7042483
http://dx.doi.org/10.1109/VAST.2014.7042483
73
82

C
We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the Carpet
). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering
 help network engineers investigating unknown computer security incidents. Most of them
 however
 have limited knowledge of advanced visualization techniques
VAST
2014
YMCA - Your Mesh Comparison Application
10.1109/VAST.2014.7042491
http://dx.doi.org/10.1109/VAST.2014.7042491
153
162

C
Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.
Schmidt, J.;Preiner, R.;Auzinger, T.;Wimmer, T.;Groller, E.;Bruckner S.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;;
10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.213;10.1109/VISUAL.2002.1183790
Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison
InfoVis
2013
A Deeper Understanding of Sequence in Narrative Visualization
10.1109/TVCG.2013.119
http://dx.doi.org/10.1109/TVCG.2013.119
2406
2415

J
Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.
Hullman, J.;Drucker, S.;Riche, N.H.;Bongshin Lee;Fisher, D.;Adar, E.
;;;;;
10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/TVCG.2008.137;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70539;10.1109/INFVIS.2000.885086
Data storytelling, narrative visualization, narrative structure
InfoVis
2013
A Design Space of Visualization Tasks
10.1109/TVCG.2013.120
http://dx.doi.org/10.1109/TVCG.2013.120
2366
2375

J
Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.
Schulz, H.-J.;Nocke, T.;Heitzler, M.;Schumann, H.
Univ. of Rostock, Rostock, Germany|c|;;;
10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375
Task taxonomy, design space, climate impact research, visualization recommendation
InfoVis
2013
A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays
10.1109/TVCG.2013.122
http://dx.doi.org/10.1109/TVCG.2013.122
2287
2296

J
Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.
Kehrer, J.;Piringer, H.;Berger, W.;Groller, E.
VRVis Res. Center, Vienna, Austria|c|;;;
10.1109/TVCG.2010.138;10.1109/TVCG.2007.70594;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.125;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102439;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885086;10.1109/TVCG.2012.237;10.1109/TVCG.2007.70521
Comparative visualization, small-multiple displays, trellis displays, categorical data
InfoVis
2013
A Multi-Level Typology of Abstract Visualization Tasks
10.1109/TVCG.2013.124
http://dx.doi.org/10.1109/TVCG.2013.124
2376
2385

J
The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.
Brehmer, M.;Munzner, T.
;
10.1109/TVCG.2007.70541;10.1109/TVCG.2012.219;10.1109/INFVIS.1996.559213;10.1109/TVCG.2012.213;10.1109/TVCG.2012.273;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2008.137;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2012.252;10.1109/VISUAL.1990.146375
Typology, visualization models, task and requirements analysis, qualitative evaluation
InfoVis
2013
An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization
10.1109/TVCG.2013.130
http://dx.doi.org/10.1109/TVCG.2013.130
2356
2365

J
Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, & delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, & prescribe) and interaction operands (space-alone, attributes-in-space, & space-in-time; elementary & general). The operator sort suggested five enabling operators (import, export, save, edit, & annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, & calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.
Roth, R.E.
Univ. of Wisconsin-Madison, Madison, WI, USA|c|
10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5653599;10.1109/INFVIS.2000.885092
Science of interaction, interaction primitives, interactive maps, geovisualization, interaction techniques
InfoVis
2013
An Interaction Model for Visualizations Beyond The Desktop
10.1109/TVCG.2013.134
http://dx.doi.org/10.1109/TVCG.2013.134
2396
2405

J
We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.
Jansen, Y.;Dragicevic, P.
Inria & Univ. Paris Sud, Paris, France|c|;
10.1109/TVCG.2010.177;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2006.178;10.1109/TVCG.2009.162;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1990.146375
Information visualization, interaction model, notational system, physical visualization
InfoVis
2013
Automatic Layout of Structured Hierarchical Reports
10.1109/TVCG.2013.137
http://dx.doi.org/10.1109/TVCG.2013.137
2586
2595

J
Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.
Bakke, E.;Karger, D.R.;Miller, R.C.
Comput. Sci. & Artificial Intell. Lab. (CSAIL), MIT, Cambridge, MA, USA|c|;;
10.1109/VAST.2011.6102445;10.1109/INFVIS.2004.1;10.1109/INFVIS.1995.528693;10.1109/TVCG.2007.70594;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636761
Hierarchy data, tabular data, nested relations, layout management
InfoVis
2013
Common Angle Plots as Perception-True Visualizations of Categorical Associations
10.1109/TVCG.2013.140
http://dx.doi.org/10.1109/TVCG.2013.140
2297
2305

J
Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue.
Hofmann, H.;Vendettuoli, M.
;
10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532128;10.1109/TVCG.2010.186;10.1109/TVCG.2011.185;10.1109/TVCG.2009.128
Linewidth illusion, data visualization, high-dimensional displays, parallel sets, hammock plots, Muller-Lyer illusion
InfoVis
2013
Creative User-Centered Visualization Design for Energy Analysts and Modelers
10.1109/TVCG.2013.145
http://dx.doi.org/10.1109/TVCG.2013.145
2516
2525

J
We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.
Goodwin, S.;Dykes, J.;Jones, S.;Dillingham, I.;Dove, G.;Duffy, A.;Kachkaev, A.;Slingsby, A.;Wood, J.
giCentre, City Univ. London, London, UK|c|;;;;;;;;
10.1109/TVCG.2010.191;10.1109/TVCG.2012.213;10.1109/TVCG.2011.196;10.1109/TVCG.2007.70539;10.1109/INFVIS.1999.801851;10.1109/TVCG.2011.209
Creativity techniques, user-centered design, data visualization, smart home, energy consumption
InfoVis
2013
DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation
10.1109/TVCG.2013.149
http://dx.doi.org/10.1109/TVCG.2013.149
2556
2565

J
Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.
Rufiange, S.;McGuffin, M.J.
Ecole de Technol. Super., Montreal, QC, Canada|c|;
10.1109/VAST.2012.6400552;10.1109/TVCG.2011.169;10.1109/INFVIS.2005.1532151;10.1109/TVCG.2011.226;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.213;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70582;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173160;10.1109/TVCG.2007.70539
Dynamic networks, hybrid visualization, taxonomy, evolution, animation, difference map
InfoVis
2013
Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data
10.1109/TVCG.2013.150
http://dx.doi.org/10.1109/TVCG.2013.150
2625
2633

J
For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.
Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo
Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China|c|;;;
10.1109/INFVIS.2005.1532142;10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VAST.2012.6400488;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.184;10.1109/TVCG.2009.128;10.1109/VAST.2006.261422;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173151
High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix
InfoVis
2013
Edge Compression Techniques for Visualization of Dense Directed Graphs
10.1109/TVCG.2013.151
http://dx.doi.org/10.1109/TVCG.2013.151
2596
2605

J
We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.
Dwyer, T.;Riche, N.H.;Marriott, K.;Mears, C.
;;;
10.1109/TVCG.2009.165;10.1109/TVCG.2011.233;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.66
Directed graphs, networks, modular decomposition, power graph analysis
InfoVis
2013
Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices
10.1109/TVCG.2013.153
http://dx.doi.org/10.1109/TVCG.2013.153
2634
2643

J
To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.
Sedlmair, M.;Munzner, T.;Tory, M.
Univ. of Vienna, Vienna, Austria|c|;;
10.1109/TVCG.2009.127;10.1109/TVCG.2011.229;10.1109/TVCG.2007.70596;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1997.636793;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2008.109;10.1109/VAST.2009.5332628
Dimensionality reduction, scatterplots, quantitative study
InfoVis
2013
Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets
10.1109/TVCG.2013.154
http://dx.doi.org/10.1109/TVCG.2013.154
2536
2545

J
Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.
Lex, A.;Partl, C.;Kalkofen, D.;Streit, M.;Gratzl, S.;Wassermann, A.M.;Schmalstieg, D.;Pfister, H.
Harvard Univ., Cambridge, MA, USA|c|;;;;;;;
10.1109/VAST.2009.5333443;10.1109/TVCG.2011.250;10.1109/TVCG.2011.213;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087
Pathway visualization, biological networks, subsets, graphs, biomolecular data
InfoVis
2013
Evaluation of filesystem Provenance Visualization Tools
10.1109/TVCG.2013.155
http://dx.doi.org/10.1109/TVCG.2013.155
2476
2485

J
Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.
Borkin, M.A.;Yeh, C.S.;Boyd, M.;Macko, P.;Gajos, K.Z.;Seltzer, M.;Pfister, H.
Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;
10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2006.120;10.1109/TVCG.2009.167;10.1109/INFVIS.2004.66;10.1109/INFVIS.2004.1;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532134
Provenance data, graph/network data, hierarchy data, quantitative evaluation, gender differences
InfoVis
2013
GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data
10.1109/TVCG.2013.160
http://dx.doi.org/10.1109/TVCG.2013.160
2606
2614

J
Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.
Im, J.-F.;McGuffin, M.J.;Leung, R.
Ecole de Technol. Super., Montreal, QC, Canada|c|;;
10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/TVCG.2007.70594;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2010.205;10.1109/TVCG.2011.183;10.1109/VISUAL.1993.398859;10.1109/TVCG.2011.201;10.1109/TVCG.2010.164;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/VISUAL.1991.175796
Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence
InfoVis
2013
Hybrid-Image Visualization for Large Viewing Environments
10.1109/TVCG.2013.163
http://dx.doi.org/10.1109/TVCG.2013.163
2346
2355

J
We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.
Isenberg, P.;Dragicevic, P.;Willett, W.;Bezerianos, A.;Fekete, J.-D.
Inria, France;;;;
10.1109/TVCG.2012.251;10.1109/TVCG.2012.264;10.1109/TVCG.2006.184;10.1109/TVCG.2007.70582;10.1109/INFVIS.2001.963288;10.1109/TVCG.2007.70583;10.1109/INFVIS.2005.1532131
Multi-scale, large displays, hybrid images, collaboration, visualization
InfoVis
2013
Information Visualization and Proxemics: Design Opportunities and Empirical findings
10.1109/TVCG.2013.166
http://dx.doi.org/10.1109/TVCG.2013.166
2386
2395

J
People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.
Jakobsen, M.R.;Sahlemariam Haile, Y.;Knudsen, S.;Hornbaek, K.
Univ. of Copenhagen, Copenhagen, Denmark|c|;;;
10.1109/TVCG.2006.184;10.1109/TVCG.2012.204;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136
Proxemics, information visualization, user study, large displays, user tracking, movement, orientation, distance
InfoVis
2013
Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale
10.1109/TVCG.2013.170
http://dx.doi.org/10.1109/TVCG.2013.170
2336
2345

J
In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' p- rformance and to discuss differences between the two experimental approaches.
Jakobsen, M.R.;Hornbaek, K.
Univ. of Copenhagen, Copenhagen, Denmark|c|;
10.1109/TVCG.2006.184;10.1109/TVCG.2006.187
Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies
InfoVis
2013
LineUp: Visual Analysis of Multi-Attribute Rankings
10.1109/TVCG.2013.173
http://dx.doi.org/10.1109/TVCG.2013.173
2277
2286

J
Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.
Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.
Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;
10.1109/TVCG.2012.253;10.1109/TVCG.2008.166;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.181;10.1109/TVCG.2007.70539
Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts
InfoVis
2013
Nanocubes for Real-Time Exploration of Spatiotemporal Datasets
10.1109/TVCG.2013.179
http://dx.doi.org/10.1109/TVCG.2013.179
2456
2465

J
Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.
Lins, L.;Klosowski, J.T.;Scheidegger, C.
;;
10.1109/TVCG.2006.161;10.1109/INFVIS.2002.1173141;10.1109/TVCG.2009.191;10.1109/VAST.2008.4677357;10.1109/TVCG.2007.70594;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185
Data cube, Data structures, Interactive exploration
InfoVis
2013
Orthographic Star Coordinates
10.1109/TVCG.2013.182
http://dx.doi.org/10.1109/TVCG.2013.182
2615
2624

J
Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.
Lehmann, D.J.;Theisel, H.
Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;
10.1109/VISUAL.1997.663916
Start plot, multivariate visualization, visual analytics
InfoVis
2013
Perception of Average Value in Multiclass Scatterplots
10.1109/TVCG.2013.183
http://dx.doi.org/10.1109/TVCG.2013.183
2316
2325

J
The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.
Gleicher, M.;Correll, M.;Nothelfer, C.;Franconeri, S.
Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|;;;
10.1109/TVCG.2012.233
Psychophysics, Information Visualization, Perceptual Study
InfoVis
2013
Radial Sets: Interactive Visual Analysis of Large Overlapping Sets
10.1109/TVCG.2013.184
http://dx.doi.org/10.1109/TVCG.2013.184
2496
2505

J
In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.
Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.
Vienna Univ. of Technol., Vienna, Austria|c|;;;
10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157
Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability
InfoVis
2013
Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation
10.1109/TVCG.2013.187
http://dx.doi.org/10.1109/TVCG.2013.187
2326
2335

J
Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.
Fink, M.;Haunert, J.-H.;Spoerhase, J.;Wolff, A.
Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|;;;
10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.167
Scatter plot, aspect ratio, Delaunay triangulation
InfoVis
2013
SketchStory: Telling More Engaging Stories with Data through Freeform Sketching
10.1109/TVCG.2013.191
http://dx.doi.org/10.1109/TVCG.2013.191
2416
2425

J
Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.
Bongshin Lee;Kazi, R.H.;Smith, G.
;;
10.1109/TVCG.2007.70577;10.1109/TVCG.2012.262;10.1109/TVCG.2010.179;10.1109/TVCG.2012.275;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992
Storytelling, data presentation, sketch, pen and touch, interaction, visualization
InfoVis
2013
SoccerStories: A Kick-off for Visual Soccer Analysis
10.1109/TVCG.2013.192
http://dx.doi.org/10.1109/TVCG.2013.192
2506
2515

J
This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.
Perin, C.;Vuillemot, R.;Fekete, J.-D.
INRIA, Univ. Paris-Sud, Paris, France|c|;;
10.1109/TVCG.2007.70582;10.1109/TVCG.2011.169;10.1109/TVCG.2011.185;10.1109/TVCG.2012.263
Visual knowledge discovery, visual knowledge representation, sport analytics, visual aggregation
InfoVis
2013
StoryFlow: Tracking the Evolution of Stories
10.1109/TVCG.2013.196
http://dx.doi.org/10.1109/TVCG.2013.196
2436
2445

J
Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.
Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu
;;;;
10.1109/TVCG.2012.253;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/TVCG.2011.226;10.1109/VAST.2008.4677364;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/VAST.2006.261421;10.1109/VAST.2009.5333437;10.1109/TVCG.2011.239
Storylines, story-telling visualization, user interactions, level-of-detail, optimization
InfoVis
2013
Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization
10.1109/TVCG.2013.209
http://dx.doi.org/10.1109/TVCG.2013.209
2526
2535

J
Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.
Basole, R.C.;Clear, T.;Mengdie Hu;Mehrotra, H.;Stasko, J.
;;;;
10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/INFVIS.2003.1249027;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652530;10.1109/TVCG.2006.166
Business ecosystems, market research, strategic analysis, design study, interaction, network visualization
InfoVis
2013
Using Concrete Scales: A Practical Framework for Effective Visual Depiction of Complex Measures
10.1109/TVCG.2013.210
http://dx.doi.org/10.1109/TVCG.2013.210
2426
2435

J
From financial statistics to nutritional values, we are frequently exposed to quantitative information expressed in measures of either extreme magnitudes or unfamiliar units, or both. A common practice used to comprehend such complex measures is to relate, re-express, and compare them through visual depictions using magnitudes and units that are easier to grasp. Through this practice, we create a new graphic composition that we refer to as a concrete scale. To the best of our knowledge, there are no design guidelines that exist for concrete scales despite their common use in communication, educational, and decision-making settings. We attempt to fill this void by introducing a novel framework that would serve as a practical guide for their analysis and design. Informed by a thorough analysis of graphic compositions involving complex measures and an extensive literature review of scale cognition mechanisms, our framework outlines the design space of various measure relations-specifically relations involving the re-expression of complex measures to more familiar concepts-and their visual representations as graphic compositions.
Chevalier, F.;Vuillemot, R.;Gali, G.
Univ. of Toronto & OCAD Univ., Toronto, ON, Canada|c|;;
10.1109/TVCG.2012.199
Concrete scale, scale cognition, visual comparison, graphic composition, visual notation
InfoVis
2013
Variant View: Visualizing Sequence Variants in their Gene Context
10.1109/TVCG.2013.214
http://dx.doi.org/10.1109/TVCG.2013.214
2546
2555

J
Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.
Ferstay, J.A.;Nielsen, C.B.;Munzner, T.
;;
10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/TVCG.2012.213;10.1109/TVCG.2011.185;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.116;10.1109/TVCG.2009.167;10.1109/TVCG.2011.209
Information visualization, design study, bioinformatics, genetic variants
InfoVis
2013
Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs
10.1109/TVCG.2013.225
http://dx.doi.org/10.1109/TVCG.2013.225
2576
2585

J
This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.
Maguire, E.;Rocca-Serra, P.;Sansone, S.-A.;Davies, J.;Min Chen
Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK|c|;;;;
10.1109/TVCG.2007.70584;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.147;10.1109/TVCG.2009.195;10.1109/TVCG.2012.271;10.1109/VISUAL.1996.567752;10.1109/TVCG.2008.174;10.1109/TVCG.2006.166
Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm
InfoVis
2013
Visual Sedimentation
10.1109/TVCG.2013.227
http://dx.doi.org/10.1109/TVCG.2013.227
2446
2455

J
We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.
Huron, S.;Vuillemot, R.;Fekete, J.-D.
;;
10.1109/VAST.2012.6400552;10.1109/TVCG.2012.291;10.1109/TVCG.2011.179;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.185;10.1109/TVCG.2008.166;10.1109/TVCG.2008.171;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539
Design, Information Visualization, Dynamic visualization, Dynamic data, Data stream, Real time, Metaphor
InfoVis
2013
Visualization of Shape Motions in Shape Space
10.1109/TVCG.2013.230
http://dx.doi.org/10.1109/TVCG.2013.230
2644
2652

J
Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.
Taimouri, V.;Jing Hua
Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;
10.1109/TVCG.2006.137;10.1109/INFVIS.2003.1249025;10.1109/TVCG.2009.159;10.1109/INFVIS.2004.65
Medial surface, shape space, comparative visualization, left ventricle diagnosis
InfoVis
2013
Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView
10.1109/TVCG.2013.231
http://dx.doi.org/10.1109/TVCG.2013.231
2566
2575

J
To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.
Guerra-Gomez, J.;Pack, M.L.;Plaisant, C.;Shneiderman, B.
Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;;;
10.1109/VAST.2011.6102439;10.1109/TVCG.2006.147;10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70556;10.1109/INFVIS.2002.1173150;10.1109/VAST.2006.261450;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2003.1249026;10.1109/TVCG.2007.70529
Information visualization, Tree comparison
InfoVis
2013
Visualizing Fuzzy Overlapping Communities in Networks
10.1109/TVCG.2013.232
http://dx.doi.org/10.1109/TVCG.2013.232
2486
2495

J
An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.
Vehlow, C.;Reinhardt, T.;Weiskopf, D.
VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;
10.1109/VISUAL.1993.398872;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2004.43;10.1109/TVCG.2009.113
Overlapping community visualization, fuzzy clustering, graph visualization, uncertainty visualization
InfoVis
2013
Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems
10.1109/TVCG.2013.233
http://dx.doi.org/10.1109/TVCG.2013.233
2466
2475

J
Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.
Sambasivan, R.R.;Shafer, I.;Mazurek, M.L.;Ganger, G.R.
;;;
10.1109/VAST.2010.5652910;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/VAST.2011.6102442
Distributed systems, human factors, problem diagnosis, visualization
InfoVis
2013
What Makes a Visualization Memorable?
10.1109/TVCG.2013.234
http://dx.doi.org/10.1109/TVCG.2013.234
2306
2315

J
An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.
Borkin, M.A.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.
Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;
10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175
Visualization taxonomy, information visualization, memorability
SciVis
2013
A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures
10.1109/TVCG.2013.121
http://dx.doi.org/10.1109/TVCG.2013.121
2802
2809

J
We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.
Jackson, B.;Tung Yuen Lau;Schroeder, D.;Toussaint, K.C.;Keefe, D.F.
Univ. of Minnesota, Minneapolis, MN, USA|c|;;;;
10.1109/TVCG.2009.138;10.1109/VISUAL.2005.1532846;10.1109/VISUAL.2002.1183753;10.1109/VISUAL.1997.663912
Scientific visualization, 3D interaction, tangible interaction, microscopy visualization
SciVis
2013
A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation
10.1109/TVCG.2013.123
http://dx.doi.org/10.1109/TVCG.2013.123
2792
2801

J
We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.
Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma
Univ. of California, Davis, Davis, CA, USA|c|;;
10.1109/TVCG.2006.152;10.1109/TVCG.2006.140;10.1109/TVCG.2009.189;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.2005.1532834;10.1109/TVCG.2012.292;10.1109/VISUAL.2005.1532787;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2001.964517
Camera motion planning, volume rendering, visualization, animation
SciVis
2013
A Systematic Review on the Practice of Evaluating Visualization
10.1109/TVCG.2013.126
http://dx.doi.org/10.1109/TVCG.2013.126
2818
2827

J
We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.
Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.
INRIA, France|c|;;;;
10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223
Evaluation, validation, systematic review, visualization, scientific visualization, information visualization
SciVis
2013
Acuity-Driven Gigapixel Visualization
10.1109/TVCG.2013.127
http://dx.doi.org/10.1109/TVCG.2013.127
2886
2895

J
We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.
Papadopoulos, C.;Kaufman, A.E.
Stony Brook Univ., Stony Brook, NY, USA|c|;
10.1109/TVCG.2011.231;10.1109/INFVIS.2004.66
Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display
SciVis
2013
Adaptive Refinement of the Flow Map Using Sparse Samples
10.1109/TVCG.2013.128
http://dx.doi.org/10.1109/TVCG.2013.128
2753
2762

J
We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.
Barakat, S.S.;Tricoche, X.
Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA|c|;
10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70551
Lagrangian flow visualization, flow map, edge features, scattered data interpolation, sparse sampling, adaptive refinement, parallel reconstruction
SciVis
2013
Ambient Volume Scattering
10.1109/TVCG.2013.129
http://dx.doi.org/10.1109/TVCG.2013.129
2936
2945

J
We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.
Ament, M.;Sadlo, F.;Weiskopf, D.
Univ. of Stuttgart, Stuttgart, Germany|c|;;
10.1109/TVCG.2011.211;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2000.885683;10.1109/TVCG.2010.187;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250406;10.1109/TVCG.2010.145;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2005.1532803;10.1109/TVCG.2009.204
Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading
SciVis
2013
An Exploration Framework to Identify and Track Movement of Cloud Systems
10.1109/TVCG.2013.131
http://dx.doi.org/10.1109/TVCG.2013.131
2896
2905

J
We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.
Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.
Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|;;
10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383
Cloud clusters, tracking, computational topology, split tree, weather and climate simulations
SciVis
2013
An Information-Aware Framework for Exploring Multivariate Data Sets
10.1109/TVCG.2013.133
http://dx.doi.org/10.1109/TVCG.2013.133
2683
2692

J
Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.
Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.
Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;
10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785
Information theory, framework, isosurface, multivariate uncertainty
SciVis
2013
Area-Preservation Mapping using Optimal Mass Transport
10.1109/TVCG.2013.135
http://dx.doi.org/10.1109/TVCG.2013.135
2838
2847

J
We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n2) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.
Xin Zhao;Zhengyu Su;Gu, X.D.;Kaufman, A.;Jian Sun;Jie Gao;Feng Luo
;;;;;;
10.1109/TVCG.2011.171
Area-preservation mapping, surface flattening, optimal transport map, Monge-Brenier theory, visualization and graphics applications
SciVis
2013
Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging
10.1109/TVCG.2013.138
http://dx.doi.org/10.1109/TVCG.2013.138
2703
2712

J
Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.
Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.
;;;;;;
10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181
Uncertainty visualization, numerical ensembles, statistical visualization
SciVis
2013
Colon Flattening Using Heat Diffusion Riemannian Metric
10.1109/TVCG.2013.139
http://dx.doi.org/10.1109/TVCG.2013.139
2848
2857

J
We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.
Gurijala, K.C.;Rui Shi;Wei Zeng;Xianfeng Gu;Kaufman, A.
Stony Brook Univ., Stony Brook, NY, USA|c|;;;;
10.1109/VISUAL.2001.964540;10.1109/TVCG.2006.112;10.1109/VISUAL.2001.964540;10.1109/TVCG.2010.200
Colon flattening, heat diffusion, virtual colonoscopy, volume rendering, topological noise, shape-preserving mapping
SciVis
2013
Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles
10.1109/TVCG.2013.141
http://dx.doi.org/10.1109/TVCG.2013.141
2743
2752

J
Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.
Hummel, M.;Obermaier, H.;Garth, C.;Joy, K.I.
Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;
10.1109/TVCG.2011.203;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2007.70551
Ensemble, flow field, time-varying, comparison, visualization, Lagrangian, variance, principal components analysis
SciVis
2013
ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data
10.1109/TVCG.2013.142
http://dx.doi.org/10.1109/TVCG.2013.142
2868
2877

J
This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.
Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.
King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;
10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2009.178;10.1109/TVCG.2012.240;10.1109/TVCG.2006.195;10.1109/VISUAL.1995.485139;10.1109/TVCG.2007.70560;10.1109/TVCG.2009.118;10.1109/TVCG.2009.121
Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis
SciVis
2013
Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles
10.1109/TVCG.2013.143
http://dx.doi.org/10.1109/TVCG.2013.143
2713
2722

J
Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.
Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.
Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;
10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.181
Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics
SciVis
2013
Coupled Ensemble Flow Line Advection and Analysis
10.1109/TVCG.2013.144
http://dx.doi.org/10.1109/TVCG.2013.144
2733
2742

J
Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.
Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu
Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;
10.1109/VISUAL.2005.1532853;10.1109/TVCG.2011.219;10.1109/TVCG.2011.203;10.1109/TVCG.2006.116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/VISUAL.1996.568116;10.1109/TVCG.2007.70551
Ensemble analysis, parallel processing, field line advection
SciVis
2013
Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles
10.1109/TVCG.2013.147
http://dx.doi.org/10.1109/TVCG.2013.147
2783
2791

J
We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.
Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.
Univ. of Minnesota, Minneapolis, MN, USA|c|;;;
10.1109/TVCG.2012.261;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/VISUAL.2000.885734;10.1109/TVCG.2010.171;10.1109/TVCG.2007.70581
Design, simulation, direct manipulation, multi-touch
SciVis
2013
Detecting Symmetry in Scalar fields Using Augmented Extremum Graphs
10.1109/TVCG.2013.148
http://dx.doi.org/10.1109/TVCG.2013.148
2663
2672

J
Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.
Thomas, D.M.;Natarajan, V.
Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;
10.1109/VISUAL.2004.68;10.1109/TVCG.2009.120;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.244;10.1109/TVCG.2007.70603;10.1109/TVCG.2012.200;10.1109/TVCG.2006.186
Scalar field visualization, extremum graph, Morse decomposition, symmetry detection, data exploration
SciVis
2013
Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform
10.1109/TVCG.2013.152
http://dx.doi.org/10.1109/TVCG.2013.152
2693
2702

J
Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.
Teng-Yok Lee;Han-Wei Shen
Ohio State Univ., Columbus, OH, USA|c|;
10.1109/VISUAL.1999.809910;10.1109/TVCG.2010.131;10.1109/TVCG.2011.246;10.1109/VISUAL.2001.964516;10.1109/TVCG.2011.198;10.1109/TVCG.2009.197
WaveletSAT, integral histograms, discrete wavelet transform
SciVis
2013
Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities
10.1109/TVCG.2013.156
http://dx.doi.org/10.1109/TVCG.2013.156
2810
2817

J
Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.
Froese, M.-E.;Tory, M.;Evans, G.-W.;Shrikhande, K.
;;;
10.1109/VISUAL.2005.1532836;10.1109/VISUAL.2003.1250396
Spatial ability, 3D visualization, training, evaluation, orthographic projection, CAD
SciVis
2013
Fast Blending Scheme for Molecular Surface Representation
10.1109/TVCG.2013.158
http://dx.doi.org/10.1109/TVCG.2013.158
2653
2662

J
Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.
Parulek, J.;Brambilla, A.
Dept. ofInformatics, Univ. of Bergen, Bergen, Norway|c|;
10.1109/TVCG.2009.157;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2006.115
Molecular visualization, geometry-based techniques, implicit surfaces
SciVis
2013
Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy
10.1109/TVCG.2013.159
http://dx.doi.org/10.1109/TVCG.2013.159
2673
2682

J
We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.
Ehlke, M.;Ramm, H.;Lamecker, H.;Hege, H.-C.;Zachow, S.
Zuse Inst. Berlin, Berlin, Germany|c|;;;;
10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2005.1532815;10.1109/TVCG.2006.110;10.1109/VISUAL.2003.1250384
Digitally reconstructed radiographs, volume rendering, mesh deformation, statistical shape and intensity models, image registration, GPU acceleration
SciVis
2013
GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data
10.1109/TVCG.2013.161
http://dx.doi.org/10.1109/TVCG.2013.161
2916
2925

J
We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.
Maries, A.;Mays, N.;Hunt, M.O.;Wong, K.F.;Layton, W.;Boudreau, R.;Rosano, C.;Marai, G.E.
Dept. of Comput. Sci., Univ. of Pittsburgh, Pittsburgh, PA, USA|c|;;;;;;;
10.1109/TVCG.2009.141;10.1109/VISUAL.2000.885739;10.1109/VAST.2006.261438;10.1109/TVCG.2009.111;10.1109/TVCG.2010.137;10.1109/TVCG.2009.114;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.162
Design studies, methodology design, task and requirements analysis, integrating spatial and non-spatial data visualization, visual comparison, high-dimensional data, applications of visualization
SciVis
2013
Interactive Patient-Specific Vascular Modeling with Sweep Surfaces
10.1109/TVCG.2013.169
http://dx.doi.org/10.1109/TVCG.2013.169
2828
2837

J
The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.
Kretschmer, J.;Godenschwager, C.;Preim, B.;Stamminger, M.
Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;
10.1109/VISUAL.2001.964538;10.1109/VISUAL.1994.346339
Surface modeling, vascular visualization, centerline-based modeling
SciVis
2013
Lighting Design for Globally Illuminated Volume Rendering
10.1109/TVCG.2013.172
http://dx.doi.org/10.1109/TVCG.2013.172
2946
2955

J
With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.
Yubo Zhang;Kwan-Liu Ma
Univ. of California, Davis, Davis, CA, USA|c|;
10.1109/VISUAL.2005.1532812;10.1109/VISUAL.2004.62;10.1109/TVCG.2011.198;10.1109/TVCG.2012.267;10.1109/VISUAL.2002.1183785
Global illumination, lighting design, volume rendering, tone mapping
SciVis
2013
ManyVis: Multiple Applications in an Integrated Visualization Environment
10.1109/TVCG.2013.174
http://dx.doi.org/10.1109/TVCG.2013.174
2878
2885

J
As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.
Rungta, A.;Summa, B.;Demir, D.;Bremer, P.-T.;Pascucci, V.
SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;
10.1109/TVCG.2007.70552
Visualization environments, integrated applications, macros, linked views
SciVis
2013
MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data
10.1109/TVCG.2013.177
http://dx.doi.org/10.1109/TVCG.2013.177
2906
2915

J
This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.
Reh, A.;Gusenbauer, C.;Kastner, J.;Groller, M.E.;Heinzl, C.
Univ. of Appl. Sci. Upper Austria, Wels, Austria|c|;;;;
10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809871;10.1109/TVCG.2009.121;10.1109/TVCG.2012.227;10.1109/TVCG.2011.248;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.190;10.1109/TVCG.2010.214;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1997.663875
3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects
SciVis
2013
Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data
10.1109/TVCG.2013.180
http://dx.doi.org/10.1109/TVCG.2013.180
2926
2935

J
Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.
Khlebnikov, R.;Kainz, B.;Steinberger, M.;Schmalstieg, D.
Graz Univ. of Technol., Graz, Austria|c|;;;
10.1109/VISUAL.1990.146373;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2006.113;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2007.70623;10.1109/TVCG.2012.223;10.1109/VISUAL.2003.1250362
Volume rendering, multi-variate data visualization, multi-volume rendering, scientific visualization
SciVis
2013
Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates
10.1109/TVCG.2013.189
http://dx.doi.org/10.1109/TVCG.2013.189
2773
2782

J
Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.
Kohler, B.;Gasteiger, R.;Preim, U.;Theisel, H.;Gutberlet, M.;Preim, B.
;;;;;
10.1109/TVCG.2011.260;10.1109/VISUAL.1999.809869;10.1109/TVCG.2010.153;10.1109/VISUAL.1999.809896;10.1109/TVCG.2011.243;10.1109/TVCG.2007.70545;10.1109/VISUAL.2004.99;10.1109/TVCG.2010.173
4D pc-mri, cardiac blood flow, hemodynamics, line predicates, vortex extraction
SciVis
2013
Uncertainty Quantification in Linear Interpolation for Isosurface Extraction
10.1109/TVCG.2013.208
http://dx.doi.org/10.1109/TVCG.2013.208
2723
2732

J
We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.
Athawale, T.;Entezari, A.
Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|;
10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70602;10.1109/VISUAL.1991.175782;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.194;10.1109/TVCG.2011.203
Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes
SciVis
2013
Vessel Visualization using Curved Surface Reformation
10.1109/TVCG.2013.215
http://dx.doi.org/10.1109/TVCG.2013.215
2858
2867

J
Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.
Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;
10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555
Reformation, volume rendering, surface approximation
SciVis
2013
Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields
10.1109/TVCG.2013.229
http://dx.doi.org/10.1109/TVCG.2013.229
2763
2772

J
Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.
Szymczak, A.;Sipeki, L.
Colorado Sch. of Mines, Golden, CO, USA|c|;
10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2012.209;10.1109/VISUAL.2000.885716
Morse connection graph, vector field topology
VAST
2013
A Partition-Based Framework for Building and Validating Regression Models
10.1109/TVCG.2013.125
http://dx.doi.org/10.1109/TVCG.2013.125
1962
1971

J
Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.
Muhlbacher, T.;Piringer, H.
;
10.1109/TVCG.2012.219;10.1109/TVCG.2009.128;10.1109/VISUAL.1993.398859;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102453;10.1109/VAST.2009.5333431;10.1109/TVCG.2010.213;10.1109/TVCG.2012.205;10.1109/VAST.2009.5332628;10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102450;10.1109/VAST.2008.4677368;10.1109/VAST.2010.5652460;10.1109/TVCG.2011.248;10.1109/INFVIS.2005.1532142;10.1109/VAST.2007.4388999;10.1109/INFVIS.2004.10;10.1109/TVCG.2009.110;10.1109/VAST.2011.6102448;10.1109/INFVIS.2004.3
Regression, model building, visual knowledge discovery, feature selection, data partitioning, guided visualization
VAST
2013
An Extensible Framework for Provenance in Human Terrain Visual Analytics
10.1109/TVCG.2013.132
http://dx.doi.org/10.1109/TVCG.2013.132
2139
2148

J
We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.
Walker, R.;Slingsby, A.;Dykes, J.;Kai Xu;Wood, J.;Nguyen, P.H.;Stephens, D.;Wong, B.L.W.;Yongjun Zheng
Middlesex Univ., London, UK|c|;;;;;;;;
10.1109/TVCG.2012.252;10.1109/TVCG.2010.191;10.1109/VAST.2007.4388992;10.1109/TVCG.2006.142;10.1109/VAST.2006.261431;10.1109/TVCG.2010.154;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677366;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4388992;10.1109/TVCG.2009.128;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919;10.1109/TVCG.2011.209;10.1109/TVCG.2009.139;10.1109/TVCG.2008.175
Human terrain analysis, provenance, framework, bookmarks, narratives
VAST
2013
Decision Exploration Lab: A Visual Analytics Solution for Decision Management
10.1109/TVCG.2013.146
http://dx.doi.org/10.1109/TVCG.2013.146
1972
1981

J
We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.
Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.
IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|;;;
10.1109/VISUAL.1991.175815;10.1109/VAST.2011.6102463;10.1109/VAST.2010.5652398;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677363;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102457
Decision support systems, model validation and analysis, multivariate Statistics, program analysis
VAST
2013
Explainers: Expert Explorations with Crafted Projections
10.1109/TVCG.2013.157
http://dx.doi.org/10.1109/TVCG.2013.157
2042
2051

J
This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.
Gleicher, M.
Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|
10.1109/VAST.2012.6400487;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.71;10.1109/TVCG.2012.256;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2011.220;10.1109/INFVIS.1998.729559;10.1109/VAST.2011.6102448;10.1109/TVCG.2009.153
High-dimensional spaces, exploration, support vector machines
VAST
2013
HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies
10.1109/TVCG.2013.162
http://dx.doi.org/10.1109/TVCG.2013.162
2002
2011

J
Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.
Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.
Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;
10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485
Hierarchical topic representation, topic modeling, visual analytics, rose tree
VAST
2013
Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis
10.1109/TVCG.2013.164
http://dx.doi.org/10.1109/TVCG.2013.164
2198
2206

J
We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.
Willett, W.;Ginosar, S.;Steinitz, A.;Hartmann, B.;Agrawala, M.
INRIA, Sophia-Antipolis, France|c|;;;;
10.1109/TVCG.2007.70577
Crowdsourcing, social data analysis
VAST
2013
Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets
10.1109/TVCG.2013.167
http://dx.doi.org/10.1109/TVCG.2013.167
2080
2089

J
Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.
Jian Zhao;Collins, C.;Chevalier, F.;Balakrishnan, R.
Univ. of Toronto, Toronto, ON, Canada|c|;;;
10.1109/TVCG.2008.137;10.1109/VAST.2011.6102440;10.1109/TVCG.2011.213;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.205;10.1109/TVCG.2012.252;10.1109/TVCG.2006.166;10.1109/INFVIS.2000.885086
Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics
VAST
2013
Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization
10.1109/TVCG.2013.168
http://dx.doi.org/10.1109/TVCG.2013.168
2119
2128

J
We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.
Meghdadi, A.H.;Irani, P.
Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada|c|;
10.1109/INFVIS.2004.27;10.1109/TVCG.2012.222;10.1109/VISUAL.2003.1250401
Video visual analytics, surveillance video, video visualization, video summarization, video browsing and exploration
VAST
2013
MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation
10.1109/TVCG.2013.178
http://dx.doi.org/10.1109/TVCG.2013.178
2257
2266

J
We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.
Bernard, J.;Wilhelm, N.;Kruger, B.;May, T.;Schreck, T.;Kohlhammer, J.
Fraunhofer Inst. for Comput. Graphics Res. Darmstadt, Darmstadt, Germany|c|;;;;;
10.1109/VISUAL.1999.809865;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.120;10.1109/TVCG.2011.181;10.1109/TVCG.2011.188
Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph
VAST
2013
Open-Box Spectral Clustering: Applications to Medical Image Analysis
10.1109/TVCG.2013.181
http://dx.doi.org/10.1109/TVCG.2013.181
2100
2108

J
Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.
Schultz, T.;Kindlmann, G.L.
Univ. of Bonn, Bonn, Germany|c|;
10.1109/VISUAL.2005.1532820;10.1109/VAST.2010.5652926;10.1109/VISUAL.2000.885740;10.1109/VAST.2012.6400488;10.1109/TVCG.2009.141;10.1109/TVCG.2009.112;10.1109/TVCG.2009.177;10.1109/TVCG.2010.199;10.1109/TVCG.2009.199;10.1109/TVCG.2011.248;10.1109/TVCG.2011.253
Image segmentation, spectral clustering, high-dimensional embeddings, linked views, programming with example
VAST
2013
ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering
10.1109/TVCG.2013.186
http://dx.doi.org/10.1109/TVCG.2013.186
2022
2031

J
The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.
Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.
Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;
10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175
Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification
VAST
2013
Semantics of Directly Manipulating Spatializations
10.1109/TVCG.2013.188
http://dx.doi.org/10.1109/TVCG.2013.188
2052
2059

J
When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.
Xinran Hu;Bradel, L.;Maiti, D.;House, L.;North, C.;Leman, S.
;;;;;
10.1109/VAST.2011.6102449;10.1109/INFVIS.1995.528686;10.1109/TVCG.2012.260;10.1109/VAST.2012.6400486;10.1109/VAST.2008.4677358
Visual to parametric interaction, visual analytics, statistical models
VAST
2013
SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space
10.1109/TVCG.2013.190
http://dx.doi.org/10.1109/TVCG.2013.190
2060
2069

J
High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPadND, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPadND offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.
Bing Wang;Ruchikachorn, P.;Mueller, K.
Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;
10.1109/TVCG.2011.237;10.1109/VAST.2012.6400489
Synthetic data generation, data editing, data acquisition and management, multivariate data, high-dimensional data, interaction, user interface, parallel coordinates, scatterplot, N-D navigation, multiple views
VAST
2013
Space Transformation for Understanding Group Movement
10.1109/TVCG.2013.193
http://dx.doi.org/10.1109/TVCG.2013.193
2169
2178

J
We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.
Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.
;;;;
10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.27
Visual analytics, movement data, collective movement
VAST
2013
Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli
10.1109/TVCG.2013.194
http://dx.doi.org/10.1109/TVCG.2013.194
2129
2138

J
We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.
Kurzhals, K.;Weiskopf, D.
Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;
10.1109/TVCG.2010.149;10.1109/TVCG.2011.193;10.1109/TVCG.2012.276;10.1109/TVCG.2006.194
Eye-tracking, space-time cube, dynamic areas of interest, spatiotemporal clustering, motion-compensated heat map
VAST
2013
Supporting Awareness through Collaborative Brushing and Linking of Tabular Data
10.1109/TVCG.2013.197
http://dx.doi.org/10.1109/TVCG.2013.197
2189
2197

J
Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing & linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing & linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.
Hajizadeh, A.H.;Tory, M.;Leung, R.
Univ. of Victoria, Victoria, BC, Canada|c|;;
10.1109/TVCG.2011.196;10.1109/TVCG.2007.70541;10.1109/TVCG.2011.185;10.1109/VAST.2010.5652880;10.1109/INFVIS.2003.1249020;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102447
Collaboration, awareness, attentionally ambient visualization, brushing and linking, linked views, user study
VAST
2013
Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes
10.1109/TVCG.2013.198
http://dx.doi.org/10.1109/TVCG.2013.198
2267
2276

J
The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.
Hadlak, S.;Schumann, H.;Cap, C.H.;Wollenberg, T.
Univ. of Rostock, Rostock, Germany|c|;;;
10.1109/INFVIS.2005.1532151;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.18;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213;10.1109/TVCG.2006.193;10.1109/VAST.2012.6400493;10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70529;10.1109/INFVIS.2002.1173160
Dynamic networks, visualization, supergraph clustering
VAST
2013
Temporal Event Sequence Simplification
10.1109/TVCG.2013.200
http://dx.doi.org/10.1109/TVCG.2013.200
2227
2236

J
Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.
Monroe, M.;Rongjian Lan;Hanseung Lee;Plaisant, C.;Shneiderman, B.
Univ. of Maryland, College Park, MD, USA|c|;;;;
10.1109/TVCG.2009.117;10.1109/TVCG.2012.213;10.1109/VAST.2010.5652890
Event sequences, simplification, electronic heath records, temporal query
VAST
2013
The Impact of Physical Navigation on Spatial Organization for Sensemaking
10.1109/TVCG.2013.205
http://dx.doi.org/10.1109/TVCG.2013.205
2207
2216

J
Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.
Andrews, C.;North, C.
Middlebury Coll., USA|c|;
10.1109/VAST.2012.6400559;10.1109/VAST.2008.4677358;10.1109/VAST.2009.5333878
Sensemaking, visual analytics, physical navigation, embodiment, large and high-resolution displays
VAST
2013
TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data
10.1109/TVCG.2013.206
http://dx.doi.org/10.1109/TVCG.2013.206
2247
2256

J
Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.
Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.
Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Vienna, Austria|c|;;;;
10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102446;10.1109/VAST.2006.261428;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.144;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.64;10.1109/TVCG.2013.222;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.185;10.1109/TVCG.2010.126;10.1109/INFVIS.1997.636792
Visual Analytics, information visualization, toolkits, software infrastructure, time, temporal data
VAST
2013
Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop
10.1109/TVCG.2013.207
http://dx.doi.org/10.1109/TVCG.2013.207
2109
2118

J
Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.
Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen
Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;
10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208
Visual knowledge discovery, data clustering, machine learning, multimedia visualization
VAST
2013
Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design
10.1109/TVCG.2013.211
http://dx.doi.org/10.1109/TVCG.2013.211
2217
2226

J
This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.
Kodagoda, N.;Attfield, S.;Wong, B.L.W.;Rooney, C.;Choudhury, S.
Middlesex Univ., London, UK|c|;;;;
10.1109/VAST.2009.5333020;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.252
Visual analytics, sense-making, dataframe mode, evaluation, reasoning, analysis, interaction, interface design
VAST
2013
UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization
10.1109/TVCG.2013.212
http://dx.doi.org/10.1109/TVCG.2013.212
1992
2001

J
Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.
Jaegul Choo;Changhyun Lee;Reddy, C.K.;Park, H.
Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;
10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443
Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics
VAST
2013
VAICo: Visual Analysis for Image Comparison
10.1109/TVCG.2013.213
http://dx.doi.org/10.1109/TVCG.2013.213
2090
2099

J
Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.
Schmidt, J.;Groller, M.E.;Bruckner, S.
Vienna Univ. of Technol., Vienna, Austria|c|;;
10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70623;10.1109/VAST.2012.6400555;10.1109/TVCG.2010.190;10.1109/VISUAL.1999.809871;10.1109/VISUAL.1999.809873;10.1109/TVCG.2011.248;10.1109/VISUAL.2002.1183790
Comparative visualization, focus+context visualization, image set comparison
VAST
2013
Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations
10.1109/TVCG.2013.219
http://dx.doi.org/10.1109/TVCG.2013.219
1982
1991

J
For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.
Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli, E.
Sch. of Comput. Software & Inf. Technol., Tianjin Univ., Tianjin, China|c|;;;;
10.1109/TVCG.2011.239;10.1109/INFVIS.2004.1;10.1109/TVCG.2008.173;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2012.244;10.1109/VAST.2007.4389013;10.1109/TVCG.2008.153;10.1109/INFVIS.2000.885098
Cultural heritage, wall paintings, degradation, visual analytics
VAST
2013
Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System
10.1109/TVCG.2013.220
http://dx.doi.org/10.1109/TVCG.2013.220
2070
2079

J
Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.
Shadoan, R.;Weaver, C.
Akashic Labs. LLC, USA|c|;
10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520
Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities
VAST
2013
Visual Analysis of Topic Competition on Social Media
10.1109/TVCG.2013.221
http://dx.doi.org/10.1109/TVCG.2013.221
2012
2021

J
How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.
Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;
10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851
Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting
VAST
2013
Visual Analytics for Model Selection in Time Series Analysis
10.1109/TVCG.2013.222
http://dx.doi.org/10.1109/TVCG.2013.222
2237
2246

J
Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.
Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.
Vienna Univ. of Technol., Vienna, Austria|c|;;;;;
10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539
Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views
VAST
2013
Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists
10.1109/TVCG.2013.223
http://dx.doi.org/10.1109/TVCG.2013.223
2032
2041

J
Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.
Ghani, S.;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Elmqvist, N.
Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;
10.1109/TVCG.2011.247;10.1109/VAST.2011.6102440;10.1109/TVCG.2012.213;10.1109/TVCG.2011.201;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70521;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173155;10.1109/VAST.2006.261430;10.1109/TVCG.2006.166;10.1109/TVCG.2011.209
Design study, user-centered design, node-link diagrams, multimodal graphs, interaction, qualitative evaluation
VAST
2013
Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration
10.1109/TVCG.2013.224
http://dx.doi.org/10.1109/TVCG.2013.224
2179
2188

J
We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.
Packer, E.;Bak, P.;Nikkila, M.;Polishchuk, V.;Ship, H.J.
IBM Res. Haifa Lab., Haifa, Israel|c|;;;;
10.1109/VAST.2011.6102449;10.1109/INFVIS.2003.1249015;10.1109/VAST.2012.6400486;10.1109/TVCG.2009.122;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.186
Heuristic-based spatial clustering, interactive visual clustering, k-order a-(alpha)-shapes
VAST
2013
Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips
10.1109/TVCG.2013.226
http://dx.doi.org/10.1109/TVCG.2013.226
2149
2158

J
As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.
Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.
;;;;
10.1109/INFVIS.2004.12;10.1109/VAST.2008.4677356;10.1109/VAST.2011.6102454;10.1109/TVCG.2007.70535;10.1109/VAST.2010.5652467;10.1109/INFVIS.2005.1532150;10.1109/VAST.2008.4677370;10.1109/INFVIS.2000.885086
Spatio-temporal queries, urban data, taxi movement data, visual exploration
VAST
2013
Visual Traffic Jam Analysis Based on Trajectory Data
10.1109/TVCG.2013.228
http://dx.doi.org/10.1109/TVCG.2013.228
2159
2168

J
In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.
Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.
Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;
10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455
Traffic visualization, traffic jam propagation
InfoVis
2012
A User Study on Curved Edges in Graph Visualization
10.1109/TVCG.2012.189
http://dx.doi.org/10.1109/TVCG.2012.189
2449
2456

J
Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.
Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.
Middlesex Univ., London, UK|c|;;;;
10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166
Graph, visualization, curved edges, evaluation
InfoVis
2012
Adaptive Composite Map Projections
10.1109/TVCG.2012.192
http://dx.doi.org/10.1109/TVCG.2012.192
2575
2582

J
All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.
Jenny, B.
Oregon State Univ., Corvallis, OR, USA|c|
10.1109/TVCG.2011.191;10.1109/TVCG.2010.191;10.1109/INFVIS.2000.885095
Multi-scale map, web mapping, web cartography, web map projection, web Mercator, HTML5 Canvas
InfoVis
2012
Algorithms for Labeling Focus Regions
10.1109/TVCG.2012.193
http://dx.doi.org/10.1109/TVCG.2012.193
2583
2592

J
In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.
Fink, M.;Haunert, J.-H.;Schulz, A.;Spoerhase, J.;Wolff, A.
Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|;;;;
10.1109/TVCG.2011.191;10.1109/TVCG.2010.180;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087
Focus+context techniques, data clustering, mobile and ubiquitous visualization, geographic/geospatial visualization
InfoVis
2012
An Empirical Model of Slope Ratio Comparisons
10.1109/TVCG.2012.196
http://dx.doi.org/10.1109/TVCG.2012.196
2613
2620

J
Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45Â°, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45Â° minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.'s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45Â°. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection.
Talbot, J.;Gerth, J.;Hanrahan, P.
;;
10.1109/TVCG.2006.163;10.1109/TVCG.2011.167
Banking to 45 degrees, slope perception, orientation resolution, aspect ratio selection
InfoVis
2012
An Empirical Study on Using Visual Embellishments in Visualization
10.1109/TVCG.2012.197
http://dx.doi.org/10.1109/TVCG.2012.197
2759
2768

J
In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces â€œdivided attentionâ€? and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.
Borgo, R.;Abdul-Rahman, A.;Mohamed, F.;Grant, P.W.;Reppa, I.;Floridi, L.;Min Chen
Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;
10.1109/TVCG.2010.132;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.171;10.1109/TVCG.2011.175
Visual embellishments, metaphors, icons, cognition, working memory, long-term memory, visual search, evaluation
InfoVis
2012
Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing
10.1109/TVCG.2012.199
http://dx.doi.org/10.1109/TVCG.2012.199
2536
2545

J
People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.
Micallef, L.;Dragicevic, P.;Fekete, J.
INRIA, Sophia Antipolis, France|c|;;
10.1109/TVCG.2010.210;10.1109/TVCG.2009.122
Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing
InfoVis
2012
Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions
10.1109/TVCG.2012.204
http://dx.doi.org/10.1109/TVCG.2012.204
2689
2698

J
The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more â€œnaturalâ€?interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more â€œnatural,â€?interaction techniques for InfoVis.
Bongshin Lee;Isenberg, P.;Riche, N.H.;Carpendale, S.
;;;
10.1109/TVCG.2010.164;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121;10.1109/TVCG.2009.162;10.1109/TVCG.2010.206;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70568
Design considerations, interaction, post-WIMP, NUI (Natural User Interface)
InfoVis
2012
Capturing the Design Space of Sequential Space-filling Layouts
10.1109/TVCG.2012.205
http://dx.doi.org/10.1109/TVCG.2012.205
2593
2602

J
We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.
Baudel, T.;Broeksema, B.
;
10.1109/VISUAL.1991.175815;10.1109/TVCG.2006.178;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.200;10.1109/TVCG.2011.227;10.1109/INFVIS.1998.729560;10.1109/TVCG.2010.186;10.1109/TVCG.2008.165;10.1109/TVCG.2009.128
Layout, visualization models, tables & tree layouts, grids, treemaps, mosaic plots, dimensional stacking
InfoVis
2012
Comparing Clusterings Using Bertin's Idea
10.1109/TVCG.2012.207
http://dx.doi.org/10.1109/TVCG.2012.207
2506
2515

J
Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes â€œthe discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of studyâ€? Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin's idea and concepts related to Kendall's t [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset.
Pilhofer, A.;Gribov, A.;Unwin, A.
Univ. of Augsburg, Augsburg, Germany|c|;;
10.1109/TVCG.2010.184;10.1109/TVCG.2010.138
Order optimization, fluctuation diagrams, classification, seriation
InfoVis
2012
Compressed Adjacency Matrices: Untangling Gene Regulatory Networks
10.1109/TVCG.2012.208
http://dx.doi.org/10.1109/TVCG.2012.208
2457
2466

J
We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.
Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.
;;
10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030
Network, gene regulation, scale-free, adjacency matrix
InfoVis
2012
Design Considerations for Optimizing Storyline Visualizations
10.1109/TVCG.2012.212
http://dx.doi.org/10.1109/TVCG.2012.212
2679
2688

J
Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's â€œMovie Narrative Chartsâ€?[21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.
Tanahashi, Y.;Kwan-Liu Ma
ViDi Res. Group, Univ. of California, Davis, CA, USA|c|;
10.1109/TVCG.2008.166;10.1109/TVCG.2008.135;10.1109/TVCG.2011.190;10.1109/TVCG.2011.239;10.1109/TVCG.2006.193;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.125;10.1109/INFVIS.2002.1173160
Layout algorithm, timeline visualization, storyline visualization, design study
InfoVis
2012
Design Study Methodology: Reflections from the Trenches and the Stacks
10.1109/TVCG.2012.213
http://dx.doi.org/10.1109/TVCG.2012.213
2431
2440

J
Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.
Sedlmair, M.;Meyer, M.;Munzner, T.
;;
10.1109/INFVIS.1999.801869;10.1109/INFVIS.1996.559226;10.1109/TVCG.2008.117;10.1109/TVCG.2009.152;10.1109/TVCG.2010.206;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.193;10.1109/VAST.2011.6102443;10.1109/TVCG.2011.174;10.1109/VAST.2007.4389008;10.1109/TVCG.2009.116;10.1109/TVCG.2011.192;10.1109/TVCG.2009.128;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.167;10.1109/TVCG.2009.111;10.1109/TVCG.2011.209
Design study, methodology, visualization, framework
InfoVis
2012
Different Strokes for Different Folks: Visual Presentation Design between Disciplines
10.1109/TVCG.2012.214
http://dx.doi.org/10.1109/TVCG.2012.214
2411
2420

J
We present an ethnographic study of design differences in visual presentations between academic disciplines. Characterizing design conventions between users and data domains is an important step in developing hypotheses, tools, and design guidelines for information visualization. In this paper, disciplines are compared at a coarse scale between four groups of fields: social, natural, and formal sciences; and the humanities. Two commonplace presentation types were analyzed: electronic slideshows and whiteboard â€œchalk talksâ€? We found design differences in slideshows using two methods - coding and comparing manually-selected features, like charts and diagrams, and an image-based analysis using PCA called eigenslides. In whiteboard talks with controlled topics, we observed design behaviors, including using representations and formalisms from a participant's own discipline, that suggest authors might benefit from novel assistive tools for designing presentations. Based on these findings, we discuss opportunities for visualization ethnography and human-centered authoring tools for visual information.
Gomez, S.R.;Jianu, R.;Ziemkiewicz, C.;Hua Guo;Laidlaw, D.H.
Brown Univ., Providence, RI, USA|c|;;;;
10.1109/TVCG.2011.251;10.1109/TVCG.2010.177;10.1109/TVCG.2010.179;10.1109/TVCG.2011.255
Presentations, information visualization, design, visual analysis
InfoVis
2012
Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making
10.1109/TVCG.2012.215
http://dx.doi.org/10.1109/TVCG.2012.215
2421
2430

J
For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.
Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi
Sch. ofIndustrial Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;
10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.193;10.1109/VAST.2008.4677363;10.1109/TVCG.2010.149;10.1109/TVCG.2011.183;10.1109/VAST.2009.5333920
Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision
InfoVis
2012
Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty
10.1109/TVCG.2012.220
http://dx.doi.org/10.1109/TVCG.2012.220
2769
2778

J
We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.
Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.
INRIA, Sophia Antipolis, France|c|;;;
10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1992.235199;10.1109/TVCG.2007.70530;10.1109/TVCG.2009.114;10.1109/VAST.2009.5332611;10.1109/VAST.2006.261424;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70589;10.1109/VISUAL.2000.885679
Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception
InfoVis
2012
Evaluating the Effect of Style in Information Visualization
10.1109/TVCG.2012.221
http://dx.doi.org/10.1109/TVCG.2012.221
2739
2748

J
This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.
Vande Moere, A.;Tomitsch, M.;Wimmer, C.;Christoph, B.;Grechenig, T.
;;;;
10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.122
Visualization, design, style, aesthetics, evaluation, online study, user experience
InfoVis
2012
Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization
10.1109/TVCG.2012.225
http://dx.doi.org/10.1109/TVCG.2012.225
2659
2668

J
Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.
Wongsuphasawat, K.;Gotz, D.
Univ. of Maryland, College Park, MD, USA|c|;
10.1109/TVCG.2009.181;10.1109/VAST.2011.6102453;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532150;10.1109/VAST.2009.5332595;10.1109/TVCG.2009.117;10.1109/INFVIS.2005.1532152;10.1109/VAST.2006.261421
Outflow, information visualization, temporal event sequences, state diagram, state transition
InfoVis
2012
Facilitating Discourse Analysis with Interactive Visualization
10.1109/TVCG.2012.226
http://dx.doi.org/10.1109/TVCG.2012.226
2639
2648

J
A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.
Jian Zhao;Chevalier, F.;Collins, C.;Balakrishnan, R.
Univ. of Toronto, Toronto, ON, Canada|c|;;;
10.1109/VAST.2011.6102439;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.122;10.1109/INFVIS.1999.801869;10.1109/INFVIS.2003.1249030
Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques
InfoVis
2012
Graphical Overlays: Using Layered Elements to Aid Chart Reading
10.1109/TVCG.2012.229
http://dx.doi.org/10.1109/TVCG.2012.229
2631
2638

J
Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.
Kong, N.;Agrawala, M.
Comput. Sci. Div., UC Berkeley, Berkeley, CO, USA|c|;
10.1109/TVCG.2011.242;10.1109/VISUAL.1991.175820;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183
Visualization, overlays, graphical perception, graph comprehension
InfoVis
2012
Graphical Tests for Power Comparison of Competing Designs
10.1109/TVCG.2012.230
http://dx.doi.org/10.1109/TVCG.2012.230
2441
2448

J
Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.
Hofmann, H.;Follett, L.;Majumder, M.;Cook, D.
Stat., Iowa State Univ., Ames, IA, USA|c|;;;
10.1109/TVCG.2009.111;10.1109/TVCG.2010.161
Lineups, Visual inference, Power comparison, Efficiency of displays
InfoVis
2012
How Capacity Limits of Attention Influence Information Visualization Effectiveness
10.1109/TVCG.2012.233
http://dx.doi.org/10.1109/TVCG.2012.233
2402
2410

J
In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.
Haroz, S.;Whitney, D.
Univ. of California, Davis, CA, USA|c|;
10.1109/INFVIS.2001.963274;10.1109/VISUAL.1996.568118;10.1109/TVCG.2010.186;10.1109/VISUAL.2005.1532838
Perception, attention, color, motion, user study, nominal axis, layout, goal-oriented design
InfoVis
2012
Intelligent Graph Layout Using Many Users' Input
10.1109/TVCG.2012.236
http://dx.doi.org/10.1109/TVCG.2012.236
2699
2708

J
In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.
Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang
Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;
10.1109/TVCG.2008.155;10.1109/INFVIS.2005.1532130;10.1109/TVCG.2009.109;10.1109/TVCG.2007.70580
Graph layout, Laplacian matrix, force directed layout, stress model, merging, editing, crowd sourcing
InfoVis
2012
Interaction Support for Visual Comparison Inspired by Natural Behavior
10.1109/TVCG.2012.237
http://dx.doi.org/10.1109/TVCG.2012.237
2719
2728

J
Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.
Tominski, C.;Forsell, C.;Johansson, J.
Univ. of Rostock, Rostock, Germany|c|;;
10.1109/TVCG.2008.109;10.1109/TVCG.2007.70568;10.1109/TVCG.2011.201;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.151;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2011.223;10.1109/TVCG.2007.70582;10.1109/TVCG.2008.153
Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction
InfoVis
2012
Interactive Level-of-Detail Rendering of Large Graphs
10.1109/TVCG.2012.238
http://dx.doi.org/10.1109/TVCG.2012.238
2486
2495

J
We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.
Zinsmaier, M.;Brandes, U.;Deussen, O.;Strobelt, H.
;;;
10.1109/INFVIS.2005.1532150;10.1109/TVCG.2006.120;10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.187;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/INFVIS.2004.66
Graph visualization, OpenGL, edge aggregation
InfoVis
2012
Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors
10.1109/TVCG.2012.244
http://dx.doi.org/10.1109/TVCG.2012.244
2799
2808

J
Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.
Ma, J.;Liao, I.;Kwan-Liu Ma;Frazier, J.
Exploratorium, San Francisco, CA, USA|c|;;;
10.1109/TVCG.2008.127;10.1109/TVCG.2011.175;10.1109/INFVIS.2004.8
Information visualization, user interaction, evaluation, user studies, science museums, informal learning environments
InfoVis
2012
Memorability of Visual Features in Network Diagrams
10.1109/TVCG.2012.245
http://dx.doi.org/10.1109/TVCG.2012.245
2477
2485

J
We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.
Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.
Monash Univ., Melbourne, VIC, Australia|c|;;;
10.1109/TVCG.2008.155;10.1109/TVCG.2009.109
Network diagrams, graph layout, perceptual theories, visual features, diagram recall, experiment
InfoVis
2012
Organizing Search Results with a Reference Map
10.1109/TVCG.2012.250
http://dx.doi.org/10.1109/TVCG.2012.250
2546
2555

J
We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.
Nocaj, A.;Brandes, U.
;
10.1109/INFVIS.2005.1532128;10.1109/INFVIS.1997.636718;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/TVCG.2009.176
Search results, mental map, voronoi treemaps, dynamic graph layout, multidimensional scaling, edge bundling
InfoVis
2012
Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications
10.1109/TVCG.2012.251
http://dx.doi.org/10.1109/TVCG.2012.251
2516
2525

J
We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.
Bezerianos, A.;Isenberg, P.
;
10.1109/TVCG.2011.160;10.1109/TVCG.2006.184
Information visualization, perception, wall-displays
InfoVis
2012
PivotPaths: Strolling through Faceted Information Spaces
10.1109/TVCG.2012.252
http://dx.doi.org/10.1109/TVCG.2012.252
2709
2718

J
We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.
Dork, M.;Riche, N.H.;Ramos, G.;Dumais, S.
;;;
10.1109/VAST.2009.5333443;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677370;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.175
Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search
InfoVis
2012
RankExplorer: Visualization of Ranking Changes in Large Time Series Data
10.1109/TVCG.2012.253
http://dx.doi.org/10.1109/TVCG.2012.253
2669
2678

J
For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.
Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;
10.1109/TVCG.2008.166;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.193;10.1109/VAST.2010.5652530;10.1109/INFVIS.2000.885098;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2010.129;10.1109/TVCG.2008.181;10.1109/TVCG.2009.187;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.194;10.1109/TVCG.2011.239;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195;10.1109/TVCG.2009.180
Time-series data, ranking change, Themeriver, interaction techniques
InfoVis
2012
RelEx: Visualization for Actively Changing Overlay Network Specifications
10.1109/TVCG.2012.255
http://dx.doi.org/10.1109/TVCG.2012.255
2729
2738

J
We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.
Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.
Univ. of British Columbia, Vancouver, BC, Canada|c|;;;
10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102443;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/INFVIS.1999.801869;10.1109/TVCG.2008.141;10.1109/TVCG.2008.117;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/INFVIS.2003.1249030;10.1109/VAST.2006.261426
Network visualization, change management, traffic routing, traffic optimization, automotive, design study
InfoVis
2012
Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data
10.1109/TVCG.2012.256
http://dx.doi.org/10.1109/TVCG.2012.256
2621
2630

J
Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.
Turkay, C.;Lundervold, A.;Lundervold, A.J.;Hauser, H.
Dept. of Inf., Univ. of Bergen, Bergen, Norway|c|;;;
10.1109/TVCG.2009.199;10.1109/INFVIS.2005.1532142;10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70569;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153
Interactive visual analysis, high-dimensional data analysis
InfoVis
2012
Sketchy Rendering for Information Visualization
10.1109/TVCG.2012.262
http://dx.doi.org/10.1109/TVCG.2012.262
2749
2758

J
We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.
Wood, J.;Isenberg, P.;Isenberg, T.;Dykes, J.;Boukhelifa, N.;Slingsby, A.
giCentre, City Univ. London, London, UK|c|;;;;;
10.1109/TVCG.2010.186;10.1109/TVCG.2011.175;10.1109/TVCG.2012.220;10.1109/TVCG.2011.251;10.1109/TVCG.2011.209;10.1109/TVCG.2011.255
NPR, non-photorealistic rendering, sketch, hand-drawn, uncertainty, visualization
InfoVis
2012
SnapShot: Visualization to Propel Ice Hockey Analytics
10.1109/TVCG.2012.263
http://dx.doi.org/10.1109/TVCG.2012.263
2819
2828

J
Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.
Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.T.
;;;
10.1109/TVCG.2010.179;10.1109/TVCG.2007.70537;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.1996.559229
Visual knowledge discovery, visual knowledge representation, hypothesis testing, visual evidence, human computer interaction
InfoVis
2012
Spatial Text Visualization Using Automatic Typographic Maps
10.1109/TVCG.2012.264
http://dx.doi.org/10.1109/TVCG.2012.264
2556
2564

J
We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.
Afzal, S.;Maciejewski, R.;Yun Jang;Elmqvist, N.;Ebert, D.S.
Purdue Univ. in West Lafayette, West Lafayette, IN, USA|c|;;;;
10.1109/VAST.2010.5652931;10.1109/TVCG.2010.191;10.1109/TVCG.2010.175;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2002.1173144;10.1109/TVCG.2008.165;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171;10.1109/INFVIS.2000.885095
Geovisualization, spatial data, text visualization, label placement
InfoVis
2012
Stacking-Based Visualization of Trajectory Attribute Data
10.1109/TVCG.2012.265
http://dx.doi.org/10.1109/TVCG.2012.265
2565
2574

J
Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.
Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.
;;;
10.1109/TVCG.2010.197;10.1109/VAST.2011.6102455;10.1109/VAST.2009.5332593;10.1109/VISUAL.1995.480803;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532144;10.1109/VAST.2011.6102454
Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data
InfoVis
2012
Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments
10.1109/TVCG.2012.271
http://dx.doi.org/10.1109/TVCG.2012.271
2603
2612

J
Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.
Maguire, E.;Rocca-Serra, P.;Sansone, S.-A.;Davies, J.;Min Chen
Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK|c|;;;;
10.1109/TVCG.2006.134;10.1109/TVCG.2012.197;10.1109/TVCG.2010.132;10.1109/VISUAL.1995.485141;10.1109/INFVIS.1998.729568
Glyph-based techniques, taxonomies, design methodologies, bioinformatics visualization
InfoVis
2012
The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning
10.1109/TVCG.2012.272
http://dx.doi.org/10.1109/TVCG.2012.272
2789
2798

J
In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.
Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen
;;;;;
10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541
Informal science education, collaborative learning, large tree visualizations, multi-touch interaction
InfoVis
2012
Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards
10.1109/TVCG.2012.275
http://dx.doi.org/10.1109/TVCG.2012.275
2779
2788

J
Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.
Walny, J.;Bongshin Lee;Johns, P.;Riche, N.H.;Carpendale, S.
;;;;
10.1109/TVCG.2012.262;10.1109/TVCG.2009.174;10.1109/TVCG.2011.251;10.1109/TVCG.2007.70568;10.1109/TVCG.2010.164
Pen and touch, interaction, Wizard of Oz, whiteboard, data exploration
InfoVis
2012
Visual Semiotics & Uncertainty Visualization: An Empirical Study
10.1109/TVCG.2012.279
http://dx.doi.org/10.1109/TVCG.2012.279
2496
2505

J
This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.
MacEachren, A.M.;Roth, R.E.;O'Brien, J.;Li, B.;Swingley, D.;Gahegan, M.
;;;;;
10.1109/VISUAL.1992.235199;10.1109/TVCG.2011.197;10.1109/TVCG.2009.114
Uncertainty visualization, uncertainty categories, visual variables, semiotics
InfoVis
2012
Visualizing Flow of Uncertainty through Analytical Processes
10.1109/TVCG.2012.285
http://dx.doi.org/10.1109/TVCG.2012.285
2526
2535

J
Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.
Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma
Univ. of California, Davis, CA, USA|c|;;
10.1109/TVCG.2008.137;10.1109/TVCG.2011.178;10.1109/INFVIS.2004.2;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2009.114;10.1109/TVCG.2011.197;10.1109/TVCG.2010.176
Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion
InfoVis
2012
Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations
10.1109/TVCG.2012.286
http://dx.doi.org/10.1109/TVCG.2012.286
2467
2476

J
The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.
Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.
;;;;;;;;
10.1109/TVCG.2009.196;10.1109/INFVIS.2004.66
Performance analysis, network traffic visualization, projected graph layouts
InfoVis
2012
Visualizing Student Histories Using Clustering and Composition
10.1109/TVCG.2012.288
http://dx.doi.org/10.1109/TVCG.2012.288
2809
2818

J
While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.
Trimm, D.;Rheingans, P.;desJardins, M.
Univ. of Maryland, Baltimore County (UMBC), Baltimore, MD, USA|c|;;
10.1109/INFVIS.2005.1532140;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.131
Clustering, aggregate visualization, student performance analysis, visualization composition
InfoVis
2012
Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time
10.1109/TVCG.2012.291
http://dx.doi.org/10.1109/TVCG.2012.291
2649
2658

J
When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, â€œWhisperâ€? for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.
Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu
Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;
10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188
Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns
VAST
2012
A case study: Tracking and visualizing the evolution of dark matter halos and groups of satellite halos in cosmology simulations
10.1109/VAST.2012.6400532
http://dx.doi.org/10.1109/VAST.2012.6400532
243
244
X
M
In this poster, we track the evolution of cosmic structures and higher level host structures in cosmological simulation as they interact with each other. The structures found in these simulations are made up of groups of dark matter tracer particles called satellite halos and groups of satellite halos called host halos. We implement a multilevel tracking model to track dark matter tracer particles, satellite halos and host halos to understand their behaviour and show how the different structures are formed over time. We also represent the evolution of halos in the form of merger trees for detailed analysis by cosmologists.
Takle, J.;Silver, D.;Heitmann, K.
Dept. of Electr. &amp; Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;;

Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns
VAST
2012
A correlative analysis process in a visual analytics environment
10.1109/VAST.2012.6400491
http://dx.doi.org/10.1109/VAST.2012.6400491
33
42

C
Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.
Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.
Purdue Univ., West Lafayette, IN, USA|c|;;;;;
10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801851;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195
Visual analytics, correlative analysis
VAST
2012
A generic model for the integration of interactive visualization and statistical computing using R
10.1109/VAST.2012.6400537
http://dx.doi.org/10.1109/VAST.2012.6400537
233
234
X
M
This poster describes general concepts of integrating the statistical computation package R into a coordinated multiple views framework. The integration is based on a cyclic analysis workflow. In this model, interactive selections are a key aspect to trigger and control computations in R. Dynamic updates of data columns are a generic mechanism to transfer computational results back to the interactive visualization. Further aspects include the integration of the R console and an R object browser as views in our system. We illustrate our approach by means of an interactive modeling process.
Kehrer, J.;Boubela, R.N.;Filzmoser, P.;Piringer, H.
VRVis Res. Center, Vienna, Austria|c|;;;

Visual analytics, correlative analysis
VAST
2012
A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series
10.1109/TVCG.2012.191
http://dx.doi.org/10.1109/TVCG.2012.191
2899
2907

J
We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems.
Sips, M.;Kothur, P.;Unger, A.;Hege, H.-C.;Dransch, D.
German Res. Center for Geosci. GFZ, Germany|c|;;;;
10.1109/INFVIS.2001.963273;10.1109/INFVIS.1995.528685
Time series analysis, multiscale visualization, visual analytics
VAST
2012
A visual analytics approach to understanding cycling behaviour
10.1109/VAST.2012.6400550
http://dx.doi.org/10.1109/VAST.2012.6400550
207
208
X
M
Existing research into cycling behaviours has either relied on detailed ethnographic studies or larger public attitude surveys [1] [9]. Instead, following recent contributions from information visualization [13] and data mining [5] [7], this design study uses visual analytics techniques to identify, describe and explain cycling behaviours within a large and attribute rich transactional dataset. Using data from London's bike share scheme1, customer level classifications will be created, which consider the regularity of scheme use, journey length and travel times. Monitoring customer usage over time, user classifications will attend to the dynamics of cycling behaviour, asking substantive questions about how behaviours change under varying conditions. The 3-year PhD project will contribute to academic and strategic discussions around sustainable travel policy. A programme of research is outlined, along with an early visual analytics prototype for rapidly querying customer journeys.
Beecham, R.;Wood, J.;Bowerman, A.
City Univ. London, London, UK|c|;;

Time series analysis, multiscale visualization, visual analytics
VAST
2012
AlVis: Situation awareness in the surveillance of road tunnels
10.1109/VAST.2012.6400556
http://dx.doi.org/10.1109/VAST.2012.6400556
153
162

C
In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.
Piringer, H.;Buchetics, M.;Benedik, R.
;;
10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2005.1532134;10.1109/VAST.2011.6102456;10.1109/TVCG.2007.70544;10.1109/TVCG.2007.70521;10.1109/TVCG.2007.70621;10.1109/INFVIS.2004.27;10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.185;10.1109/VAST.2007.4388994;10.1109/VAST.2007.4388998;10.1109/VAST.2008.4677353
A visual analytics approach to understanding cycling behaviour s
VAST
2012
An adaptive parameter space-filling algorithm for highly interactive cluster exploration
10.1109/VAST.2012.6400493
http://dx.doi.org/10.1109/VAST.2012.6400493
13
22

C
For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.
Ahmed, Z.;Weaver, C.
Sch. of Comput. Sci. &amp; Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|;
10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12;10.1109/VAST.2009.5332629;10.1109/VAST.2008.4677357;10.1109/TVCG.2011.188;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VAST.2007.4388999
A visual analytics approach to understanding cycling behaviour s
VAST
2012
An Affordance-Based Framework for Human Computation and Human-Computer Collaboration
10.1109/TVCG.2012.195
http://dx.doi.org/10.1109/TVCG.2012.195
2859
2868

J
Visual Analytics is â€œthe science of analytical reasoning facilitated by visual interactive interfacesâ€?[70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.
Crouser, R.J.;Chang, R.
;
10.1109/VAST.2010.5652398;10.1109/VAST.2011.6102461;10.1109/TVCG.2009.199;10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652484;10.1109/VAST.2009.5332584;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5333564;10.1109/VAST.2010.5652392;10.1109/VAST.2009.5332586;10.1109/VAST.2011.6102451;10.1109/VAST.2009.5333023;10.1109/VAST.2009.5333020;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.173;10.1109/TVCG.2011.218;10.1109/TVCG.2011.231;10.1109/VAST.2010.5652443;10.1109/VAST.2010.5653598;10.1109/VAST.2011.6102447
Human computation, human complexity, theory, framework
VAST
2012
Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays
10.1109/VAST.2012.6400559
http://dx.doi.org/10.1109/VAST.2012.6400559
123
131

C
Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.
Andrews, C.;North, C.
Virginia Tech, Blacksburg, VA, USA|c|;
10.1109/TVCG.2008.121;10.1109/VAST.2008.4677362;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677358;10.1109/TVCG.2006.184;10.1109/VAST.2007.4388992;10.1109/VAST.2010.5652880;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878
Embodiment, distributed cognition, large and high-resolution display, sensemaking, space
VAST
2012
Augmenting visual representation of affectively charged information using sound graphs
10.1109/VAST.2012.6400547
http://dx.doi.org/10.1109/VAST.2012.6400547
213
214
X
M
Within the Visual Analytics research agenda there is an interest on studying the applicability of multimodal information representation and interaction techniques for the analytical reasoning process. The present study summarizes a pilot experiment conducted to understand the effects of augmenting visualizations of affectively-charged information using auditory graphs. We designed an audiovisual representation of social comments made to different news posted on a popular website, and their affective dimension using a sentiment analysis tool for short texts. Participants of the study were asked to create an assessment of the affective valence trend (positive or negative) of the news articles using for it, the visualizations and sonifications. The conditions were tested looking for speed/accuracy trade off comparing the visual representation with an audiovisual one. We discuss our preliminary findings regarding the design of augmented information-representation.
Calderon, N.A.;Riecke, B.E.;Fisher, B.
;;

Embodiment, distributed cognition, large and high-resolution display, sensemaking, space
VAST
2012
Dis-function: Learning distance functions interactively
10.1109/VAST.2012.6400486
http://dx.doi.org/10.1109/VAST.2012.6400486
83
92

C
The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.
Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.
Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;
10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443
Embodiment, distributed cognition, large and high-resolution display, sensemaking, space
VAST
2012
Enterprise Data Analysis and Visualization: An Interview Study
10.1109/TVCG.2012.219
http://dx.doi.org/10.1109/TVCG.2012.219
2917
2926

J
Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.
Kandel, S.;Paepcke, A.;Hellerstein, J.M.;Heer, J.
Stanford Univ., Stanford, CA, USA|c|;;;
10.1109/TVCG.2008.137;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5652880;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102435
Data, analysis, visualization, enterprise
VAST
2012
Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts
10.1109/TVCG.2012.224
http://dx.doi.org/10.1109/TVCG.2012.224
2869
2878

J
While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems.
Youn-ah Kang;Stasko, J.
;
10.1109/VAST.2008.4677362;10.1109/VAST.2006.261416;10.1109/INFVIS.2004.5;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333878
Visual analytics, case study, qualitative evaluation
VAST
2012
Exploring cyber physical data streams using Radial Pixel Visualizations
10.1109/VAST.2012.6400541
http://dx.doi.org/10.1109/VAST.2012.6400541
225
226
X
M
Cyber physical systems (CPS), such as smart buildings and data centers, are richly instrumented systems composed of tightly coupled computational and physical elements that generate large amounts of data. To explore CPS data and obtain actionable insights, we construct a Radial Pixel Visualization (RPV) system, which uses multiple concentric rings to show the data in a compact circular layout of small polygons (pixel cells), each of which represents an individual data value. RPV provides an effective visual representation of locality and periodicity of the high volume, multivariate data streams, and seamlessly combines them with the results of an automated analysis. In the outermost ring the results of correlation analysis and peak point detection are highlighted. Our explorations demonstrates how RPV can help administrators to identify periodic thermal hot spots, understand data center energy consumption, and optimize IT workload.
Hao, M.;Marwah, M.;Mittelstadt, S.;Janetzko, H.;Keim, D.;Dayal, U.;Bash, C.;Felix, C.;Patel, C.;Hsu, M.;Chen, Y.
Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;;;;;;

Visual analytics, case study, qualitative evaluation
VAST
2012
Exploring the impact of emotion on visual judgement
10.1109/VAST.2012.6400540
http://dx.doi.org/10.1109/VAST.2012.6400540
227
228
X
M
Existing research suggests that individual personality differences can influence performance with visualizations. In addition to stable traits such as locus of control, research in psychology has found that temporary changes in affect (emotion) can significantly impact individual performance on cognitive tasks. We examine the relationship between fundamental visual judgement tasks and affect through a crowdsourced user study that combines affective-priming techniques from psychology with longstanding graphical perception experiments. Our results suggest that affective-priming can significantly influence accuracy in visual judgements, and that some chart types may be more affected than others.
Harrison, L.;Chang, R.;Aidong Lu
UNC-Charlotte, Charlotte, NC, USA|c|;;

  8 ://dx.doi.org/10.1109/VAST.2012.6400540 dgement 
VAST
2012
Feature-similarity visualization of MRI cortical surface data
10.1109/VAST.2012.6400548
http://dx.doi.org/10.1109/VAST.2012.6400548
211
212
X
M
We present an analytics-based framework for simultaneous visualization of large surface data collections arising in clinical neuroimaging studies. Termed Informatics Visualization for Neuroimaging (INVIZIAN), this framework allows the visualization of both cortical surfaces characteristics and feature relatedness in unison. It also uses dimension reduction methods to derive new coordinate systems using a Jensen-Shannon divergence metric for positioning cortical surfaces in a metric space such that the proximity in location is proportional to neuroanatomical similarity. Feature data such as thickness and volume are colored on the cortical surfaces and used to display both subject-specific feature values and global trends within the population. Additionally, a query-based framework allows the neuroscience researcher to investigate probable correlations between neuroanatomical and subject patient attribute values such as age and diagnosis.
Bowman, I.;Joshi, S.H.;Greer, V.;Van Horn, J.D.
Sch. of Med., Lab. of Neuro Imaging, UCLA, Los Angeles, CA, USA|c|;;;

Exploring the impact of emotion on visual judgement 
VAST
2012
iLAMP: Exploring high-dimensional spacing through backward multidimensional projection
10.1109/VAST.2012.6400489
http://dx.doi.org/10.1109/VAST.2012.6400489
53
62

C
Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space.
Portes dos Santos Amorim, E.;Brazil, E.V.;Daniels, J.;Joia, P.;Nonato, L.G.;Sousa, M.C.
;;;;;
10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/TVCG.2010.213;10.1109/TVCG.2009.140;10.1109/TVCG.2011.220;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.170;10.1109/TVCG.2007.70580;10.1109/TVCG.2010.207;10.1109/INFVIS.2002.1173161
Exploring the impact of emotion on visual judgement 
VAST
2012
Incorporating GOMS analysis into the design of an EEG data visual analysis tool
10.1109/VAST.2012.6400542
http://dx.doi.org/10.1109/VAST.2012.6400542
223
224
X
M
In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst's current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user's visual analysis process.
Hua Guo;Tran, D.;Laidlaw, D.H.
Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;

Exploring the impact of emotion on visual judgement 
VAST
2012
Infographics at the Congressional Budget Office
10.1109/VAST.2012.6400533
http://dx.doi.org/10.1109/VAST.2012.6400533
241
242
X
M
The Congressional Budget Office (CBO) is an agency of the federal government with about 240 employees that provides the U.S. Congress with timely, nonpartisan analysis of important budgetary and economic issues. Recently, CBO began producing static infographics to present its headline stories and to provide information to the Congress in different ways.
Schwabish, J.A.


